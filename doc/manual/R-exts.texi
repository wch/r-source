\input texinfo
@c %**start of header
@setfilename R-exts.info
@settitle Writing R Extensions
@setchapternewpage on
@c %**end of header

@c @documentencoding ISO-8859-1

@syncodeindex fn vr

@dircategory Programming
@direntry
* R Extensions: (R-exts).      Writing R Extensions.
@end direntry

@finalout

@include R-defs.texi
@include version.texi

@ifinfo
This is a guide to extending R.

@Rcopyright{1999}

@ignore
Permission is granted to process this file through TeX and print the
results, provided the printed document carries a copying permission
notice identical to this one except for the removal of this paragraph
(this paragraph not being relevant to the printed manual).

@end ignore

@permission{}
@c ---------- ^- read that
@end ifinfo

@titlepage
@title Writing R Extensions
@subtitle Version @value{VERSION}
@author R Development Core Team
@page
@vskip 0pt plus 1filll
@permission{}

@Rcopyright{1999}

@value{ISBN-exts}
@end titlepage

@ifnothtml
@contents
@end ifnothtml

@ifnottex
@node Top, Acknowledgements, (dir), (dir)
@top Writing R Extensions

This is a guide to extending @R{}, describing the process of creating R
add-on packages, writing @R{} documentation, @R{}'s system and foreign
language interfaces, and the @R{} @acronym{API}.

The current version of this document is @value{VERSION}.

@value{ISBN-exts}
@end ifnottex

@menu
* Acknowledgements::            
* Creating R packages::         
* Writing R documentation files::  
* Tidying and profiling R code::  
* Debugging::                   
* System and foreign language interfaces::  
* The R API::                   
* Generic functions and methods::  
* Linking GUIs and other front-ends to R::  
* Function and variable index::  
* Concept index::               
@end menu

@node Acknowledgements, Creating R packages, Top, Top
@unnumbered Acknowledgements


The contributions of Saikat DebRoy (who wrote the first draft of a guide
to using @code{.Call} and @code{.External}) and of Adrian Trapletti (who
provided information on the C++ interface) are gratefully acknowledged.

@node Creating R packages, Writing R documentation files, Acknowledgements, Top
@chapter Creating R packages
@cindex Packages
@cindex Creating packages

Packages provide a mechanism for loading optional code and attached
documentation as needed.  The @R{} distribution provides several
packages.

In the following, we assume that you know the @samp{library()} command,
including its @samp{lib.loc} argument, and we also assume basic
knowledge of the @code{INSTALL} utility.  Otherwise, please look at @R{}'s
help pages

@example
?library
?INSTALL
@end example

@noindent
before reading on.  

A computing environment including a number of tools is assumed; the
``R Installation and Administration'' manual describes what is needed.
Under a Unix-alike most of the tools are likely to be present by
default, but Microsoft Windows and MacOS X will require careful setup.

Once a source package is created, it must be installed by
the command @code{R CMD INSTALL}.
@ifset UseExternalXrefs
@xref{Add-on packages, , Add-on-packages,
R-admin, R Installation and Administration}, for further details.
@end ifset

Other types of extensions are supported: @xref{Package types}.

@menu
* Package structure::           
* Configure and cleanup::       
* Checking and building packages::  
* Writing package vignettes::   
* Submitting a package to CRAN::  
* Package name spaces::         
* Writing portable packages::   
* Diagnostic messages::         
* Internationalization::        
* Package types::               
* Services::                    
@end menu

@node Package structure, Configure and cleanup, Creating R packages, Creating R packages
@section Package structure
@cindex Package structure

A package consists of a subdirectory containing a file
@file{DESCRIPTION} and the subdirectories @file{R}, @file{data},
@file{demo}, @file{exec}, @file{inst}, @file{man}, @file{po},
@file{src}, and @file{tests} (some of which can be missing).  The
package subdirectory may also contain files @file{INDEX},
@file{NAMESPACE}, @file{configure}, @file{cleanup}, and @file{COPYING}.
Other files such as @file{README}, @file{NEWS} or @file{ChangeLog} will
be ignored by @R{}, but may be useful to end-users.

The @file{DESCRIPTION} and @file{INDEX} files are described in the
sections below.  The @file{NAMESPACE} file is described in @ref{Package
name spaces}.

@cindex configure file
@cindex cleanup file

The optional files @file{configure} and @file{cleanup} are (Bourne
shell) script files which are executed before and (provided that option
@option{--clean} was given) after installation on Unix-alikes, see
@ref{Configure and cleanup}.

@cindex COPYING file

The optional file @file{COPYING} contains a copy of the license to the
package, e.g.@: a copy of the @acronym{GNU} public license.  Whereas you
should feel free to include a licence file in your source distribution,
please do not arrange to install yet another copy of the @acronym{GNU}
@file{COPYING} or @file{COPYING.LIB} files but refer to the copies in
the @R{} distribution (e.g., in directory @file{share/licenses} in your
own @file{COPYING} file).

The package subdirectory should be given the same name as the package.
Because some file systems (e.g., those on Windows) are not
case-sensitive, to maintain portability it is strongly recommended that
case distinctions not be used to distinguish different packages.  For
example, if you have a package named @file{foo}, do not also create a
package named @file{Foo}.

To ensure that file names are valid across file systems and supported
operating system platforms, the @acronym{ASCII} control characters as
well as the characters @samp{"}, @samp{*}, @samp{:}, @samp{/}, @samp{<},
@samp{>}, @samp{?}, @samp{\}, and @samp{|} are not allowed in file
names.  In addition, files with names @samp{con}, @samp{prn},
@samp{aux}, @samp{clock$}, @samp{nul}, @samp{com1} to @samp{com9}, and
@samp{lpt1} to @samp{lpt9} after conversion to lower case and stripping
possible ``extensions'' (e.g., @samp{lpt5.foo.bar}), are disallowed.
Also, file names in the same directory must not differ only by case (see
the previous paragraph).  In addition, the names of @samp{.Rd} files
will be used in URLs and so must be @acronym{ASCII} and not contain
@code{%}.

The @R{} function @code{package.skeleton} can help to create the
structure for a new package: see its help page for details.

@menu
* The DESCRIPTION file::        
* The INDEX file::              
* Package subdirectories::      
* Package bundles::             
@end menu

@node The DESCRIPTION file, The INDEX file, Package structure, Package structure
@subsection The @file{DESCRIPTION} file
@cindex DESCRIPTION file

The @file{DESCRIPTION} file contains basic information about the package
in the following format:

@quotation
@cartouche
@smallexample
Package: pkgname
Version: 0.5-1
Date: 2004-01-01
Title: My First Collection of Functions
Author: Joe Developer <Joe.Developer@@some.domain.net>, with
  contributions from A. User <A.User@@whereever.net>.
Maintainer: Joe Developer <Joe.Developer@@some.domain.net>
Depends: R (>= 1.8.0), nlme
Suggests: MASS
Description: A short (one paragraph) description of what
  the package does and why it may be useful.
License: GPL version 2 or newer
URL: http://www.r-project.org, http://www.another.url
@end smallexample
@end cartouche
@end quotation

@noindent
Continuation lines (for example, for descriptions longer than one line)
start with a space or tab.  The @samp{Package}, @samp{Version},
@samp{License}, @samp{Description}, @samp{Title}, @samp{Author}, and
@samp{Maintainer} fields are mandatory, the remaining fields
(@samp{Date}, @samp{Depends}, @samp{URL}, @dots{}) are optional.

The @file{DESCRIPTION} file should be written entirely in
@acronym{ASCII} for maximal portability.

The @samp{Package} and @samp{Version} fields give the name and the
version of the package, respectively.  The name should consist of
letters, numbers, and the dot character and start with a letter.  The
version is a sequence of at least @emph{two} (and usually three)
non-negative integers separated by single @samp{.} or @samp{-}
characters.  The canonical form is as shown in the example, and a
version such as @samp{0.01} or @samp{0.01.0} will be handled as if it
were @samp{0.1-0}.  (Translation packages are allowed names of the form
@samp{Translation-@var{ll}}.)

The @samp{License} field should contain an explicit statement or a
well-known abbreviation (such as @samp{GPL}, @samp{LGPL}, @samp{BSD}, or
@samp{Artistic}), perhaps followed by a reference to the actual license
file.  It is very important that you include this information!
Otherwise, it may not even be legally correct for others to distribute
copies of the package.

The @samp{Description} field should give a comprehensive description of
what the package does.  One can use several (complete) sentences, but
only one paragraph.

The @samp{Title} field should give a short description of the
package. Some package listings may truncate the title to 65 characters
in order to keep the overall size of the listing limited.
It should be capitalized, not use any markup, not have any continuation
lines, and not end in a period.  Older versions of @R{} used a separate
file @file{TITLE} for giving this information; this is now defunct, and
the @samp{Title} field in @file{DESCRIPTION} is required.

The @samp{Author} field describes who wrote the package.  It is a plain
text field intended for human readers, but not for automatic processing
(such as extracting the email addresses of all listed contributors).

The @samp{Maintainer} field should give a @emph{single} name with a
@emph{valid} email address in angle brackets (for sending bug reports
etc.).  It should not end in a period or comma.

The optional @samp{Date} field gives the release date of the current
version of the package.  It is strongly recommended to use the yyyy-mm-dd
format conforming to the ISO standard.

The optional @samp{Depends} field gives a comma-separated list of
package names which this package depends on.  The package name may be
optionally followed by a comparison operator (currently only @samp{>=}
and @samp{<=} are supported), whitespace and a valid version number in
parentheses.  (List package names even if they are part of a bundle.)
You can also use the special package name @samp{R} if your package
depends on a certain version of @R{}.  E.g., if the package works only with
@R{} version 2.4.0 or newer, include @samp{R (>= 2.4.0)} in the
@samp{Depends} field.  Both @code{library} and the @R{} package checking
facilities use this field, hence it is an error to use improper syntax
or misuse the @samp{Depends} field for comments on other software that
might be needed.  Other dependencies (external to the @R{} system)
should be listed in the @samp{SystemRequirements} field or a separate
@file{README} file.  The @R{} @command{INSTALL} facilities check if the
version of @R{} used is recent enough for the package being installed,
and the list of packages which is specified will be attached (after
checking version dependencies) before the current package, both when
@code{library} is called and when saving an image of the package's code
or preparing for lazy-loading.

The optional @samp{Imports} field lists packages whose name spaces are
imported from but which do not need to be attached.  Name spaces
accessed by the @samp{::} and @samp{:::} operators must be listed here,
or in @samp{Suggests} or @samp{Enhances} (see below).  Ideally this
field will include all the standard packages, and it is important to
include S4-using packages (as their class definitions can change and the
@file{DESCRIPTION} file is used to decide which packages to re-install
when this happens).

The optional @samp{Suggests} field uses the same syntax as
@samp{Depends} and lists packages that are not necessarily needed.  This
includes packages used only in examples or vignettes (@pxref{Writing
package vignettes}), and packages loaded in the body of functions.
E.g., suppose an example from package @pkg{foo} uses a dataset from
package @pkg{bar}. Then it is not necessary to have @pkg{bar} for
routine use of @pkg{foo}, unless one wants to execute the examples: it
is nice to have @pkg{bar}, but not necessary.

Finally, the optional @samp{Enhances} field lists packages ``enhanced''
by the package at hand, e.g., by providing methods for classes from
these packages.

The general rules are

@itemize @bullet
@item
Packages whose name space only is needed to load the package using
@code{library(@var{pkgname})} must be listed in the @samp{Imports}
field.
@item
Packages that need to be attached to successfully load the package using
@code{library(@var{pkgname})} must be listed in the @samp{Depends}
field.
@item
All packages that are needed to successfully run @code{R CMD check} on
the package must be listed in one of @samp{Depends} or @samp{Suggests}
or @samp{Imports}.
@end itemize

@noindent
In particular, large packages providing ``only'' data for examples or
vignettes should be listed in @samp{Suggests} rather than @samp{Depends}
in order to make lean installations possible.

The optional @samp{URL} field may give a list of @acronym{URL}s
separated by commas or whitespace, for example the homepage of the
author or a page where additional material describing the software can
be found.  These @acronym{URL}s are converted to active hyperlinks on
@acronym{CRAN}.

Base and recommended packages (i.e., packages contained in the @R{}
source distribution or available from @acronym{CRAN} and recommended to
be included in every binary distribution of @R{}) have a @samp{Priority}
field with value @samp{base} or @samp{recommended}, respectively.  These
priorities must not be used by ``other'' packages.

An optional @samp{Collate} field (or OS-specific variants
@samp{Collate.@var{OStype}}, such as e.g.@: @samp{Collate.windows}) can
be used for controlling the collation order for the @R{} code files in a
package when these are concatenated into a single file upon installation
from source.  The default is to try collating according to the @samp{C}
locale.  If present, the collate specification must list @emph{all} R
code files in the package (taking possible OS-specific subdirectories
into account, see @ref{Package subdirectories}) as a whitespace
separated list of file paths relative to the @file{R} subdirectory.
@c % double quotes are not allowed in path names, for Windows
Paths containing white space or quotes need to be quoted.  An applicable
OS-specific collation field (@samp{Collate.unix} or
@samp{Collate.windows}) will be used instead of @samp{Collate}.

The optional @samp{LazyLoad} and @samp{LazyData} fields control whether
the @R{} objects and the datasets (respectively) use lazy-loading: set
the field's value to @samp{yes} or @samp{true} for lazy-loading and
@samp{no} or @samp{false} for no lazy-loading.  (Capitalized values
are also accepted.)

If the package you are writing uses the @pkg{methods} package, specify
@samp{LazyLoad: yes}.

The optional @samp{ZipData} field controls whether the automatic
Windows build will zip up the data directory or no: set this to
@samp{no} if your package will not work with a zipped data directory.

If the @file{DESCRIPTION} file is not entirely in @acronym{ASCII} it
should contain an @samp{Encoding} field specifying an encoding.  This
is currently used as the encoding of the @file{DESCRIPTION} file
itself and of the @file{R} and @file{NAMESPACE} files, and is taken as
the default encoding of @file{.Rd} files as from @R{} 2.6.0.  Only
encoding names @code{latin1}, @code{latin2} and @code{UTF-8} are known
to be portable.  (Do not specify an encoding unless one is actually
needed: doing so makes the package @emph{less} portable.)


The optional @samp{Type} field specifies the type of the package:
@pxref{Package types}.

@quotation Note
There should be no @samp{Built} or @samp{Packaged} fields, as these are
added by the package management tools.
@end quotation


@node The INDEX file, Package subdirectories, The DESCRIPTION file, Package structure
@subsection The @file{INDEX} file
@cindex INDEX file

The optional file @file{INDEX} contains a line for each sufficiently
interesting object in the package, giving its name and a description
(functions such as print methods not usually called explicitly might not
be included).  Normally this file is missing, and the corresponding
information is automatically generated from the documentation sources
(using @code{Rdindex()} from package @pkg{tools}) when installing from
source and when using the package builder (@pxref{Checking and building
packages}).

Rather than editing this file, it is preferable to put customized
information about the package into an overview man page
(@pxref{Documenting packages}) and/or a vignette (@pxref{Writing package
vignettes}).

@node Package subdirectories, Package bundles, The INDEX file, Package structure
@subsection Package subdirectories
@cindex Package subdirectories

The @file{R} subdirectory contains @R{} code files, only.  The code
files to be installed must start with a (lower or upper case) letter or
digit and have one of the extensions @file{.R}, @file{.S}, @file{.q},
@file{.r}, or @file{.s}.  We recommend using @file{.R}, as this
extension seems to be not used by any other software.  It should be
possible to read in the files using @code{source()}, so @R{} objects
must be created by assignments.  Note that there need be no connection
between the name of the file and the R objects created by it.  The @R{}
code files should only create @R{} objects and not call functions with
side effects such as @code{require} and @code{options}.

Two exceptions are allowed: if the @file{R} subdirectory contains a file
@file{sysdata.rda} (a saved image of @R{} objects) this will be
lazy-loaded into the name space/package environment -- this is intended
for system datasets that are not intended to be user-accessible via
@code{data}.  Also, files ending in @samp{.in} will be allowed in the
@file{R} directory to allow a @file{configure} script to generate
suitable files,

Only @acronym{ASCII} characters (and the control characters tab,
formfeed, LF and CR) should be used in code files.  Other characters are
accepted in comments, but then the comments may not be readable in
e.g.@: a UTF-8 locale.  Non-@acronym{ASCII} characters in object names
will normally@footnote{This is true for OSes which implement the
@samp{C} locale, unless neither lazy-loading nor saving an image are
used, in which case it would fail if loaded in a @samp{C}
locale. (Windows' idea of the @samp{C} locale uses the WinAnsi
charset.)} fail when the package is installed.  Any byte will be
allowed@footnote{It is good practice to encode them as octal or hex
escape sequences.} in a quoted character string (but @code{\uxxxx}
escapes should not be used), but non-@acronym{ASCII} character strings
may not be usable in some locales and may display incorrectly in others.


@findex .First.lib
@findex .Last.lib
@findex library.dynam
Various @R{} functions in a package can be used to initialize and clean
up.  For packages without a name space, these are @code{.First.lib} and
@code{.Last.lib}.  (@xref{Load hooks}, for packages with a name space.)
It is conventional to define these functions in a file called
@file{zzz.R}.  If @code{.First.lib} is defined in a package, it is
called with arguments @code{libname} and @code{pkgname} after the
package is loaded and attached.  (If a package is installed with version
information, the package name includes the version information, e.g.@:
@samp{ash_1.0.9}.)  A common use is to call @code{library.dynam}
inside @code{.First.lib} to load compiled code: another use is to call
those functions with side effects.  If @code{.Last.lib} exists in a
package it is called (with argument the full path to the installed
package) just before the package is detached.  It is uncommon to detach
packages and rare to have a @code{.Last.lib} function: one use is to
call @code{library.dynam.unload} to unload compiled code.


The @file{man} subdirectory should contain (only) documentation files
for the objects in the package in @dfn{R documentation} (Rd) format.
The documentation files to be installed must start with a (lower or
upper case @acronym{ASCII}) letter or digit and have the extension
@file{.Rd} (the default) or @file{.rd}.  Further, the names must be
valid in @samp{file://} URLs, which means@footnote{More precisely, they
can contain the English alphanumeric characters and the symbols @samp{$
- _ . + ! ' ( ) , ; @ = &}.}  they must be entirely @acronym{ASCII} and
not contain @samp{%}.  @xref{Writing R documentation files}, for more
information.  Note that all user-level objects in a package should be
documented; if a package @var{pkg} contains user-level objects which are
for ``internal'' use only, it should provide a file
@file{@var{pkg}-internal.Rd} which documents all such objects, and
clearly states that these are not meant to be called by the user.  See
e.g.@: the sources for package @pkg{grid} in the @R{} distribution for
an example.  Note that packages which use internal objects extensively
should hide those objects in a name space, when they do not need to be
documented (@pxref{Package name spaces}).

The @file{R} and @file{man} subdirectories may contain OS-specific
subdirectories named @file{unix} or @file{windows}.

The sources and headers for the compiled code are in @file{src}, plus
optionally file @file{Makevars} or @file{Makefile}.  When a package is
installed using @code{R CMD INSTALL}, Make is used to control
compilation and linking into a shared object for loading into @R{}.
There are default variables and rules for this (determined when @R{} is
configured and recorded in @file{@var{R_HOME}/etc/Makeconf}), providing
support for C, C++, FORTRAN 77, Fortran 9x@footnote{Note that Ratfor is
not supported.  If you have Ratfor source code, you need to convert it
to FORTRAN.  Only FORTRAN-77 (which we write in upper case) is supported
on all platforms, but some also support Fortran-95 (for which we use
title case).  If you want to ship Ratfor source files, please do so in a
subdirectory of @file{src} and not in the main subdirectory.}, Objective
C and Objective C++ with associated extensions @file{.c}, @file{.cc} or
@file{.cpp} or @file{.C}, @file{.f}, @file{.f90} or @file{.f95},
@file{.m}, and @file{.mm} or @file{.M}, respectively.  We recommend
using @file{.h} for headers, also for C++@footnote{Using @file{.hpp},
although somewhat popular, is not guaranteed to be portable.} or Fortran
9x include files.  The default rules can be tweaked by setting macros in
a file @file{src/Makevars} (@pxref{Using Makevars}).  Note that this
mechanism should be general enough to eliminate the need for a
package-specific @file{src/Makefile}.  If such a file is to be
distributed, considerable care is needed to make it general enough to
work on all @R{} platforms.  It should have a target @code{all:}. In
addition, it should have a (possibly empty) target @samp{clean} which
removes all files generated by Make (to be used by @samp{R CMD INSTALL
--clean} and @samp{R CMD INSTALL --preclean}).  If necessary,
platform-specific files can be used, for example @file{src/Makevars.win}
or @file{src/Makefile.win} on Windows take precedence over
@file{src/Makevars} or @file{src/Makefile}.

The @file{data} subdirectory is for additional data files the package
makes available for loading using @code{data()}.  Currently, data files
can have one of three types as indicated by their extension: plain R
code (@file{.R} or @file{.r}), tables (@file{.tab}, @file{.txt}, or
@file{.csv}), or @code{save()} images (@file{.RData} or @file{.rda}).
(All ports of @R{} use the same binary (XDR) format and can read
compressed images.  Use images saved with @code{save(, compress =
TRUE)}, the default, to save space.)  Note that R code should be
``self-sufficient'' and not make use of extra functionality provided by
the package, so that the data file can also be used without having to
load the package.  It is no longer necessary to provide a @file{00Index}
file in the @file{data} directory---the corresponding information is
generated automatically from the documentation sources when installing
from source, or when using the package builder (@pxref{Checking and
building packages}).  If your data files are enormous you can speed up
installation by providing a file @file{datalist} in the @file{data}
subdirectory.  This should have one line per topic that @code{data()}
will find, in the format @samp{foo} if @code{data(foo)} provides
@samp{foo}, or @samp{foo: bar bah} if @code{data(foo)} provides
@samp{bar} and @samp{bah}.

The @file{demo} subdirectory is for @R{} scripts (for running via
@code{demo()}) that demonstrate some of the functionality of the
package.  Demos may be interactive and are not checked automatically, so
if testing is desired use code in the @file{tests} directory.  The
script files must start with a (lower or upper case) letter and have one
of the extensions @file{.R} or @file{.r}.  If present, the @file{demo}
subdirectory should also have a @file{00Index} file with one line for
each demo, giving its name and a description separated by white
space. (Note that it is not possible to generate this index file
automatically.)

The contents of the @file{inst} subdirectory will be copied recursively
to the installation directory.  Subdirectories of @file{inst} should not
interfere with those used by @R{} (currently, @file{R}, @file{data},
@file{demo}, @file{exec}, @file{libs}, @file{man}, @file{help},
@file{html}, @file{latex}, @file{R-ex}, @file{chtml}, and @file{Meta}).
The copying of the @file{inst} happens after @file{src} is built so its
@file{Makefile} can create files to be installed.  Note that with the
exceptions of @file{INDEX} and @file{COPYING}, information files at the
top level of the package will @emph{not} be installed and so not be
known to users of Windows and MacOS X compiled packages (and not seen by
those who use @command{R CMD INSTALL} or @command{install.packages} on
the tarball).  So any information files you wish an end user to see
should be included in @file{inst}.  One thing you might like to add to
@file{inst} is a @file{CITATION} file for use by the @code{citation}
function.

Subdirectory @file{tests} is for additional package-specific test code,
similar to the specific tests that come with the @R{} distribution.
Test code can either be provided directly in a @file{.R} file, or via a
@file{.Rin} file containing code which in turn creates the corresponding
@file{.R} file (e.g., by collecting all function objects in the package
and then calling them with the strangest arguments).  The results of
running a @file{.R} file are written to a @file{.Rout} file.  If there
is a corresponding @file{.Rout.save} file, these two are compared, with
differences being reported but not causing an error.  The directory
@file{tests} is copied to the check area, and the tests are run with the
copy as the working directory and with @code{R_LIBS} set to ensure that
the copy of the package installed during testing will be found by
@code{library(@var{pkg_name})}.

Subdirectory @file{exec} could contain additional executables the package
needs, typically scripts for interpreters such as the shell, Perl, or
Tcl.  This mechanism is currently used only by a very few packages, and
still experimental.

Subdirectory @file{po} is used for files related to @emph{localization}:
@pxref{Internationalization}.

@node  Package bundles,  , Package subdirectories, Package structure
@subsection Package bundles
@cindex Package bundles

Sometimes it is convenient to distribute several packages as a
@emph{bundle}.  (An example is @pkg{VR} which contains four packages.)
The installation procedures on both Unix-alikes and Windows can handle
package bundles.

The @file{DESCRIPTION} file of a bundle has a @samp{Bundle}
field and no @samp{Package} field, as in

@quotation
@cartouche
@smallexample
Bundle: VR
Priority: recommended
Contains: MASS class nnet spatial
Version: 7.2-12
Date: 2005-01-31
Depends: R (>= 2.0.0), graphics, stats
Suggests: lattice, nlme, survival
Author: S original by Venables & Ripley.
  R port by Brian Ripley <ripley@@stats.ox.ac.uk>, following earlier
  work by Kurt Hornik and Albrecht Gebhardt.
Maintainer: Brian Ripley <ripley@@stats.ox.ac.uk>
BundleDescription: Functions and datasets to support Venables and
  Ripley, `Modern Applied Statistics with S' (4th edition).
License: GPL (version 2 or later)  See file LICENCE.
URL: http://www.stats.ox.ac.uk/pub/MASS4/
@end smallexample
@end cartouche
@end quotation

The @samp{Contains} field lists the packages (space separated), which
should be contained in separate subdirectories with the names given.
During building and installation, packages will be installed in the
order specified.  Be sure to order this list so that dependencies are
met appropriately.

The packages contained in a bundle are standard packages in all
respects except that the @file{DESCRIPTION} file is replaced by a
@file{DESCRIPTION.in} file which just contains fields additional to
the @file{DESCRIPTION} file of the bundle, for example

@quotation
@cartouche
@smallexample
Package: spatial
Description: Functions for kriging and point pattern analysis.
Title: Functions for Kriging and Point Pattern Analysis
@end smallexample
@end cartouche
@end quotation

Any files in the package bundle except the @file{DESCRIPTION} file and
the named packages will be ignored.

The @samp{Depends} field in the bundle's @file{DESCRIPTION} file should
list the dependencies of all the constituent packages (and similarly for
@samp{Imports} and @samp{Suggests}), and then @file{DESCRIPTION.in}
files should not contain these fields.

@node Configure and cleanup, Checking and building packages, Package structure, Creating R packages
@section Configure and cleanup

Note that most of this section is Unix-specific: see the comments
later on about the Windows port of @R{}.

If your package needs some system-dependent configuration before
installation you can include a (Bourne shell) script @file{configure} in
your package which (if present) is executed by @code{R CMD INSTALL}
before any other action is performed.  This can be a script created by
the Autoconf mechanism, but may also be a script written by yourself.
Use this to detect if any nonstandard libraries are present such that
corresponding code in the package can be disabled at install time rather
than giving error messages when the package is compiled or used.  To
summarize, the full power of Autoconf is available for your extension
package (including variable substitution, searching for libraries,
etc.).

The (Bourne shell) script @file{cleanup} is executed as last thing by
@code{R CMD INSTALL} if present and option @option{--clean} was given,
and by @code{R CMD build} when preparing the package for building from
its source.  It can be used to clean up the package source tree.  In
particular, it should remove all files created by @command{configure}.

As an example consider we want to use functionality provided by a (C or
FORTRAN) library @code{foo}.  Using Autoconf, we can create a configure
script which checks for the library, sets variable @code{HAVE_FOO} to
@code{TRUE} if it was found and with @code{FALSE} otherwise, and then
substitutes this value into output files (by replacing instances of
@samp{@@HAVE_FOO@@} in input files with the value of @code{HAVE_FOO}).
For example, if a function named @code{bar} is to be made available by
linking against library @code{foo} (i.e., using @option{-lfoo}), one
could use

@example
@group
AC_CHECK_LIB(foo, @var{fun}, [HAVE_FOO=TRUE], [HAVE_FOO=FALSE])
AC_SUBST(HAVE_FOO)
......
AC_CONFIG_FILES([foo.R])
AC_OUTPUT
@end group
@end example

@noindent
in @file{configure.ac} (assuming Autoconf 2.50 or better).

The definition of the respective @R{} function in @file{foo.R.in} could be

@example
@group
foo <- function(x) @{
    if(!@@HAVE_FOO@@)
      stop("Sorry, library 'foo' is not available"))
    ...
@end group
@end example

@noindent
From this file @command{configure} creates the actual @R{} source file
@file{foo.R} looking like

@example
@group
foo <- function(x) @{
    if(!FALSE)
      stop("Sorry, library 'foo' is not available"))
    ...
@end group
@end example

@noindent
if library @code{foo} was not found (with the desired functionality).
In this case, the above @R{} code effectively disables the function.

One could also use different file fragments for available and missing
functionality, respectively.

You will very likely need to ensure that the same C compiler and
compiler flags are used in the @file{configure} tests as when compiling
@R{} or your package.  Under Unix, you can achieve this by including the
following fragment early in @file{configure.ac}

@example
@group
: $@{R_HOME=`R RHOME`@}
if test -z "$@{R_HOME@}"; then
  echo "could not determine R_HOME"
  exit 1
fi
CC=`"$@{R_HOME@}/bin/R" CMD config CC`
CFLAGS=`"$@{R_HOME@}/bin/R" CMD config CFLAGS`
CPPFLAGS=`"$@{R_HOME@}/bin/R" CMD config CPPFLAGS`
@end group
@end example

@noindent
(using @samp{$@{R_HOME@}/bin/R} rather than just @samp{R} is necessary
in order to use the `right' version of @R{} when running the script as
part of @code{R CMD INSTALL}.)

@findex R CMD config
Note that earlier versions of this document recommended obtaining the
configure information by direct extraction (using grep and sed) from
@file{@var{R_HOME}/etc/Makeconf}, which only works for variables
recorded there as literals.  You can use @code{R CMD config} for getting
the value of the basic configuration variables, or the header and
library flags necessary for linking against @R{}, see @kbd{R CMD config
--help} for details.

To check for an external BLAS library using the @code{ACX_BLAS} macro
from the official Autoconf Macro Archive, one can simply do

@example
@group
F77=`"$@{R_HOME@}/bin/R" CMD config F77`
AC_PROG_F77
FLIBS=`"$@{R_HOME@}/bin/R" CMD config FLIBS`
ACX_BLAS([], AC_MSG_ERROR([could not find your BLAS library], 1))
@end group
@end example

Note that @code{FLIBS} as determined by @R{} must be used to ensure that
FORTRAN 77 code works on all @R{} platforms.  Calls to the Autoconf macro
@code{AC_F77_LIBRARY_LDFLAGS}, which would overwrite @code{FLIBS}, must
not be used (and hence e.g.@: removed from @code{ACX_BLAS}).  (Recent
versions of Autoconf in fact allow an already set @code{FLIBS} to
override the test for the FORTRAN linker flags.  Also, recent versions
of @R{} can detect external BLAS and LAPACK libraries.)

You should bear in mind that the configure script may well not work on
Windows systems (this seems normally to be the case for those generated
by Autoconf, although simple shell scripts do work).  If your package is
to be made publicly available, please give enough information for a user
on a non-Unix platform to configure it manually, or provide a
@file{configure.win} script to be used on that platform.  (Optionally,
there can be a @file{cleanup.win} script as well.  Both should be shell
scripts, to be executed by @command{ash}, which is a minimal version of
@command{sh}.)

In some rare circumstances, the configuration and cleanup scripts need
to know the location into which the package is being installed.  An
example of this is a package that uses C code and creates two shared
object/DLLs.  Usually, the object that is dynamically loaded by @R{}
is linked against the second, dependent, object.  On some systems, we
can add the location of this dependent object to the object that is
dynamically loaded by @R{}.  This means that each user does not have to
set the value of the @env{LD_LIBRARY_PATH} (or equivalent) environment
variable, but that the secondary object is automatically resolved.
Another example is when a package installs support files that are
required at run time, and their location is substituted into an @R{}
data structure at installation time. (This happens with the Java Archive
files in the @pkg{SJava} package.)
@vindex R_LIBRARY_DIR
@vindex R_PACKAGE_DIR
The names of the top-level library directory (i.e., specifiable via the
@samp{-l} argument) and the directory of the package itself are made
available to the installation scripts via the two shell/environment
variables @env{R_LIBRARY_DIR} and @env{R_PACKAGE_DIR}.  Additionally,
the name of the package (e.g., @samp{survival} or @samp{MASS}) being
installed is available from the shell variable @env{R_PACKAGE_NAME}.

@menu
* Using Makevars::              
* Configure example::           
* Using F95 code::              
@end menu

@node Using Makevars, Configure example, Configure and cleanup, Configure and cleanup
@subsection Using @file{Makevars}

Sometimes writing your own @file{configure} script can be avoided by
supplying a file @file{Makevars}: also one of the most common uses of a
@file{configure} script is to make @file{Makevars} from
@file{Makevars.in}.

The most common use of a @file{Makevars} file is to set additional
preprocessor (for example include paths) flags via @code{PKG_CPPFLAGS},
and additional compiler flags by setting @code{PKG_CFLAGS},
@code{PKG_CXXFLAGS} and @code{PKG_FFLAGS}, for C, C++, or FORTRAN
respectively (@pxref{Creating shared objects}).

Also, @file{Makevars} can be used to set flags for the linker, for
example @samp{-L} and @samp{-l} options.

When writing a @file{Makevars} file for a package you intend to
distribute, take care to ensure that it is not specific to your
compiler: flags such as @option{-O2 -Wall -pedantic} are all specific to
GCC.

There are some macros which are built whilst configuring the building of
@R{} itself, are stored on Unix-alikes in
@file{@var{R_HOME}/etc/Makeconf} and can be used in @file{Makevars}.
These include

@table @code
@item FLIBS
@vindex FLIBS
A macro containing the set of libraries need to link FORTRAN code.  This
may need to be included in @code{PKG_LIBS}.

@item BLAS_LIBS
@vindex BLAS_LIBS
A macro containing the BLAS libraries used when building @R{}.  This may
need to be included in @code{PKG_LIBS}.  Beware that if it is empty then
the @R{} executable will contain all the double-precision and
double-complex BLAS routines, but no single-precision or complex
routines.  If @code{BLAS_LIBS} is included, then @code{FLIBS} also needs
to be@footnote{on Unix-alikes: Windows resolves such dependencies at
link time.}, as most BLAS libraries are written in FORTRAN.

@item LAPACK_LIBS
@vindex LAPACK_LIBS
A macro containing the LAPACK libraries (and paths where appropriate)
used when building @R{}.  This may need to be included in
@code{PKG_LIBS}.  This may point to a dynamic library @code{libRlapack}
which contains all the double-precision LAPACK routines as well as those
double-complex LAPACK and BLAS routines needed to build @R{}, or it
may point to an external LAPACK library, or may be empty if an external
BLAS library also contains LAPACK.

[There is no guarantee that the LAPACK library will provide more than
all the double-precision and double-complex routines, and some do not
provide all the auxiliary routines.]

The macros @code{BLAS_LIBS} and @code{FLIBS} should always be included
@emph{after} @code{LAPACK_LIBS}.

@item SAFE_FFLAGS
@vindex SAFE_FFLAGS
A macro containing flags which are needed to circumvent
over-optimization of Fortran code: it is typically @samp{-g -O2 
-ffloat-store} on @cputype{ix86} platforms using @command{g77} or
@command{gfortran}.
@end table

Note that @file{Makevars} should not normally contain targets, as it is
included before the default @file{Makefile} and @command{make} is called
without an explicit target.  To circumvent that, use a suitable phony
target before any actual targets: for example @pkg{fastICA} has

@smallexample
SLAMC_FFLAGS=$(R_XTRA_FFLAGS) $(FPICFLAGS) $(SHLIB_FFLAGS) $(SAFE_FFLAGS)

all: $(SHLIB)

slamc.o: slamc.f
        $(F77) $(SLAMC_FFLAGS) -c -o slamc.o slamc.f
@end smallexample

@noindent
to ensure that the LAPACK routines find some constants without infinite
looping.


@node Configure example, Using F95 code, Using Makevars, Configure and cleanup
@subsection Configure example

It may be helpful to give an extended example of using a
@file{configure} script to create a @file{src/Makevars} file: this is
based on that in the @pkg{RODBC} package.

The @file{configure.ac} file follows: @file{configure} is created from
this by running @command{autoconf} in the top-level package directory
(containing @file{configure.ac}).

@quotation
@c @cartouche
@smallexample
AC_INIT([RODBC], 1.1.8) dnl package name, version

dnl A user-specifiable option
odbc_mgr=""
AC_ARG_WITH([odbc-manager],
            AC_HELP_STRING([--with-odbc-manager=MGR],
                           [specify the ODBC manager, e.g. odbc or iodbc]),
            [odbc_mgr=$withval])

if test "$odbc_mgr" = "odbc" ; then
  AC_PATH_PROGS(ODBC_CONFIG, odbc_config)
fi

dnl Select an optional include path, from a configure option
dnl or from an environment variable.
AC_ARG_WITH([odbc-include],
            AC_HELP_STRING([--with-odbc-include=INCLUDE_PATH],
                           [the location of ODBC header files]),
            [odbc_include_path=$withval])
RODBC_CPPFLAGS="-I."
if test [ -n "$odbc_include_path" ] ; then
   RODBC_CPPFLAGS="-I. -I$@{odbc_include_path@}"
else
  if test [ -n "$@{ODBC_INCLUDE@}" ] ; then
     RODBC_CPPFLAGS="-I. -I$@{ODBC_INCLUDE@}"
  fi
fi

dnl ditto for a library path
AC_ARG_WITH([odbc-lib],
            AC_HELP_STRING([--with-odbc-lib=LIB_PATH],
                           [the location of ODBC libraries]),
            [odbc_lib_path=$withval])
if test [ -n "$odbc_lib_path" ] ; then
   LIBS="-L$odbc_lib_path $@{LIBS@}"
else 
  if test [ -n "$@{ODBC_LIBS@}" ] ; then
     LIBS="-L$@{ODBC_LIBS@} $@{LIBS@}"
  else
    if test -n "$@{ODBC_CONFIG@}"; then
      odbc_lib_path=`odbc_config --libs | sed s/-lodbc//`
      LIBS="$@{odbc_lib_path@} $@{LIBS@}"
    fi
  fi
fi

dnl Now find the compiler and compiler flags to use
: $@{R_HOME=`R RHOME`@}
if test -z "$@{R_HOME@}"; then
  echo "could not determine R_HOME"
  exit 1
fi
CC=`"$@{R_HOME@}/bin/R" CMD config CC`
CPP=`"$@{R_HOME@}/bin/R" CMD config CPP`
CFLAGS=`"$@{R_HOME@}/bin/R" CMD config CFLAGS`
CPPFLAGS=`"$@{R_HOME@}/bin/R" CMD config CPPFLAGS`
AC_PROG_CC
AC_PROG_CPP


if test -n "$@{ODBC_CONFIG@}"; then
  RODBC_CPPFLAGS=`odbc_config --cflags`
fi
CPPFLAGS="$@{CPPFLAGS@} $@{RODBC_CPPFLAGS@}"

dnl Check the headers can be found
AC_CHECK_HEADERS(sql.h sqlext.h)
if test "$@{ac_cv_header_sql_h@}" = no ||
   test "$@{ac_cv_header_sqlext_h@}" = no; then
   AC_MSG_ERROR("ODBC headers sql.h and sqlext.h not found")
fi

dnl search for a library containing an ODBC function
if test [ -n "$@{odbc_mgr@}" ] ; then
  AC_SEARCH_LIBS(SQLTables, $@{odbc_mgr@}, ,
      AC_MSG_ERROR("ODBC driver manager $@{odbc_mgr@} not found"))
else
  AC_SEARCH_LIBS(SQLTables, odbc odbc32 iodbc, ,
      AC_MSG_ERROR("no ODBC driver manager found"))
fi

dnl for 64-bit ODBC need SQL[U]LEN, and it is unclear where they are defined.
AC_CHECK_TYPES([SQLLEN, SQLULEN], , , [# include <sql.h>])
dnl for unixODBC header
AC_CHECK_SIZEOF(long, 4)

dnl substitute RODBC_CPPFLAGS and LIBS
AC_SUBST(RODBC_CPPFLAGS)
AC_SUBST(LIBS)
AC_CONFIG_HEADERS([src/config.h])
dnl and do substitution in the src/Makevars.in and src/config.h
AC_CONFIG_FILES([src/Makevars])
AC_OUTPUT
@end smallexample
@c @end cartouche
@end quotation

@noindent
where @file{src/Makevars.in} would be simply

@quotation
@example
PKG_CPPFLAGS = @@RODBC_CPPFLAGS@@
PKG_LIBS = @@LIBS@@
@end example
@end quotation

A user can then be advised to specify the location of the ODBC driver
manager files by options like (lines broken for easier reading)

@example
R CMD INSTALL
  --configure-args='--with-odbc-include=/opt/local/include
  --with-odbc-lib=/opt/local/lib --with-odbc-manager=iodbc'
  RODBC
@end example

@noindent
or by setting the environment variables @code{ODBC_INCLUDE} and
@code{ODBC_LIBS}.

@node Using F95 code,  , Configure example, Configure and cleanup
@subsection Using F95 code

@R{} currently does not distinguish between FORTRAN 77 and Fortran 90/95
code, and assumes all FORTRAN comes in source files with extension
@file{.f}.  Commercial Unix systems typically use a F95 compiler, but
only since the release of @code{gcc 4.0.0} in April 2005 have Linux and
other non-commercial OSes had much support for F95.  The compiler used
for @R{} on Windows is a F77 compiler.

This means that portable packages need to be written in correct
FORTRAN 77, which will also be valid Fortran 95.  See
@uref{http://developer.r-project.org/Portability.html} for reference
resources.  In particular, @emph{free source form} F95 code is not
portable.

On some systems an alternative F95 compiler is available: from the
@code{gcc} family this might be @command{gfortran} or @command{g95}.
Configuring @R{} will try to find a compiler which (from its name)
appears to be a Fortran 90/95 compiler, and set it in macro @samp{FC}.
Note that it does not check that such a compiler is fully (or even
partially) compliant with Fortran 90/95.  Packages making use of
Fortran 90/95 features should use file extension @file{.f90} or
@file{.f95} for the source files: the variable @code{PKG_FCFLAGS}
specifies any special flags to be used.  There is no guarantee that
compiled Fortran 90/95 code can be mixed with any other type of code,
nor that a build of @R{} will have support for such packages.

MinGW huilds of @command{gcc} @code{4.2.0} or later include a F95
compiler.  For those using @command{gcc} @code{3.4.z}, there is a MinGW
build of @command{gfortran} available from
@url{http://@/gcc.gnu.org/@/wiki/@/GFortranBinaries} and a MinGW
build@footnote{Remember to set @env{LIBRARY_PATH} to point to your MinGW
@file{lib} directory} of @command{g95} from @uref{http://www.g95.org}.
Set @code{F95} in @code{MkRules} to point to the installed compiler.
Then @command{R CMD SHLIB} and @command{R CMD INSTALL} will work for
packages containing Fortran 90/95 source code.

@node Checking and building packages, Writing package vignettes, Configure and cleanup, Creating R packages
@section Checking and building packages

Before using these tools, please check that your package can be
installed and loaded.  @code{R CMD check} will @emph{inter alia} do
this, but you will get more informative error messages doing the checks
directly.

@menu
* Checking packages::           
* Building packages::           
* Customizing checking and building::  
@end menu

@node Checking packages, Building packages, Checking and building packages, Checking and building packages
@subsection Checking packages
@cindex Checking packages

@findex R CMD check
Using @code{R CMD check}, the @R{} package checker, one can test whether
@emph{source} @R{} packages work correctly.  It can be run on one or
more directories, or gzipped package @command{tar}
archives@footnote{This may require GNU @command{tar}: the command used
can be set with environment variable @env{TAR}.}  with extension
@file{.tar.gz} or @file{.tgz}.  This runs a series of checks, including

@enumerate
@item
The package is installed.  This will warn about missing cross-references
and duplicate aliases in help files.

@item
The file names are checked to be valid across file systems and supported
operating system platforms.

@item
The files and directories are checked for sufficient permissions (Unix
only).

@item
The @file{DESCRIPTION} file is checked for completeness, and some of its
entries for correctness.  Unless installation tests are skipped,
checking is aborted if the package dependencies cannot be resolved at
run time.  One check is that the package name is not that of a standard
package, nor of the defunct standard packages (@samp{ctest}, @samp{eda},
@samp{lqs}, @samp{mle}, @samp{modreg}, @samp{mva}, @samp{nls},
@samp{stepfun} and @samp{ts}) which are handled specially by
@code{library}.  Another check is that all packages mentioned in
@code{library} or @code{requires} or from which the @file{NAMESPACE}
file imports or are called @emph{via} @code{::} or @code{:::} are listed
(in @samp{Depends}, @samp{Imports}, @samp{Suggests} or @samp{Contains}):
this is not an exhaustive check of the actual imports.

@item
Available index information (in particular, for demos and vignettes) is
checked for completeness.

@item
The package subdirectories are checked for suitable file names and for
not being empty.  The checks on file names are controlled by the option
@option{--check-subdirs=@var{value}}.  This defaults to @samp{default},
which runs the checks only if checking a tarball: the default can be
overridden by specifying the value as @samp{yes} or @samp{no}.  Further,
the check on the @file{src} directory is only run if the package/bundle
does not contain a @file{configure} script (which corresponds to the
value @samp{yes-maybe}) and there is no @file{src/Makefile} or
@file{src/Makefile.in}.

To allow a @file{configure} script to generate suitable files, files
ending in @samp{.in} will be allowed in the @file{R} directory.

@item
The @R{} files are checked for syntax errors.  Bytes which are
non-@acronym{ASCII} are reported as warnings, but these should be
regarded as errors unless it is known that the package will always be
used in the same locale.

@item
It is checked that the package can be loaded, first with the usual
default packages and then only with package @pkg{base} already
loaded. If the package has a namespace, it is checked if this can be
loaded in an empty session with only the @pkg{base} namespace loaded.
(Namespaces and packages can be loaded very early in the session, before
the default packages are available, so packages should work then.)

@item
The @R{} files are checked for correct calls to @code{library.dynam} (with
no extension).  In addition, it is checked whether methods have all
arguments of the corresponding generic, and whether the final argument
of replacement functions is called @samp{value}.  All foreign function
calls (@code{.C}, @code{.Fortran}, @code{.Call} and @code{.External}
calls) are tested to see if they have a @code{PACKAGE} argument, and if
not, whether the appropriate DLL might be deduced from the name space of
the package.  Any other calls are reported.  (The check is generous, and
users may want to supplement this by examining the output of
@code{tools::checkFF("mypkg", verbose=TRUE)}, especially if the
intention were to always use a @code{PACKAGE} argument)

@item
The Rd files are checked for correct syntax and meta data, including the
presence of the mandatory (@code{\name}, @code{\alias}, @code{\title},
@code{\description} and @code{\keyword}) fields.  The Rd name and title
are checked for being non-empty, and the keywords found are compared to
the standard ones.  There is a check for missing cross-references
(links).

@item
A check is made for missing documentation entries, such as undocumented
user-level objects in the package.

@item
Documentation for functions, data sets, and S4 classes is checked for
consistency with the corresponding code.

@item
It is checked whether all function arguments given in @code{\usage}
sections of Rd files are documented in the corresponding
@code{\arguments} section.

@item
C, C++ and FORTRAN source and header files are tested for portable
(LF-only) line endings.  If there is a @file{Makefile} or
@file{Makefile.in} or @file{Makevars} or @file{Makevars.in} in the
@file{src} directory, it is checked for correct use of
@samp{$(BLAS_LIBS)}.

@item
The examples provided by the package's documentation are run.
(@pxref{Writing R documentation files}, for information on using
@code{\examples} to create executable example code.)

Of course, released packages should be able to run at least their own
examples.  Each example is run in a `clean' environment (so earlier
examples cannot be assumed to have been run), and with the variables
@code{T} and @code{F} redefined to generate an error unless they are set
in the example: @xref{Logical vectors, , Logical vectors, R-intro, An
Introduction to R}.

@item
If the package sources contain a @file{tests} directory then the tests
specified in that directory are run.  (Typically they will consist of a
set of @file{.R} source files and target output files
@file{.Rout.save}.)

@item
The code in package vignettes (@pxref{Writing package vignettes}) is
executed.

@item
If a working @command{latex} program is available, the @file{.dvi}
version of the package's manual is created (to check that the Rd files
can be converted successfully).
@end enumerate

Use @kbd{R CMD check --help} to obtain more information about the usage
of the @R{} package checker.  A subset of the checking steps can be
selected by adding flags.

@node Building packages, Customizing checking and building, Checking packages, Checking and building packages
@subsection Building packages
@cindex Building packages

@findex R CMD build
@cindex Package builder
Using @code{R CMD build}, the @R{} package builder, one can build R
packages from their sources (for example, for subsequent release).

Prior to actually building the package in the common gzipped tar file
format, a few diagnostic checks and cleanups are performed.  In
particular, it is tested whether object indices exist and can be assumed
to be up-to-date, and C, C++ and FORTRAN source files are tested and
converted to LF line-endings if necessary.

Run-time checks whether the package works correctly should be performed
using @code{R CMD check} prior to invoking the build procedure.

To exclude files from being put into the package, one can specify a list
of exclude patterns in file @file{.Rbuildignore} in the top-level source
directory.  These patterns should be Perl regexps, one per line, to be
matched against the file names relative to the top-level source
directory.  In addition, directories called @file{CVS} or @file{.svn} or
@file{.arch-ids} and files @file{GNUMakefile} or with base names
starting with @samp{.#}, or starting and ending with @samp{#}, or ending
in @samp{~}, @samp{.bak} or @samp{.swp}, are excluded by default.  In
addition, those files in the @file{R}, @file{demo} and @file{man}
directories which are flagged by @code{R CMD check} as having invalid
names will be excluded.

@c <FIXME>
@c From 1.8.0 on, the build code removes exclude files itself, rather
@c than relying on tar for doing do, when building *source* packages.
@c @quotation Note
@c File exclusion does not work correctly with @acronym{GNU}
@c @code{tar} 1.13 but does work with later versions (e.g., version
@c 1.13.17).
@c @end quotation

Use @kbd{R CMD build --help} to obtain more information about the usage
of the @R{} package builder.

Unless @kbd{R CMD build} is invoked with the @option{--no-vignettes}
option, it will attempt to rebuild the vignettes (@pxref{Writing package
vignettes}) in the package.  To do so it installs the current
package/bundle into a temporary library tree, but any dependent packages
need to be installed in an available library tree (see the Note: below).

One of the checks that @code{R CMD build} runs is for empty source
directories.  These are in most cases unintentional, in which case they
should be removed and the build re-run.

It can be useful to run @code{R CMD check --check-subdirs=yes} on the
built tarball as a final check on the contents.

@code{R CMD build} can also build pre-compiled version of packages for
binary distributions, but @code{R CMD INSTALL --build} is preferred (and
is considerably more flexible).  In particular, Windows users are
recommended to use @code{R CMD INSTALL --build} and install into the
main library tree (the default) so that @HTML{} links are resolved.

@quotation Note
@code{R CMD check} and @code{R CMD build} run @R{} with
@option{--vanilla}, so none of the user's startup files are read.  If
you need @env{R_LIBS} set (to find packages in a non-standard library)
you will need to set it in the environment.
@end quotation

@quotation Note to Windows users
@code{R CMD check} and @code{R CMD build} work well under Windows
NT4/2000/XP/2003 but may not work correctly on Windows 95/98/ME because
of problems with some versions of Perl on those limited OSes.
Experiences vary.  To use them you will need to have installed the files
for building source packages (which is the default).
@end quotation

@node Customizing checking and building,  , Building packages, Checking and building packages
@subsection Customizing checking and building

In addition to the available command line options, @code{R CMD check}
also allows customization by setting (Perl) configuration variables in a
configuration file, the location of which can be specified via the
@option{--rcfile} option and defaults to @file{$HOME/.R/check.conf}
provided that the environment variable @env{HOME} is set.

The following configuration variables are currently available.

@table @code
@item $R_check_use_install_log
If true, record the output from installing a package as part of its
check to a log file (@file{00install.out} by default), even when running
interactively.
Default: true.
@item $R_check_all_non_ISO_C
If true, do not ignore compiler (typically GCC) warnings about non ISO C
code in @emph{system} headers.
Default: false.
@item $R_check_weave_vignettes
If true, weave package vignettes in the process of checking them.
Default: true.
@item $R_check_latex_vignettes
If true (and @code{$R_check_weave_vignettes} is also true), @LaTeX{}
package vignettes in the process of checking them: this will show up
@code{Sweave} source errors, including missing source files.
Default: true.
@item $R_check_subdirs_nocase
If true, check the case of directories such as @file{R} and @file{man}.
Default: false.
@item $R_check_subdirs_strict
Initial setting for @option{--check-subdirs}.
Default: @samp{default} (which checks only tarballs, and checks in the
@file{src} only if there is no @file{configure} file).
@item $R_check_force_suggests
If true, give an error if suggested packages are not available.
Default: true.
@item $R_check_use_codetools
If true, make use of the @pkg{codetools} package, which provides a
detailed analysis of visibility of objects (but may give false
positives).
Default: true.
@item $R_check_Rd_xrefs
If true, check the cross-references in @file{.Rd} files.
Default: true.
@end table

Values @samp{1} or a string with lower-cased version @samp{"yes"} or
@samp{"true"} can be used for setting the variables to true; similarly,
@samp{0} or strings with lower-cased version @samp{"no"} or
@samp{"false"} give false.

For example, a configuration file containing

@example
$R_check_use_install_log = "TRUE";
$R_check_weave_vignettes = 0;
@end example

@noindent
results in using install logs and turning off weaving.

Future versions of @R{} will enhance this customization mechanism, and
provide a similar scheme for @code{R CMD build}.

There are other internal settings that can be changed via environment
variables @w{@env{_R_CHECK_*_}:} see the Perl source code.

@node Writing package vignettes, Submitting a package to CRAN, Checking and building packages, Creating R packages
@section Writing package vignettes
@cindex vignettes
@cindex Sweave

In addition to the help files in Rd format, @R{} packages allow the
inclusion of documents in arbitrary other formats.  The standard
location for these is subdirectory @file{inst/doc} of a source package,
the contents will be copied to subdirectory @file{doc} when the package
is installed.  Pointers from package help indices to the installed
documents are automatically created.  Documents in @file{inst/doc} can
be in arbitrary format, however we strongly recommend to provide them in
PDF format, such that users on all platforms can easily read them.  To
ensure that they can be accessed from a browser, the file names should
start with an @acronym{ASCII} letter and be entirely in @acronym{ASCII}
letters or digits or minus or underscore.

A special case are documents in Sweave format, which we call
@emph{package vignettes}.  Sweave allows the integration of @LaTeX{}
documents and @R{} code and is contained in package @pkg{utils} which is
part of the base @R{} distribution, see the @code{Sweave} help page for
details on the document format.  Package vignettes found in directory
@file{inst/doc} are tested by @code{R CMD check} by executing all @R{}
code chunks they contain to ensure consistency between code and
documentation.  Code chunks with option @code{eval=FALSE} are not
tested. The @R{} working directory for all vignette tests in @code{R CMD
check} is the @emph{installed} version of the @file{doc}
subdirectory. Make sure all files needed by the vignette (data sets,
@dots{}) are accessible by either placing them in the @file{inst/doc}
hierarchy of the source package, or using calls to @code{system.file()}.

@code{R CMD build} will automatically create PDF versions of the
vignettes for distribution with the package sources.  By including the
PDF version in the package sources it is not necessary that the
vignettes can be compiled at install time, i.e., the package author can
use private @LaTeX{} extensions which are only available on his machine.
@footnote{provided the conditions of the licence are met: many would see
this as incompatible with an Open Source licence.}

By default @code{R CMD build} will run @code{Sweave} on all files in
Sweave format.  If no @file{Makefile} is found in directory
@file{inst/doc}, then @code{texi2dvi --pdf} is run on all vignettes.
Whenever a @file{Makefile} is found, then @code{R CMD build} will try to
run @command{make} after the @code{Sweave} step, such that PDF manuals
can be created from arbitrary source formats (plain @LaTeX{} files,
@dots{}).  The @file{Makefile} should take care of both creation of PDF
files and cleaning up afterwards, i.e., delete all files that shall not
appear in the final package archive.  Note that the @code{make} step is
executed independently from the presence of any files in Sweave format.

It is no longer necessary to provide a @file{00Index.dcf} file in the
@file{inst/doc} directory---the corresponding information is generated
automatically from the @code{\VignetteIndexEntry} statements in all
Sweave files when installing from source, or when using the package
builder (@pxref{Checking and building packages}).  The
@code{\VignetteIndexEntry} statement is best placed in @LaTeX{} comment,
such that no definition of the command is necessary.

At install time an @HTML{} index for all vignettes is automatically
created from the @code{\VignetteIndexEntry} statements unless a file
@file{index.html} exists in directory @file{inst/doc}. This index is
linked into the @HTML{} help system for each package.

@node Submitting a package to CRAN, Package name spaces, Writing package vignettes, Creating R packages
@section Submitting a package to @acronym{CRAN}
@cindex CRAN
@cindex CRAN submission
@cindex Submitting to CRAN

@acronym{CRAN} is a network of WWW sites holding the @R{} distributions
and contributed code, especially @R{} packages.  Users of @R{} are
encouraged to join in the collaborative project and to submit their own
packages to @acronym{CRAN}.

Before submitting a package @pkg{mypkg}, do run the following steps to
test it is complete and will install properly.  (Unix procedures only,
run from the directory containing @file{mypkg} as a subdirectory.)

@enumerate
@item
Run @code{R CMD check} to check that the package will install and will
runs its examples, and that the documentation is complete and can be
processed.  If the package contains code that needs to be compiled, try
to enable a reasonable amount of diagnostic messaging (``warnings'')
when compiling, such as e.g.@: @option{-Wall -pedantic} for tools from
GCC, the Gnu Compiler Collection.  (If @R{} was not configured
accordingly, one can achieve this e.g.@: via @code{PKG_CFLAGS} and
related variables.)

@item
Run @code{R CMD build} to make the release @file{.tar.gz} file.
@end enumerate

@noindent
Please ensure that you can run through the complete procedure with only
warnings that you understand and have reasons not to eliminate.  In
principle, packages must pass @code{R CMD check} without warnings to be
admitted to the main @acronym{CRAN} package area.

When all the testing is done, upload the @file{.tar.gz} file, using
@samp{anonymous} as log-in name and your e-mail address as password, to

@example
@url{ftp://cran.R-project.org/incoming/}
@end example

@noindent
(note: use @code{ftp} and not @code{sftp} to connect to this server) and
send a message to @email{cran@@r-project.org}
about it.  The @acronym{CRAN} maintainers will run these tests before
putting a submission in the main archive.

Note that the fully qualified name of the @file{.tar.gz} file must be of
the form

@quotation
@file{@var{package}_@var{version}@r{[}_@var{engine}@r{[}_@var{type}@r{]]}},
@end quotation

@noindent
where the @samp{[ ]} indicates that the enclosed component is optional,
@var{package} and @var{version} are the corresponding entries in file
@file{DESCRIPTION}, @var{engine} gives the S engine the package is
targeted for and defaults to @samp{R}, and @var{type} indicated whether
the file contains source or binaries for a certain platform, and
defaults to @samp{source}.  I.e.,

@example
@group
OOP_0.1-3.tar.gz
OOP_0.1-3_R.tar.gz
OOP_0.1-3_R_source.tar.gz
@end group
@end example

@noindent
are all equivalent and indicate an @R{} source package, whereas

@example
OOP_0.1-3_Splus6_sparc-sun-solaris.tar.gz
@end example

@noindent
is a binary package for installation under Splus6 on the given
platform.

This naming scheme has been adopted to ensure usability of code across S
engines.  @R{} code and utilities operating on package @file{.tar.gz} files
can only be assumed to work provided that this naming scheme is
respected.  Of course, @code{R CMD build} automatically creates valid
file names.

Note that @acronym{CRAN} generally does not accept submissions of
precompiled binaries due to security reasons.


@node Package name spaces, Writing portable packages, Submitting a package to CRAN, Creating R packages
@section Package name spaces
@cindex name spaces

@R{} has a name space management system for packages.  This system
allows the package writer to specify which variables in the package
should be @emph{exported} to make them available to package users, and
which variables should be @emph{imported} from other packages.

The current mechanism for specifying a name space for a package is to
place a @file{NAMESPACE} file in the top level package directory.  This
file contains @emph{name space directives} describing the imports and
exports of the name space.  Additional directives register any shared
objects to be loaded and any S3-style methods that are provided.  Note
that although the file looks like @R{} code (and often has @R{}-style
comments) it is not processed as @R{} code.  Only very simple
conditional processing of @code{if} statements is implemented.

Like other packages, packages with name spaces are loaded and attached
to the search path by calling @code{library}.  Only the exported
variables are placed in the attached frame.  Loading a package that
imports variables from other packages will cause these other packages to
be loaded as well (unless they have already been loaded), but they will
@emph{not} be placed on the search path by these implicit loads.

Name spaces are @emph{sealed} once they are loaded.  Sealing means that
imports and exports cannot be changed and that internal variable
bindings cannot be changed.  Sealing allows a simpler implementation
strategy for the name space mechanism.  Sealing also allows code
analysis and compilation tools to accurately identify the definition
corresponding to a global variable reference in a function body.

Note that adding a name space to a package changes the search strategy.
The package name space comes first in the search, then the imports, then
the base name space and then the normal search path.

@menu
* Specifying imports and exports::  
* Registering S3 methods::      
* Load hooks::                  
* An example::                  
* Summary -- converting an existing package::  
* Name spaces with formal classes and methods::  
@end menu


@node Specifying imports and exports, Registering S3 methods, Package name spaces, Package name spaces
@subsection Specifying imports and exports

Exports are specified using the @code{export} directive in the
@file{NAMESPACE} file.  A directive of the form

@findex export
@example
export(f, g)
@end example

@noindent
specifies that the variables @code{f} and @code{g} are to be exported.
(Note that variable names may be quoted, and non-standard names such as
@code{[<-.fractions} must be.)

For packages with many variables to export it may be more convenient to
specify the names to export with a regular expression using
@code{exportPattern}.  The directive

@findex exportPattern
@example
exportPattern("^[^\\.]")
@end example

@noindent
exports all variables that do not start with a period.

A package with a name space implicitly imports the base name space.
Variables exported from other packages with name spaces need to be
imported explicitly using the directives @code{import} and
@code{importFrom}.  The @code{import} directive imports all exported
variables from the specified package(s).  Thus the directives

@findex import
@example
import(foo, bar)
@end example

@noindent
specifies that all exported variables in the packages @pkg{foo} and
@pkg{bar} are to be imported.  If only some of the exported variables
from a package are needed, then they can be imported using
@code{importFrom}.  The directive

@findex importFrom
@example
importFrom(foo, f, g)
@end example

@noindent
specifies that the exported variables @code{f} and @code{g} of the
package @pkg{foo} are to be imported.

It is possible to export variables from a name space that it has
imported from other namespaces.

If a package only needs a few objects from another package it can use a
fully qualified variable reference in the code instead of a formal
import.  A fully qualified reference to the function @code{f} in package
@pkg{foo} is of the form @code{foo:::f}.  This is less efficient than a
formal import and also loses the advantage of recording all dependencies
in the @file{NAMESPACE} file, so this approach is usually not
recommended.  Evaluating @code{foo:::f} will cause package @pkg{foo} to
be loaded, but not attached, if it was not loaded already---this can be
an advantage is delaying the loading of a rarely used package.

Using @code{foo:::f} allows access to unexported objects: to confine
references to exported objects use @code{foo::f}.

@node Registering S3 methods, Load hooks, Specifying imports and exports, Package name spaces
@subsection Registering S3 methods

The standard method for S3-style @code{UseMethod} dispatching might fail
to locate methods defined in a package that is imported but not attached
to the search path.  To ensure that these methods are available the
packages defining the methods should ensure that the generics are
imported and register the methods using @code{S3method} directives.  If
a package defines a function @code{print.foo} intended to be used as a
@code{print} method for class @code{foo}, then the directive

@findex S3method
@example
S3method(print, foo)
@end example

@noindent
ensures that the method is registered and available for @code{UseMethod}
dispatch.  The function @code{print.foo} does not need to be exported.
Since the generic @code{print} is defined in @pkg{base} it does not need
to be imported explicitly.  This mechanism is intended for use with
generics that are defined in a name space.  Any methods for a generic
defined in a package that does not use a name space should be exported,
and the package defining and exporting the methods should be attached to
the search path if the methods are to be found.


@node Load hooks, An example, Registering S3 methods, Package name spaces
@subsection Load hooks

There are a number of hooks that apply to packages with name spaces.
See @code{help(".onLoad")} for more details.

@findex .onLoad
@findex .onAttach
Packages with name spaces do not use the @code{.First.lib} function.
Since loading and attaching are distinct operations when a name space is
used, separate hooks are provided for each.  These hook functions are
called @code{.onLoad} and @code{.onAttach}.  They take the same
arguments as @code{.First.lib}; they should be defined in the name space
but not exported.

@findex .Last.lib
@findex .onUnload
However, packages with name spaces @emph{do} use the @code{.Last.lib}
function.  There is also a hook @code{.onUnload} which is called when
the name space is unloaded (via a call to @code{unloadNamespace}) with
argument the full path to the directory in which the package was
installed.  @code{.onUnload} should be defined in the name space and not
exported, but @code{.Last.lib} does need to be exported.

Packages are not likely to need @code{.onAttach} (except perhaps for a
start-up banner); code to set options and load shared objects should be
placed in a @code{.onLoad} function, or use made of the @code{useDynLib}
directive described next.

There can be one or more @code{useDynLib} directives which allow shared
objects that need to be loaded to be specified in the @file{NAMESPACE}
file.  The directive

@findex useDynLib
@example
useDynLib(foo)
@end example

@noindent
registers the shared object @code{foo} for loading with
@code{library.dynam}.  Loading of registered object(s) occurs after the
package code has been loaded and before running the load hook function.
Packages that would only need a load hook function to load a shared
object can use the @code{useDynLib} directive instead.

User-level hooks are also available: see the help on function
@code{setHook}.

The @code{useDynLib} directive also accepts the names of the native
routines that are to be used in @R{} via the @code{.C}, @code{.Call},
@code{.Fortran} and @code{.External} interface functions.  These are given as
additional arguments to the directive, for example,

@example
useDynLib(foo, myRoutine, myOtherRoutine)
@end example

By specifying these names in the @code{useDynLib} directive, the
native symbols are resolved when the package is loaded and @R{} variables
identifying these symbols are added to the package's name space with
these names.  These can be used in the @code{.C}, @code{.Call},
@code{.Fortran} and @code{.External} calls in place of the
name of the routine and the @code{PACKAGE} argument.
For instance, we can call the routine @code{myRoutine} from R
with the code

@example
 .Call(myRoutine, x, y)
@end example

@noindent
rather than

@example
 .Call("myRoutine", x, y, PACKAGE = "foo")
@end example

There are at least two benefits to this approach.  Firstly, the symbol
lookup is done just once for each symbol rather than each time it the
routine is invoked. Secondly, this removes any ambiguity in resolving
symbols that might be present in several compiled libraries.  In
particular, it allows for correctly resolving routines when different
versions of the same package are loaded concurrently in the same @R{}
session.

In some circumstances, there will already be an @R{} variable in the
package with the same name as a native symbol. For example, we may have
an @R{} function in the package named @code{myRoutine}.  In this case,
it is necessary to map the native symbol to a different @R{} variable
name. This can be done in the @code{useDynLib} directive by using named
arguments. For instance, to map the native symbol name @code{myRoutine}
to the @R{} variable @code{myRoutine_sym}, we would use

@example
useDynLib(foo, myRoutine_sym = myRoutine, myOtherRoutine)
@end example

We could then call that routine from @R{} using the command

@example
 .Call(myRoutine_sym, x, y)
@end example

Symbols without explicit names are assigned to the @R{} variable with
that name.

In some cases, it may be preferable not to create @R{} variables in the
package's name space that identify the native routines.  It may be too
costly to compute these for many routines when the package is loaded
if many of these routines are not likely to be used.  In this case,
one can still perform the symbol resolution correctly using the DLL,
but do this each time the routine is called.  Given a reference to the
DLL as an @R{} variable, say @code{dll}, we can call the routine
@code{myRoutine} using the expression

@example
 .Call(dll$myRoutine, x, y)
@end example

The @code{$} operator resolves the routine with the given name in the
DLL using a call to @code{getNativeSymbol}.  This is the same
computation as above where we resolve the symbol when the package is
loaded. The only difference is that this is done each time in the case
of @code{dll$myRoutine}.

In order to use this dynamic approach (e.g., @code{dll$myRoutine}), one
needs the reference to the DLL as an @R{} variable in the package.  The
DLL can be assigned to a variable by using the @code{variable =
dllName} format used above for mapping symbols to @R{} variables.  For
example, if we wanted to assign the DLL reference for the DLL
@code{foo} in the example above to the variable @code{myDLL}, we would
use the following directive in the @file{NAMESPACE} file:

@example
myDLL = useDynLib(foo, myRoutine_sym = myRoutine, myOtherRoutine)
@end example

Then, the @R{} variable @code{myDLL} is in the package's name space and
available for calls such as @code{myDLL$dynRoutine} to access routines
that are not explicitly resolved at load time.

If the package has registration information (see @ref{Registering native
routines}), then we can use that directly rather than specifying the
list of symbols again in the @code{useDynLib} directive in the
@file{NAMESPACE} file.  Each routine in the registration information is
specified by giving a name by which the routine is to be specified along
with the address of the routine and any information about the number and
type of the parameters.  Using the @code{.registration} argument of
@code{useDynLib}, we can instruct the name space mechanism to create
@R{} variables for these symbols.  For example, suppose we have the
following registration information for a DLL named @code{myDLL}:

@example
R_CMethodDef cMethods[] = @{
   @{"foo", &foo, 4, @{REALSXP, INTSXP, STRSXP, LGLSXP@}@},
   @{"bar_sym", &bar, 0@},
   @{NULL, NULL, 0@}
@};

R_CallMethodDef callMethods[] = @{
   @{"R_call_sym", &R_call, 4@},
   @{"R_version_sym", &R_version, 0@},
   @{NULL, NULL, 0@}
@};
@end example

Then, the directive in the @file{NAMESPACE} file

@example
useDynLib(myDLL, .registration = TRUE)
@end example

@noindent
causes the DLL to be loaded and also for the @R{} variables @code{foo},
@code{bar_sym}, @code{R_call_sym} and @code{R_version_sym} to be
defined in the package's name space.

Note that the names for the @R{} variables are taken from the entry in
the registration information and do not need to be the same as the name
of the native routine.  This allows the creator of the registration
information to map the native symbols to non-conflicting variable names
in @R{}, e.g.@: @code{R_version} to @code{R_version_sym} for use in an
@R{} function such as

@example
R_version <- function()
@{
  .Call(R_version_sym)
@}
@end example

Using argument @code{.fixes} allows an automatic prefix to be added to
the registered symbols, which can be useful when working with an
existing package.  For example, package @pkg{KernSmooth} has

@example
useDynLib(KernSmooth, .registration = TRUE, .fixes = "F_")
@end example

@noindent
which makes the @R{} variables corresponding to the Fortran symbols
@code{F_bkde} and so on, and so avoid clashes with @R{} code in the name
space.


More information about this symbol lookup, along with some approaches
for customizing it, is available from
@url{http://www.omegahat.org/examples/RDotCall}.

@node An example, Summary -- converting an existing package, Load hooks, Package name spaces
@subsection An example

As an example consider two packages named @pkg{foo} and @pkg{bar}.  The
@R{} code for package @pkg{foo} in file @file{foo.R} is

@quotation
@cartouche
@example
x <- 1
f <- function(y) c(x,y)
foo <- function(x) .Call("foo", x, PACKAGE="foo")
print.foo <- function(x, ...) cat("<a foo>\n")
@end example
@end cartouche
@end quotation

@noindent
Some C code defines a C function compiled into DLL @code{foo} (with an
appropriate extension).  The @file{NAMESPACE} file for this package is

@quotation
@cartouche
@example
useDynLib(foo)
export(f, foo)
S3method(print, foo)
@end example
@end cartouche
@end quotation

@noindent
The second package @pkg{bar} has code file @file{bar.R}

@quotation
@cartouche
@example
c <- function(...) sum(...)
g <- function(y) f(c(y, 7))
h <- function(y) y+9
@end example
@end cartouche
@end quotation

@noindent
and @file{NAMESPACE} file

@quotation
@cartouche
@example
import(foo)
export(g, h)
@end example
@end cartouche
@end quotation

@noindent
Calling @code{library(bar)} loads @pkg{bar} and attaches its exports to
the search path.  Package @pkg{foo} is also loaded but not attached to
the search path.  A call to @code{g} produces

@example
> g(6)
[1]  1 13
@end example

@noindent
This is consistent with the definitions of @code{c} in the two settings:
in @pkg{bar} the function @code{c} is defined to be equivalent to
@code{sum}, but in @pkg{foo} the variable @code{c} refers to the
standard function @code{c} in @pkg{base}.

@node Summary -- converting an existing package, Name spaces with formal classes and methods, An example, Package name spaces
@subsection Summary -- converting an existing package

To summarize, converting an existing package to use a name space involves
several simple steps:

@itemize @bullet
@item
Identify the public definitions and place them in @code{export} directives.
@item
Identify S3-style method definitions and write corresponding
@code{S3method} declarations.
@item
Identify dependencies and replace any @code{require} calls by
@code{import} directives (and make corresponding changes in the 
@item
Replace @code{.First.lib} functions with @code{.onLoad} functions or
@code{useDynLib} directives.
@end itemize

@noindent
Some code analysis tools to aid in this process are currently under
development.

@node Name spaces with formal classes and methods,  , Summary -- converting an existing package, Package name spaces
@subsection Name spaces with formal classes and methods

Some additional steps are needed for packages which make use of formal
(S4-style) classes and methods (unless these are purely used
internally).  The package should have @code{Depends: methods} in its
@file{DESCRIPTION} file and any classes and methods which are to be
exported need to be declared in the @file{NAMESPACE} file.  For example,
the @pkg{stats} package has

@findex exportClasses
@findex exportMethods

@example
export(mle)
importFrom(graphics, plot)
importFrom(stats, AIC, coef, confint, logLik, optim, profile, 
	   qchisq, update, vcov)
exportClasses(mle, profile.mle, summary.mle)
exportMethods(AIC, BIC, coef, confint, logLik, plot, profile, 
              summary, show, update, vcov)
@end example

@noindent
All formal classes need to be listed in an @code{exportClasses}
directive.  Generics for which formal methods are defined need to be
declared in an @code{exportMethods} directive, and where the generics
are formed by taking over existing functions, those functions need to be
imported (explicitly unless they are defined in the @code{base} name
space).

Note that exporting methods on a generic in the namespace will also
export the generic, and exporting a generic in the namespace will also
export its methods.  Where a generic has been created in the package
solely to add S4 methods to it, it can be declared @emph{via} either or
both of @code{exports} or @code{exportMethods}, but the latter seems
clearer (and is used in the @pkg{stats4} example above).

Further, a package using classes and methods defined in another package
needs to import them, with directives

@findex importClassesFrom
@findex importMethodsFrom

@example
importClassesFrom(package, ...)
importMethodsFrom(package, ...)
@end example

@noindent
listing the classes and functions with methods respectively.  Suppose we
had two small packages @pkg{A} and @pkg{B} with @pkg{B} using @pkg{A}.
Then they could have @code{NAMESPACE} files

@quotation
@cartouche
@example
export(f1, ng1)
exportMethods("[")
exportClasses(c1)
@end example
@end cartouche
@end quotation

@noindent
and

@quotation
@cartouche
@example
importFrom(A, ng1)
importClassesFrom(A, c1)
importMethodsFrom(A, f1)
export(f4, f5)
exportMethods(f6, "[")
exportClasses(c1, c2)
@end example
@end cartouche
@end quotation

@noindent
respectively.

Note that @code{importMethodsFrom} will also import any generics defined
in the namespace on those methods.

If your package imports the whole of a name space, it will automatically
import the classes from that namespace.  It will also import methods,
but it is best to do so explicitly, especially where there are methods
being imported from more than one namespace.


@node Writing portable packages, Diagnostic messages, Package name spaces, Creating R packages
@section Writing portable packages

@menu
* Encoding issues::             
@end menu

@code{R CMD check} provides a basic set of checks, but often further
problems emerge when people try to install and use packages submitted to
@acronym{CRAN} -- many of these involve compiled code.  Here are some
further checks that you can do to make your package more portable.

@itemize

@item
If your package has a @file{configure} script, provide a
@file{configure.win} script to be used on Windows.  The @acronym{CRAN}
binary packages for Windows are built automatically, and if your package
does not build without intervention it is unlikely to be easily
available to a high proportion of @R{} users.

@item
Make use of the abilities of your compilers to check the
standards-conformance of your code.  For example, @code{gcc} can be used
with options @option{-Wall -pedantic} to alert you to potential
problems.  Do not be tempted to assume that these are pure pedantry: for
example @R{} is still used on platforms where the C compiler does not
accept C++/C99 comments (starting @code{//}).

@item
Do be very careful with passing arguments between @R{}, C and
@acronym{FORTRAN} code.  In particular, @code{long} in C will be 32-bit
on most @R{} platforms (including those mostly used by the
@acronym{CRAN} maintainers), but 64-bit on many modern Unix and Linux
platforms.  It is rather unlikely that the use of @code{long} in C code
has been thought through: if you need a longer type than @code{int} you
should use a configure test for a C99 type such as @code{int_fast64_t}
(and failing that, @code{long long}) and typedef your own type to be
@code{long} or @code{long long}, or use another suitable type (such as
@code{size_t}).  Note that @code{integer} in @acronym{FORTRAN}
corresponds to @code{int} in C on all @R{} platforms.

@item
Errors in memory allocation and reading/writing outside arrays are very
common causes of crashes (e.g., segfaults) on some machines.
See @ref{Using valgrind} for a tool which can be used to look for this.

@item
The Mac OS X linker has some restrictions not found on other platforms.
Try to ensure that C entry points shared between source files are
declared as @code{extern} in all but one of the files.  (This is no
longer needed in recent versions of @R{}, but is if your package is
not restricted to such versions.)

@item
Many platforms will allow unsatisfied entry points in compiled code, but
will crash the application (here @R{}) if they are ever used.  Some
(notably Windows) will not.  Looking at the output of

@example
nm -pg mypkg.so  # @r{or other extension such as @file{.sl} or @file{.dylib}}
@end example

@noindent
and checking if any of the symbols marked @code{U} is unexpected is a
good way to avoid this.

@item
Conflicts between symbols in DLLs are handled in very platform-specific
ways.  Good ways to avoid trouble are to make as many symbols as
possible static (check with @code{nm -pg}), and to use unusual names, as
well as ensuring you have used the @code{PACKAGE} argument that @code{R
CMD check} checks for.

@end itemize

@node Encoding issues,  , Writing portable packages, Writing portable packages
@subsection Encoding issues

Care is needed if your package contains non-ASCII text, and in
particular if it is intended to be used in more than one locale.  It is
possible to mark the encoding used in the @file{DESCRIPTION} file and in
@file{.Rd} files, as discussed elsewhere in this manual.  What was not
possible before @R{} 2.5.0 was to mark the encoding used by character
strings in @R{}: if you want your package to work with earlier versions
of @R{} please consult the advice in the @R{} 2.4.x version of this
manual.

First, consider carefully if you really need non-ASCII text.  Most
users of @R{} will only be able to view correctly text in their native
language group (e.g.@: Western European, Eastern European, Simplified
Chinese) and ASCII.  Other characters may not be rendered at all,
rendered incorrectly, or cause your @R{} code to give an error.
For documentation, marking the encoding and including ASCII
transliterations is likely to do a reasonable job.

The most favourable circumstance is using UTF-8-encoded text in a
package that will only ever be used in a UTF-8 locale (and hence not on
Windows, for example).  In that case it is likely that text will be
rendered correctly in the terminal/console used to run @R{}, and files
written will be readable by other UTF-8-aware applications.  However,
plotting will be problematic.  On-screen plotting using the @samp{X11()}
device will use a font that only covers a small proportion of UTF-8, and
different fonts will likely need to be selected for Polish, Russian and
Japanese (see @code{help("X11")}).  Using @samp{postscript} or
@samp{pdf} will choose a default 8-bit encoding depending on the
language of the UTF-8 locale, and your users would need to be told how
to select the @samp{encoding} argument.

Another fairly common scenario is where a package will only be used in
one language, e.g.@: French.  It is not very safe to assume that all
such users would have their computers set to a French locale, but let us
assume so.  The problem then is that there are several possible
encodings for French locales, the most common ones being @samp{CP1252}
(Windows), @samp{ISO 8859-1} (latin-1), @samp{ISO 8859-15} (latin-9 which
includes the Euro), and @samp{UTF-8}.  For characters in the French
language the first three agree, but they do not agree with @samp{UTF-8}.
Further, you (or different users) can run @R{} in different locales in
different sessions, say @samp{fr_CA.utf8} one day and
@samp{fr_CH.iso88591} the next.  As from @R{} 2.5.0, declaring the
encoding as either @samp{latin1} or @samp{UTF-8} in the
@file{DESCRIPTION} file will enable this to work.  If you have character
data in @file{.rda} files (for use by @code{data} or LazyData) these
need to have been prepared and @code{save}d in @R{} 2.5.0 in an
appropriate locale (or marked via @code{Encoding}).  For example (from
package @pkg{FactoMineR} version @code{1.02}):

@example
> library(FactoMineR)
> data(wine)
> Encoding(names(wine)) <- "latin1"
> Encoding(levels(wine$Terroir)) <- "latin1"
> save(wine, file="wine.rda")
@end example

@noindent
was used to update a @file{.rda} file.

If you want to run @command{R CMD check} on a Unix-alike over a
package that sets the encoding you may need to specify a suitable
locale via an environment variable.  The default is equivalent to

@example
R_ENCODING_LOCALES="latin1=en_US:latin2=pl_PL:UTF-8=en_US.utf8:latin9=fr_FR.iso885915@@euro"
@end example

@noindent
which is appropriate for a system based on @code{glibc}, except if the
current locale in UTF-8 and @samp{iconv} is available, when the
package code is translated to UTF-8 for syntax checking.


@node Diagnostic messages, Internationalization, Writing portable packages, Creating R packages
@section Diagnostic messages

Now that diagnostic messages can be made available for translation, it
is important to write them in a consistent style.  Using the tools
described in the next section to extract all the messages can give a
useful overview of your consistency (or lack of it).

Some guidelines follow.

@itemize
@item
Messages are sentence fragments, and not viewed in isolation.  So it is
conventional not to capitalize the first word and not to end with a
period (or other punctuation).

@item
Try not to split up messages into small pieces.  In C error messages use
a single format string containing all English words in the messages.

In @R{} error messages do not construct a message with @code{paste} (such
messages will not be translated) but via multiple arguments to
@code{stop} or @code{warning}, or via @code{gettextf}.

@item
Do not use colloquialisms such as ``can't'' and ``don't''.

@item
If possible, make quotation marks part of your message as different
languages have different conventions.  In @R{} messages this means not
using @code{sQuote} or @code{dQuote} except where the argument is a
variable.

Conventionally single quotation marks are used for quotations such as

@example
'ord' must be a positive integer, at most the number of knots
@end example

@noindent
and double quotation marks when referring to an @R{} character string
such as

@example
'format' must be "normal" or "short" - using "normal"
@end example

Since @acronym{ASCII} does not contain directional quotation marks, it
is best to use @samp{'} and let the translator (including automatic
translation) use directional quotations where available.  The range of
quotation styles is immense: unfortunately we cannot reproduce them in a
portable @code{texinfo} document.  But as a taster, some languages use
`up' and `down' (comma) quotes rather than left or right quotes, and
some use guillemets (and some use what Adobe calls `guillemotleft' to
start and others use it to end).


@item
Occasionally messages need to be singular or plural (and in other
languages there may be no such concept or several plural forms --
Slovenian has four).  So avoid constructions such as was once used in
@code{library}

@example
if((length(nopkgs) > 0) && !missing(lib.loc)) @{
    if(length(nopkgs) > 1)
        warning("libraries ",
                paste(sQuote(nopkgs), collapse = ", "),
                " contain no packages")
    else
        warning("library ", paste(sQuote(nopkgs)),
                " contains no package")
@}
@end example

@noindent
and was replaced by

@example
if((length(nopkgs) > 0) && !missing(lib.loc)) @{
    pkglist <- paste(sQuote(nopkgs), collapse = ", ")
    msg <- sprintf(ngettext(length(nopkgs),
                     "library %s contains no packages",
                     "libraries %s contain no packages"),
                   pkglist)
    warning(msg, domain=NA)
@}
@end example

@noindent
Note that it is much better to have complete clauses as here, since
in another language one might need to say `There is no package in library
%s' or `There are no packages in libraries %s'.

@end itemize

@node Internationalization, Package types, Diagnostic messages, Creating R packages
@section Internationalization

There are mechanisms to translate the R- and C-level error and warning
messages.  There are only available if @R{} is compiled with NLS support
(which is requested by @command{configure} option @option{--enable-nls},
the default).

The procedures make use of @code{msgfmt} and @code{xgettext} which are
part of @acronym{GNU} @code{gettext} and this will need to be installed:
Windows users can find pre-compiled binaries at the @acronym{GNU}
archive mirrors and packaged with the @code{poEdit} package
(@url{http://@/poedit.sourceforge.net/@/download.php#win32}).


@menu
* C-level messages::            
* R messages::                  
@end menu

@node C-level messages, R messages, Internationalization, Internationalization
@subsection C-level messages

The process of enabling translations is

@itemize
@item
In a header file that will be included in all the C files
containing messages that should be translated, declare

@example
#include <R.h>  /* to include Rconfig.h */

#ifdef ENABLE_NLS
#include <libintl.h>
#define _(String) dgettext ("@var{pkg}", String)
/* replace @var{pkg} as appropriate */
#else
#define _(String) (String)
#endif
@end example

@item
For each message that should be translated, wrap it in @code{_(...)},
for example

@example
error(_("'ord' must be a positive integer"));
@end example

@item
In the package's @file{src} directory run

@example
xgettext --keyword=_ -o @var{pkg}.pot *.c
@end example

@end itemize

The file @file{src/@var{pkg}.pot} is the template file, and
conventionally this is shipped as @file{po/@var{pkg}.pot}.  A translator
to another language makes a copy of this file and edits it (see the
@code{gettext} manual) to produce say @file{@var{ll}.po}, where @var{ll}
is the code for the language in which the translation is to be used.
(This file would be shipped in the @file{po} directory.)  Next run
@code{msgfmt} on @file{@var{ll}.po} to produce @file{@var{ll}.mo}, and
copy that to @file{inst/po/@var{ll}/LC_MESSAGES/@var{pkg}.mo}.  Now when
the package is loaded after installation it will look for translations
of its messages in the @file{po/@var{lang}/LC_MESSAGES/@var{pkg}.mo} file
for any language @var{lang} that matches the user's preferences (via the
setting of the @code{LANGUAGE} environment variable or from the locale
settings).

@node R messages,  , C-level messages, Internationalization
@subsection R messages

Mechanisms to support the automatic translation of @R{} @code{stop},
@code{warning} and @code{message} messages are in place, provided the
package has a name space.  They make use of message catalogs in the same
way as C-level messages, but using domain @code{R-@var{pkg}} rather than
@code{@var{pkg}}.  Translation of character strings inside @code{stop},
@code{warning} and @code{message} calls is automatically enabled, as
well as other messages enclosed in calls to @code{gettext} or
@code{gettextf}.  (To suppress this, use argument @code{domain=NA}.)

Tools to prepare the @file{R-@var{pkg}.pot} file are provided in package
@pkg{tools}: @code{xgettext2pot} will prepare a file from all strings
occurring inside @code{gettext}/@code{gettextf}, @code{stop},
@code{warning} and @code{message} calls.  Some of these are likely to be
spurious and so the file is likely to need manual editing.
@code{xgettext} extracts the actual calls and so is more useful when
tidying up error messages.

Translation of messages which might be singular or plural can be very
intricate: languages can have up to four different forms.  The @R{}
function @code{ngettext} provides an interface to the C function of the
same name, and will choose an appropriate singular or plural form for
the selected language depending on the value of its first argument
@code{n}.

Packages without name spaces will need to use @code{domain="R-@var{pkg}"}
explicitly in calls to @code{stop}, @code{warning}, @code{message},
@code{gettext}/@code{gettextf} and @code{ngettext}.

@node Package types, Services, Internationalization, Creating R packages
@section Package types

The @file{DESCRIPTION} file has an optional field @code{Type} which if
missing is assumed to be @code{Package}, the sort of extension discussed
so far in this chapter.  Currently two other types are recognized, both
of which need write permission in the @R{} installation tree.

@menu
* Frontend::                    
* Translation::                 
@end menu

@node Frontend, Translation, Package types, Package types
@subsection Frontend

This is a rather general mechanism, designed for adding new front-ends
such as the @pkg{gnomeGUI} package.  If a @file{configure} file is found
in the top-level directory of the package it is executed, and then if a
@code{Makefile} is found (often generated by @file{configure}),
@code{make} is called.  If @code{R CMD INSTALL --clean} is used
@code{make clean} is called.  No other action is taken.

@code{R CMD build} can package up this type of extension, but @code{R
CMD check} will check the type and skip it.

@node Translation,  , Frontend, Package types
@subsection Translation

Conventionally, a translation package for language @var{ll} is called
@pkg{Translation-@var{ll}} and has @code{Type: Translation}.  It needs
to contain the directories @file{share/@/locale/@var{ll}} and
@file{library/@/@var{pkgname}/@/po/@/@var{ll}}, or at least those for
which translations are available.  The files @file{.mo} are installed in
the parallel places in the @R{} installation tree.

For example, a package @pkg{Translation-it} might be prepared from an
installed (and tested) version of @R{} by

@example
mkdir Translation-it
cd Translation-it
(cd $R_HOME; tar cf - share/locale/it library/*/po/it) | tar xf -
# the next step is not needed on Windows
msgfmt -c -o share/locale/it/LC_MESSAGES/RGui.mo $R_SRC_HOME/po/RGui-it.gmo
# create a DESCRIPTION file
cd ..
R CMD build Translation-it
@end example

It is probably appropriate to give the package a version number based on
the version of @R{} which has been translated.  So the
@file{DESCRIPTION} file might look like

@example
Package: Translation-it
Type: Translation
Version: 2.2.1-1
Title: Italian Translations for R 2.2.1
Description: Italian Translations for R 2.2.1
Author: The translators
Maintainer: Some Body <somebody@@some.where.net>
License: GPL Version 2 or later.
@end example

@node Services,  , Package types, Creating R packages
@section Services

Several members of the @R{} project have set up services to assist those
writing @R{} packages, particularly those intended for public
distribution.

@url{http://win-builder.r-project.org, win-builder.r-project.org} offers
the automated preparation of Windows binaries from well-tested source
packages. 

R-Forge (@url{http://R-Forge.r-project.org, R-Forge.r-project.org}) and
RForge (@url{http://www.rforge.net, www.rforge.net}) are similar
services with similar names.  Both provide source-code management
through SVN, daily building and checking, mailing lists and a repository
that can be accessed @emph{via} @code{install.packages}.  Package
developers have the opportunity to present their work on the basis of
project websites or news announcements.  Mailing lists, forums or wikis
provide useRs with convenient instruments for discussions and for
exchanging information between developers and/or interested useRs.


@node Writing R documentation files, Tidying and profiling R code, Creating R packages, Top
@chapter Writing R documentation files
@cindex Documentation, writing

@menu
* Rd format::                   
* Sectioning::                  
* Marking text::                
* Lists and tables::            
* Cross-references::            
* Mathematics::                 
* Insertions::                  
* Indices::                     
* Platform-specific sections::  
* Encoding::                    
* Processing Rd format::        
@end menu

@node Rd format, Sectioning, Writing R documentation files, Writing R documentation files
@section Rd format

@R{} objects are documented in files written in ``@R{} documentation''
(Rd) format, a simple markup language closely resembling (La)@TeX{},
which can be processed into a variety of formats, including @LaTeX{},
@HTML{} and plain text.  The translation is carried out by the Perl
script @command{Rdconv} in @file{@var{R_HOME}/bin} and by the
installation scripts for packages.

The @R{} distribution contains more than 1200 such files which can be
found in the @file{src/library/@var{pkg}/man} directories of the @R{}
source tree, where @var{pkg} stands for the standard packages which are
included in the @R{} distribution.

As an example, let us look at the file
@file{src/library/base/man/load.Rd} which documents the @R{} function
@code{load}.

@quotation
@cartouche
@smallexample
\name@{load@}
\alias@{load@}
\title@{Reload Saved Datasets@}
\description@{
  Reload the datasets written to a file with the function
  \code@{save@}.
@}
\usage@{
load(file, envir = parent.frame())
@}
\arguments@{
  \item@{file@}@{a connection or a character string giving the
    name of the file to load.@}
  \item@{envir@}@{the environment where the data should be
    loaded.@}
@}
\seealso@{
  \code@{\link@{save@}@}.
@}
\examples@{
## save all data
save(list = ls(), file= "all.Rdata")

## restore the saved values to the current environment
load("all.Rdata")

## restore the saved values to the workspace
load("all.Rdata", .GlobalEnv)
@}
\keyword@{file@}
@end smallexample
@end cartouche
@end quotation

An Rd file consists of three parts.  The header gives basic information
about the name of the file, the topics documented, a title, a short
textual description and @R{} usage information for the objects
documented.  The body gives further information (for example, on the
function's arguments and return value, as in the above example).
Finally, there is a footer with keyword information.  The header and
footer are mandatory.

See the @url{http://developer.r-project.org/Rds.html, ``Guidelines for Rd
files''} for guidelines for writing documentation in Rd format which
should be useful for package writers.

@menu
* Documenting functions::       
* Documenting data sets::       
* Documenting S4 classes and methods::  
* Documenting packages::        
@end menu

@node Documenting functions, Documenting data sets, Rd format, Rd format
@subsection Documenting functions

The basic markup commands used for documenting @R{} objects (in
particular, functions) are given in this subsection.

@table @code
@item \name@{@var{name}@}
@findex \name
@var{name} typically@footnote{There can be exceptions: for example Rd
files are not allowed to start with a dot, and have to be uniquely named
on a case-insensitve file system.} is the basename of the Rd file
containing the documentation.  It is the ``name'' of the Rd object
represented by the file and has to be unique in a package.
@c and must not contain @LaTeX{}
@c special characters (@samp{#}, @samp{$}, @samp{%}, @samp{&}, @samp{~},
@c @samp{_}, @samp{^}, @samp{\}, @samp{@{}, @samp{@}}).

@item \alias@{@var{topic}@}
@findex \alias
The @code{\alias} entries specify all ``topics'' the file documents.
This information is collected into index data bases for lookup by the
on-line (plain text and @HTML{}) help systems.

There may be several @code{\alias} entries.  Quite often it is
convenient to document several @R{} objects in one file.  For example,
file @file{Normal.Rd} documents the density, distribution function,
quantile function and generation of random variates for the normal
distribution, and hence starts with

@example
@group
\name@{Normal@}
\alias@{Normal@}
\alias@{dnorm@}
\alias@{pnorm@}
\alias@{qnorm@}
\alias@{rnorm@}
@end group
@end example

@noindent
Also, it is often convenient to have several different ways to refer to
an @R{} object, and an @code{\alias} does not need to be the name of an
object.

Note that the @code{\name} is not necessarily a topic documented, and if
so desired it needs to have an explicit @code{\alias} entry (as in this
example).

@item \title@{@var{Title}@}
@findex \title
Title information for the Rd file.  This should be capitalized, not end
in a period, and not use any markup (which would cause problems for
hypertext search).  Use of characters other than English text and
punctuation (e.g., @samp{<}) may limit portability.

@item \description@{@dots{}@}
@findex \description
A short description of what the function(s) do(es) (one paragraph, a few
lines only).  (If a description is ``too long'' and cannot easily be
shortened, the file probably tries to document too much at once.)

@item \usage@{@var{fun}(@var{arg1}, @var{arg2}, @dots{})@}
@findex \usage
One or more lines showing the synopsis of the function(s) and variables
documented in the file.  These are set in typewriter font.  This is a
verbatim-like command, so some characters need to be escaped
(@pxref{Insertions}).

The usage information specified should match the function definition
@emph{exactly} (such that automatic checking for consistency between
code and documentation is possible).

It is no longer advisable to use @code{\synopsis} for the actual
synopsis and show modified synopses in the @code{\usage}.  Support for
@code{\synopsis} will be removed eventually.  To indicate that a
function can be ``used'' in several different ways, depending on the
named arguments specified, use section @code{\details}.  E.g.,
@file{abline.Rd} contains

@example
@group
\details@{
  Typical usages are
\preformatted@{
abline(a, b, untf = FALSE, \dots)
......
@}
@end group
@end example

@findex \method
Use @code{\method@{@var{generic}@}@{@var{class}@}} to indicate the name
of an S3 method for the generic function @var{generic} for objects
inheriting from class @code{"@var{class}"}.  In the printed versions,
this will come out as @var{generic} (reflecting the understanding that
methods should not be invoked directly but via method dispatch), but
@code{codoc()} and other QC tools always have access to the full name.

For example, @file{print.ts.Rd} contains

@example
@group
\usage@{
\method@{print@}@{ts@}(x, calendar, \dots)
@}
@end group
@end example

@noindent
which will print as

@example
@group
Usage:

     ## S3 method for class 'ts':
     print(x, calendar, ...)
@end group
@end example

Usage for replacement functions should be given in the style of
@code{dim(x) <- value} rather than explicitly indicating the name of the
replacement function (@w{@code{"dim<-"}} in the above).  Similarly, one
can use @code{\method@{@var{generic}@}@{@var{class}@}(@var{arglist}) <-
value} to indicate the usage of an S3 replacement method for the generic
replacement function @code{"@var{generic}<-"} for objects inheriting
from class @code{"@var{class}"}.

@item \arguments@{@dots{}@}
@findex \arguments
Description of the function's arguments, using an entry of the form

@example
\item@{@var{arg_i}@}@{@var{Description of arg_i}.@}
@end example

@noindent
for each element of the argument list.  There may be optional text
before and after these entries.

@item \details@{@dots{}@}
@findex \details
A detailed if possible precise description of the functionality
provided, extending the basic information in the @code{\description}
slot.

@item \value@{@dots{}@}
@findex \value
Description of the function's return value.

If a list with multiple values is returned, you can use entries of the
form

@example
\item@{@var{comp_i}@}@{@var{Description of comp_i}.@}
@end example

@noindent
for each component of the list returned.  Optional text may precede this
list (see the introductory example for @code{rle}).

@item \references@{@dots{}@}
@findex \references
A section with references to the literature.  Use @code{\url@{@}} for
web pointers.

@item \note@{...@}
@findex \note
Use this for a special note you want to have pointed out.

For example, @file{pie.Rd} contains

@example
@group
\note@{
  Pie charts are a very bad way of displaying information.
  The eye is good at judging linear measures and bad at
  judging relative areas.
  ......
@}
@end group
@end example

@item \author@{@dots{}@}
@findex \author
Information about the author(s) of the Rd file.  Use @code{\email@{@}}
without extra delimiters (@samp{( )} or @samp{< >}) to specify email
addresses, or @code{\url@{@}} for web pointers.

@item \seealso@{@dots{}@}
@findex \seealso
Pointers to related @R{} objects, using @code{\code@{\link@{...@}@}} to
refer to them (@code{\code} is the correct markup for @R{} object names,
and @code{\link}
produces hyperlinks in output formats which support this.  @xref{Marking
text}, and @ref{Cross-references}).

@findex \examples
@item \examples@{@dots{}@}
Examples of how to use the function.  These are set as formatted in
typewriter font: see @ref{Insertions} for when characters need to be
escaped.  (Markup @code{\link} and @code{\var} will be interpreted, but
no other.)

Examples are not only useful for documentation purposes, but also
provide test code used for diagnostic checking of @R{}.  By default,
text inside @code{\examples@{@}} will be displayed in the output of the
help page and run by @code{R CMD check}.  You can use
@code{\dontrun@{@}}
@findex \dontrun
for commands that should only be shown, but not run, and
@code{\dontshow@{@}}
@findex \dontshow
for extra commands for testing that should not be shown to users, but
will be run by @code{example()}.  (Previously this was called
@code{\testonly}, and that is still accepted.)

For example,

@example
@group
x <- runif(10)       # @r{Shown and run.}
\dontrun@{plot(x)@}    # @r{Only shown.}
\dontshow@{log(x)@}    # @r{Only run.}
@end group
@end example

Thus, example code not included in @code{\dontrun} must be executable!
In addition, it should not use any system-specific features or require
special facilities (such as Internet access or write permission to
specific directories).  Code included in @code{\dontrun} is indicated by
comments in the processed help files.

Data needed for making the examples executable can be obtained by random
number generation (for example, @code{x <- rnorm(100)}), or by using
standard data sets listed by @code{data()} (see @code{?data} for more
info).

@findex \keyword
@item \keyword@{@var{key}@}
Each @code{\keyword} entry should specify one of the standard keywords
as listed in file @file{KEYWORDS} in the R documentation directory
(default @file{@var{R_HOME}/doc}).  Use e.g.@:
@code{file.show(file.path(R.home("doc"), "KEYWORDS"))} to inspect the
standard keywords from within R.  There must be at least one
@code{\keyword} entry, but can be more than one if the @R{} object being
documented falls into more than one category.

The special keyword @samp{internal} marks a page of internal objects
that are not part of the packages' API. If the help page for object
@code{foo} has keyword @samp{internal}, then @code{help(foo)} gives this
help page, but @code{foo} is excluded from several object indices, like
the alphabetical list of objects in the @HTML{} help system.
@end table

@findex prompt
The @R{} function @code{prompt} facilitates the construction of files
documenting @R{} objects.  If @code{foo} is an @R{} function, then
@kbd{prompt(foo)} produces file @file{foo.Rd} which already contains
the proper function and argument names of @code{foo}, and a structure
which can be filled in with information.

@node Documenting data sets, Documenting S4 classes and methods, Documenting functions, Rd format
@subsection Documenting data sets

The structure of Rd files which document @R{} data sets is slightly
different.  Whereas sections such as @code{\arguments} and @code{\value}
are not needed, the format and source of the data should be explained.

As an example, let us look at @file{src/library/datasets/man/rivers.Rd}
which documents the standard @R{} data set @code{rivers}.

@quotation
@cartouche
@smallexample
\name@{rivers@}
\docType@{data@}
\alias@{rivers@}
\title@{Lengths of Major North American Rivers@}
\description@{
  This data set gives the lengths (in miles) of 141 \dQuote@{major@}
  rivers in North America, as compiled by the US Geological
  Survey.
@}
\usage@{rivers@}
\format@{A vector containing 141 observations.@}
\source@{World Almanac and Book of Facts, 1975, page 406.@}
\references@{
  McNeil, D. R. (1977) \emph@{Interactive Data Analysis@}.
  New York: Wiley.
@}
\keyword@{datasets@}
@end smallexample
@end cartouche
@end quotation

This uses the following additional markup commands.

@table @code
@item \docType@{@dots{}@}
Indicates the ``type'' of the documentation object.  Always @samp{data}
for data sets.

@item \format@{@dots{}@}
@findex \format
A description of the format of the data set (as a vector, matrix, data
frame, time series, @dots{}).  For matrices and data frames this should
give a description of each column, preferably as a list or table.
@xref{Lists and tables}, for more information.

@item \source@{@dots{}@}
@findex \source
Details of the original source (a reference or @acronym{URL}).  In
addition, section @code{\references} could give secondary sources and
usages.
@end table

Note also that when documenting data set @var{bar},

@itemize @bullet
@item
The @code{\usage} entry is always @code{@var{bar}} or (for packages
which do not use lazy-loading of data) @code{data(@var{bar})}.  (In
particular, only document a @emph{single} data object per Rd file.)
@item
The @code{\keyword} entry is always @samp{datasets}.
@end itemize

If @code{@var{bar}} is a data frame, documenting it as a data set can
be initiated via @kbd{prompt(@var{bar})}.

@node Documenting S4 classes and methods, Documenting packages, Documenting data sets, Rd format
@subsection Documenting S4 classes and methods

There are special ways to use the @samp{?}  operator, namely
@samp{class?@var{topic}} and @samp{methods?@var{topic}}, to access
documentation for S4 classes and methods, respectively.  This mechanism
depends on conventions for the topic names used in @code{\alias}
entries.  The topic names for S4 classes and methods respectively are of
the form

@example
@var{class}-class
@var{generic},@var{signature_list}-method
@end example

@noindent
where @var{signature_list} contains the names of the classes in the
signature of the method (without quotes) separated by @samp{,} (without
whitespace), with @samp{ANY} used for arguments without an explicit
specification.  E.g., @samp{genericFunction-class} is the topic name for
documentation for the S4 class @code{"genericFunction"}, and
@samp{coerce,ANY,NULL-method} is the topic name for documentation for
the S4 method for @code{coerce} for signature @code{c("ANY", "NULL")}.

Skeletons of documentation for S4 classes and methods can be generated
by using the functions @code{promptClass()} and @code{promptMethods()}
from package @pkg{methods}.  If it is necessary or desired to provide an
explicit function declaration (in a @code{\usage} section) for an S4
method (e.g., if it has ``surprising arguments'' to be mentioned
explicitly), one can use the special markup

@example
\S4method@{@var{generic}@}@{@var{signature_list}@}(@var{argument_list})
@end example

@noindent
(e.g., @samp{\S4method@{coerce@}@{ANY,NULL@}(from, to)}).

To allow for making full use of the potential of the on-line
documentation system, all user-visible S4 classes and methods in a
package should at least have a suitable @code{\alias} entry in one of
the package's Rd files.  If a package has methods for a function defined
originally somewhere else, and does not change the underlying default
method for the function, the package is responsible for documenting the
methods it creates, but not for the function itself or the default
method.


See @kbd{help("Documentation", package = "methods")} for more
information on using and creating on-line documentation for S4 classes and
methods.

@node Documenting packages,  , Documenting S4 classes and methods, Rd format
@subsection Documenting packages

Packages may have an overview man page with an @code{\alias}
@code{@var{pkgname}-package}, e.g.@: @samp{utils-package} for the
@pkg{utils} package, when @code{package?@var{pkgname}} will open that
help page.  If a topic named @code{@var{pkgname}} does not exist in
another Rd file, it is helpful to use this as an additional
@code{\alias}.

Skeletons of documentation for a package can be generated using the
function @code{promptPackage()}.  If the @code{final = TRUE} argument
is used, then the Rd file will be generated in final form, containing
the information that would be produced by
@code{library(help = @var{pkgname})}.  Otherwise (the default) comments
will be inserted giving suggestions for content.

The only requirement for this page is that it include a
@code{\docType@{package@}} statement.  All other content is optional.
We suggest that it should be a short overview, to give a reader
unfamiliar with the package enough information to get started.  More
extensive documentation is better placed into a package vignette
(@pxref{Writing package vignettes}) and referenced from this page, or
into individual man pages for the functions, datasets, or classes.

@node Sectioning, Marking text, Rd format, Writing R documentation files
@section Sectioning

To begin a new paragraph or leave a blank line in an example, just
insert an empty line (as in (La)@TeX{}).  To break a line, use
@code{\cr}.
@findex \cr

In addition to the predefined sections (such as @code{\description@{@}},
@code{\value@{@}}, etc.), you can ``define'' arbitrary ones by
@code{\section@{@var{section_title}@}@{@dots{}@}}.
@findex \section
For example

@example
\section@{Warning@}@{You must not call this function unless @dots{}@}
@end example

@noindent
For consistency with the pre-assigned sections, the section name (the
first argument to @code{\section}) should be capitalized (but not all
upper case).

Note that additional named sections are always inserted at a fixed
position in the output (before @code{\note}, @code{\seealso} and the
examples), no matter where they appear in the input (but in the same
order as the input).


@node Marking text, Lists and tables, Sectioning, Writing R documentation files
@section Marking text
@cindex Marking text in documentation

The following logical markup commands are available for emphasizing or
quoting text.

@table @code
@item \emph@{@var{text}@}
@findex \emph
@itemx \strong@{@var{text}@}
@findex \strong
Emphasize @var{text} using @emph{italic} and @strong{bold} font if
possible; @code{\strong} is stronger.

@item \bold@{@var{text}@}
@findex \bold
Set @var{text} in @b{bold} font if possible.

@item \sQuote@{@var{text}@}
@findex \sQuote
@itemx \dQuote@{@var{text}@}
@findex \dQuote
Portably single or double quote @var{text} (without hard-wiring the
quotation marks).
@end table

The following logical markup commands are available for indicating
specific kinds of text.

@table @code
@item \code@{@var{text}@}
@findex \code
Indicate text that is a literal example of a piece of a program, e.g., a
fragment of @R{} code or the name of an @R{} object, using
@code{typewriter} font if possible.  Some characters will need to be
escaped (@pxref{Insertions}).  The only markup interpreted inside
@code{\code} is @code{\link} and @code{\var}.

@item \preformatted@{@var{text}@}
@findex \preformatted
Indicate text that is a literal example of a piece of a program, using
@code{typewriter} font if possible.  The same characters need to be
escaped as for @code{\code}.  All other formatting, e.g.@: line breaks,
is preserved.  The closing brace should be on a line by itself.

@item \kbd@{@var{keyboard-characters}@}
@findex \kbd
Indicate keyboard input, using @kbd{slanted typewriter} font if
possible, so users can distinguish the characters they are supposed to
type from those the computer outputs.

@item \samp@{@var{text}@}
@findex \samp
Indicate text that is a literal example of a sequence of characters.

@item \pkg@{@var{package_name}@}
@findex \pkg
Indicate the name of an @R{} package.

@item \file@{@var{file_name}@}
@findex \file
Indicate the name of a file.  Note that special characters do need to be
escaped.
@item \email@{@var{email_address}@}
@findex \email
Indicate an electronic mail address.
@item \url@{@var{uniform_resource_locator}@}
@findex \url
Indicate a uniform resource locator (@acronym{URL}) for the World Wide
Web.

@item \var@{@var{metasyntactic_variable}@}
@findex \var
Indicate a metasyntactic variable.  In some cases this will be rendered
distinctly, e.g.@: in italic, but not in all@footnote{Currently it is
rendered differently only in HTML conversions, and latex conversion
outside @samp{\usage} and @samp{\examples} environments.}.
@item \env@{@var{environment_variable}@}
@findex \env
Indicate an environment variable.
@item \option@{@var{option}@}
@findex \option
Indicate a command-line option.
@item \command@{@var{command_name}@}
@findex \command
Indicate the name of a command.
@item \dfn@{@var{term}@}
@findex \dfn
Indicate the introductory or defining use of a term.
@item \cite@{@var{reference}@}
@findex \cite
Indicate a reference without a direct cross-reference via @code{\link}
(@pxref{Cross-references}), such as the name of a book.
@item \acronym@{@var{acronym}@}
@findex \acronym
Indicate an acronym (an abbreviation written in all capital letters),
such as @acronym{GNU}.
@end table

Note that unless explicitly stated otherwise, special characters
(@pxref{Insertions}) must be escaped inside the above markup commands.


@node Lists and tables, Cross-references, Marking text, Writing R documentation files
@section Lists and tables
@cindex Lists and tables in documentation

@findex \itemize
@findex \enumerate
The @code{\itemize} and @code{\enumerate} commands take a single
argument, within which there may be one or more @code{\item} commands.
The text following each @code{\item} is formatted as one or more
paragraphs, suitably indented and with the first paragraph marked with a
bullet point (@code{\itemize}) or a number (@code{\enumerate}).

@code{\itemize} and @code{\enumerate} commands may be nested.

@findex \describe
The @code{\describe} command is similar to @code{\itemize} but allows
initial labels to be specified.  The @code{\item}s take two arguments,
the label and the body of the item, in exactly the same way as argument
and value @code{\item}s.  @code{\describe} commands are mapped to
@code{<DL>} lists in @HTML{} and @code{\description} lists in @LaTeX{}.

@findex \tabular
The @code{\tabular} command takes two arguments.  The first gives for
each of the columns the required alignment (@samp{l} for
left-justification, @samp{r} for right-justification or @samp{c} for
centring.)  The second argument consists of an arbitrary number of
lines separated by @code{\cr}, and with fields separated by @code{\tab}.
For example:

@example
@group
  \tabular@{rlll@}@{
    [,1] \tab Ozone   \tab numeric \tab Ozone (ppb)\cr
    [,2] \tab Solar.R \tab numeric \tab Solar R (lang)\cr
    [,3] \tab Wind    \tab numeric \tab Wind (mph)\cr
    [,4] \tab Temp    \tab numeric \tab Temperature (degrees F)\cr
    [,5] \tab Month   \tab numeric \tab Month (1--12)\cr
    [,6] \tab Day     \tab numeric \tab Day of month (1--31)
  @}
@end group
@end example

@noindent
There must be the same number of fields on each line as there are
alignments in the first argument, and they must be non-empty (but can
contain only spaces).

@node Cross-references, Mathematics, Lists and tables, Writing R documentation files
@section Cross-references
@cindex Cross-references in documentation

@findex \link
The markup @code{\link@{@var{foo}@}} (usually in the combination
@code{\code@{\link@{@var{foo}@}@}}) produces a hyperlink to the help for
@var{foo}.  Here @var{foo} is a @emph{topic}, that is the argument of
@code{\alias} markup in another Rd file (possibly in another package).
Hyperlinks are supported in some of the formats to which Rd files are
converted, for example @HTML{} and PDF, but ignored in others, e.g.@:
the text and S nroff formats.

One main usage of @code{\link} is in the @code{\seealso} section of the
help page, @pxref{Rd format}.

@cindex \linkS4class
You can specify a link to a different topic than its name by
@code{\link[=@var{dest}]@{@var{name}@}} which links to topic @var{dest}
with name @var{name}.  This can be used to refer to the documentation
for S3/4 classes, for example @code{\code@{"\link[=abc-class]@{abc@}"@}}
would be a way to refer to the documentation of an S4 class @code{"abc"}
defined in your package, and
@code{\code@{"\link[=terms.object]@{terms@}"@}} to the S3 @code{"terms"}
class (in package @pkg{stats}).  To make these easy to read,
@code{\code@{"\linkS4class@{abc@}"@}} expands to the form given above.

There are two other forms of optional argument specified as
@code{\link[@var{pkg}]@{@var{foo}@}} and
@code{\link[@var{pkg:bar}]@{@var{foo}@}} to link to the package
@var{pkg}, to @emph{files} @file{@var{foo}.html} and
@file{@var{bar}.html} respectively.  These are rarely needed, perhaps to
refer to not-yet-installed packages (but there the @HTML{} help system
will resolve the link at run time) or in the normally undesirable event
that more than one package offers help on a topic@footnote{a common
example in CRAN packages is @code{\link[mgcv]@{gam@}}.} (in which case
the present package has precedence so this is only needed to refer to
other packages).  They are only in used in (C)HTML help (and not for
hyperlinks in @LaTeX{} nor S sgml conversions of help pages), and link
to the file rather than the topic (since there is no way to know which
topics are in which files in an uninstalled package).

@node Mathematics, Insertions, Cross-references, Writing R documentation files
@section Mathematics
@cindex Mathematics in documentation
@findex \eqn
@findex \deqn

Mathematical formulae should be set beautifully for printed
documentation yet we still want something useful for text and @HTML{}
online help.  To this end, the two commands
@code{\eqn@{@var{latex}@}@{@var{ascii}@}} and
@code{\deqn@{@var{latex}@}@{@var{ascii}@}} are used.  Where @code{\eqn}
is used for ``inline'' formulae (corresponding to @TeX{}'s
@code{$@dots{}$}, @code{\deqn} gives ``displayed equations'' (as in
@LaTeX{}'s @code{displaymath} environment, or @TeX{}'s
@code{$$@dots{}$$}).

Both commands can also be used as @code{\eqn@{@var{latexascii}@}} (only
@emph{one} argument) which then is used for both @var{latex} and
@var{ascii}.

The following example is from @file{Poisson.Rd}:

@example
@group
  \deqn@{p(x) = \frac@{\lambda^x e^@{-\lambda@}@}@{x!@}@}@{%
        p(x) = lambda^x exp(-lambda)/x!@}
  for \eqn@{x = 0, 1, 2, \ldots@}.
@end group
@end example

@iftex
For the @LaTeX{} manual, this becomes

@quotation
@cartouche
@tex
$$ p(x) = \lambda^x\ {e^{-\lambda} \over x!} $$
for $x = 0, 1, 2, \ldots$.
@end tex
@end cartouche
@end quotation
@end iftex

For @HTML{} and text on-line help we get

@quotation
@cartouche
@example
    p(x) = lambda^x exp(-lambda)/x!

for x = 0, 1, 2, ....
@end example
@end cartouche
@end quotation

@c  For historic reasons mostly, the @TeX{}/@LaTeX{} commands @code{\alpha},
@c  @code{\Alpha}, @code{\beta}, @code{\Gamma}, @code{\epsilon},
@c  @code{\lambda}, @code{\mu}, @code{\pi}, @code{\sigma}, @code{\left(} and
@c  @code{\right)} exist.  These can be used directly, without using the
@c  @code{\eqn} diversion.
@c  @findex \alpha
@c  @findex \Alpha
@c  @findex \beta
@c  @findex \Gamma
@c  @findex \epsilon
@c  @findex \lambda
@c  @findex \mu
@c  @findex \pi
@c  @findex \sigma
@c  @findex \left(
@c  @findex \right)

@node Insertions, Indices, Mathematics, Writing R documentation files
@section Insertions

@findex \R
Use @code{\R} for the @R{} system itself (you don't need extra
@samp{@{@}} or @samp{\}).  Use @code{\dots}
@findex \dots
for the dots in function argument lists @samp{@dots{}}, and
@code{\ldots}
@findex \ldots
for ellipsis dots in ordinary text.

After a @samp{%}, you can put your own comments regarding the help text.
The rest of the line will be completely disregarded, normally.
Therefore, you can also use it to make part of the ``help'' invisible.

You can produce a backslash (@samp{\}) by escaping it by another
backslash.  (Note that @code{\cr} is used for generating line breaks.)

The ``comment'' character @samp{%} and unpaired braces@footnote{See the
examples section in the file @file{Paren.Rd} for an example.}
@emph{always} need to be escaped by @samp{\}, and @samp{\\} can be used
for backslash and needs to be when there two or more adjacent
backslashes).  Inside the verbatim-like commands (@code{usage},
@code{\code}, @code{\preformatted} and @code{\examples}), no other
characters are special.  Note that @code{\file} is @strong{not} a
verbatim-like command.

In ``regular'' text (not verbatim-like, no @code{\eqn}, @dots{}), you
currently must escape most @LaTeX{} special characters, i.e., besides
@samp{%}, @samp{@{}, and @samp{@}}, the specials @samp{$}, @samp{#}, and
@samp{_} are produced by preceding each with a @samp{\}.  (@samp{&} can
also be escaped, but need not be.)  Further, enter @samp{^} as
@code{\eqn@{\mbox@{\textasciicircum@}@}@{^@}}, and @samp{~} by
@code{\eqn@{\mbox@{\textasciitilde@}@}@{~@}} or @code{\eqn@{\sim@}@{~@}}
(for a short and long tilde respectively).  Also, @samp{<}, @samp{>},
and @samp{|} must only be used in math mode, i.e., within @code{\eqn} or
@code{\deqn}.

@findex \enc
Text which might need to be represented differently in different
encodings should be marked by @code{\enc}, e.g.@:
@code{\enc@{J@"oreskog@}@{Joreskog@}} where the first argument will be
used where encodings are allowed and the second should be
@acronym{ASCII} (and is used for e.g.@: the text conversion).

@node Indices, Platform-specific sections, Insertions, Writing R documentation files
@section Indices
@cindex Indices

The @code{\alias} command (@pxref{Documenting functions}) is used to
specify the ``topics'' documented, which should include @emph{all} R
objects in a package such as functions and variables, data sets, and S4
classes and methods (@pxref{Documenting S4 classes and methods}).  The
on-line help system searches the index data base consisting of all
alias topics.

@findex \concept
In addition, it is possible to provide ``concept index entries'' using
@code{\concept}, which can be used for @code{help.search()} lookups.
E.g., file @file{cor.test.Rd} in the standard package @pkg{stats}
contains

@example
\concept@{Kendall correlation coefficient@}
\concept@{Pearson correlation coefficient@}
\concept@{Spearman correlation coefficient@}
@end example

@noindent
so that e.g.@: @kbd{help.search("Spearman")} will succeed in finding the
help page for the test for association between paired samples using
Spearman's @eqn{\rho, rho}.  (Note that concepts are not currently
supported by the @HTML{} search accessed @emph{via}
@samp{help.start()}.)

(Note that @code{help.search()} only uses ``sections'' of documentation
objects with no additional markup.)

If you want to cross reference such items from other help files via
@code{\link}, you need to use @code{\alias} and not @code{\concept}.


@node  Platform-specific sections, Encoding, Indices, Writing R documentation files
@section Platform-specific documentation
@cindex Platform-specific documentation

Sometimes the documentation needs to differ by platform.  Currently two
OS-specific options are available, @samp{unix} and @samp{windows}, and
lines in the help source file can be enclosed in

@example
@group
#ifdef @var{OS}
   ...
#endif
@end group
@end example

@noindent
or

@example
@group
#ifndef @var{OS}
   ...
#endif
@end group
@end example

@noindent
for OS-specific inclusion or exclusion.

If the differences between platforms are extensive or the @R{} objects
documented are only relevant to one platform, platform-specific Rd files
can be put in a @file{unix} or @file{windows} subdirectory.

@node Encoding, Processing Rd format, Platform-specific sections, Writing R documentation files
@section Encoding
@cindex encoding

Rd files are text files and so it is impossible to deduce the encoding
they are written in unless @acronym{ASCII}: files with 8-bit
characters could be UTF-8, Latin-1, Latin-9, KOI8-R, EUC-JP,
@emph{etc}.  So the @code{\encoding@{@}} directive must be used to
specify the encoding if it is not @acronym{ASCII}.  (The
@code{\encoding@{@}} directive must be on a line by itself, and in
particular one containing no non-@acronym{ASCII} characters.  As from
@R{} 2.6.0 the encoding declared in the @file{DESCRIPTION} file will
be used if none is declared in the file.)  This is used when creating
the header of the @HTML{} conversion (if not present, for
back-compatibility the processing to @HTML{} assumes that the file is
in Latin-1 (ISO-8859-1)) and to add comments to the text and examples
conversions.  It is also used to indicate to @LaTeX{} how to process
the file (see below).

Wherever possible, avoid non-@acronym{ASCII} chars in Rd files, and even
symbols such as @samp{<}, @samp{>}, @samp{$}, @samp{^}, @samp{&},
@samp{|}, @samp{@@}, @samp{~}, and @samp{*} outside verbatim
environments (since they may disappear in fonts designed to render
text).

For convenience, encoding names @samp{latin1} and @samp{latin2} are
always recognized: these and @samp{UTF-8} are likely to work fairly
widely.

The @code{\enc} command (@pxref{Insertions}) can be used to provide
transliterations which will be used in conversions that do not support
the declared encoding.

The @LaTeX{} conversion converts an explicit encoding of the file to a

@example
\inputencoding@{@var{some_encoding}@}
@end example

@noindent
command, and this needs to be matched by a suitable invocation of the
@command{\usepackage@{inputenc@}} command.  The @R{} utility @command{R
CMD Rd2dvi} looks at the converted code and includes the encodings used:
it might for example use

@example
\usepackage[latin1,latin9,utf8]@{inputenc@}
@end example

@noindent
(Use of @code{utf8} as an encoding requires @LaTeX{} dated 2003/12/01 or
later.)

Note that this mechanism works best with letters and for example the
copyright symbol may be rendered as a subscript and the plus--minus
symbol cannot be used in text.



@node Processing Rd format,  , Encoding, Writing R documentation files
@section Processing Rd format
@cindex Processing Rd format

There are several commands to process Rd files from the system command
line.  All of these need Perl to be installed.

@findex R CMD Rdconv
Using @code{R CMD Rdconv} one can convert @R{} documentation format to
other formats, or extract the executable examples for run-time testing.
Currently, conversions to plain text, @HTML{}, @LaTeX{}, and @Sl{}
version 3 or 4 documentation formats are supported.

In addition to this low-level conversion tool, the @R{} distribution
provides two user-level programs for processing Rd format.
@findex R CMD Rd2txt
@findex R CMD Rd2dvi
@code{R CMD Rd2txt} produces ``pretty'' plain text output from an Rd
file, and is particularly useful as a previewer when writing Rd format
documentation within Emacs.  @code{R CMD Rd2dvi} generates DVI (or, if
option @option{--pdf} is given, PDF) output from documentation in Rd
files, which can be specified either explicitly or by the path to a
directory with the sources of a package (or bundle).  In the latter
case, a reference manual for all documented objects in the package is
created, including the information in the @file{DESCRIPTION} files.

@findex R CMD Sd2Rd
@code{R CMD Sd2Rd} converts @Sl{} version 3 documentation files
(which use an extended Nroff format) and @Sl{} version 4 documentation
(which uses SGML markup) to Rd format.  This is useful when porting a
package originally written for the @Sl{} system to @R{}.  @Sl{} version
3 files usually have extension @file{.d}, whereas version 4 ones have
extension @file{.sgml} or @file{.sgm}.

@findex R CMD Sweave
@findex R CMD Stangle
@code{R CMD Sweave} and @code{R CMD Stangle} process @samp{Sweave}
documentation files (usually with extension @samp{.Snw} or @samp{.Rnw}):
@code{R CMD Stangle} is use to extract the @R{} code fragments.

The exact usage and a detailed list of available options for all but the
last two of the above commands can be obtained by running @code{R CMD
@var{command} --help}, e.g., @kbd{R CMD Rdconv --help}.  All available
commands can be listed using @kbd{R --help} (or @kbd{Rcmd --help} under
Windows).

All of these work under Windows. You will need to have installed the
files in the @R{} binary Windows distribution for installing source
packages (this is true for a default installation), and for @code{R CMD
Rd2dvi} also the tools to build packages from source as described in the
``R Installation and Administration'' manual.


@node Tidying and profiling R code, Debugging, Writing R documentation files, Top
@chapter Tidying and profiling R code

@menu
* Tidying R code::              
* Profiling R code for speed::  
* Profiling R code for memory use::  
* Profiling compiled code::     
@end menu

@R{} code which is worth preserving in a package and perhaps making
available for others to use is worth documenting, tidying up and perhaps
optimizing. The last two of these activities are the subject of this
chapter.

@node Tidying R code, Profiling R code for speed, Tidying and profiling R code, Tidying and profiling R code
@section Tidying R code
@cindex Tidying R code

@R{} treats function code loaded from packages and code entered by users
differently.  Code entered by users has the source code stored in an
attribute, and when the function is listed, the original source is
reproduced.  Loading code from a package (by default) discards the
source code, and the function listing is re-created from the parse tree
of the function.

Normally keeping the source code is a good idea, and in particular it
avoids comments being moved around in the source.  However, we can make
use of the ability to re-create a function listing from its parse tree
to produce a tidy version of the function, for example with consistent
indentation and spaces around operators.  This tidied version is much
easier to read, not least by other users who are used to the standard
format.  Although the deparsing cannot do so, we recommend the
consistent use of the preferred assignment operator @samp{<-} (rather
than @samp{=}) for assignment.

We can subvert the keeping of source in two ways.

@enumerate
@item
The option @code{keep.source} can be set to @code{FALSE} before the code
is loaded into @R{}.
@item
The stored source code can be removed by removing the @code{source}
attribute, for example by

@example
attr(myfun, "source") <- NULL
@end example

@end enumerate

@noindent
In each case if we then list the function we will get the standard
layout.

Suppose we have a file of functions @file{myfuns.R} that we want to
tidy up.  Create a file @file{tidy.R} containing

@example
@group
options(keep.source = FALSE)
source("myfuns.R")
dump(ls(all = TRUE), file = "new.myfuns.R")
@end group
@end example

@noindent
and run @R{} with this as the source file, for example by @kbd{R
--vanilla < tidy.R} or by pasting into an @R{} session.  Then the file
@file{new.myfuns.R} will contain the functions in alphabetical order in
the standard layout.  You may need to move comments to more appropriate
places.

The standard format provides a good starting point for further tidying.
Most package authors use a version of Emacs (on Unix or Windows) to edit
@R{} code, using the ESS[S] mode of the @acronym{ESS} Emacs package.
See @ref{R coding standards, , R coding standards, R-ints, R Internals}
for style options within the ESS[S] mode recommended for the source code
of @R{} itself.


@node Profiling R code for speed, Profiling R code for memory use, Tidying R code, Tidying and profiling R code
@section Profiling R code for speed
@cindex Profiling
@findex Rprof

It is possible to profile @R{} code on Windows and most@footnote{@R{}
has to be built to enable this, but the option
@option{--enable-R-profiling} is the default.} Unix-like versions of
@R{}.

The command @command{Rprof} is used to control profiling, and its help
page can be consulted for full details.  Profiling works by recording at
fixed intervals@footnote{For Unix-alikes these are intervals of CPU
time, and for Windows of elapsed time.} (by default every 20 msecs) which
@R{} function is being used, and recording the results in a file
(default @file{Rprof.out} in the working directory).  Then the function
@code{summaryRprof} or the command-line utility @code{R CMD Rprof
@var{Rprof.out}} can be used to summarize the activity.

As an example, consider the following code (from Venables & Ripley,
2002).

@smallexample
@group
library(MASS); library(boot)
storm.fm <- nls(Time ~ b*Viscosity/(Wt - c), stormer,
                start = c(b=29.401, c=2.2183))
st <- cbind(stormer, fit=fitted(storm.fm))
storm.bf <- function(rs, i) @{
    st$Time <-  st$fit + rs[i]
    tmp <- nls(Time ~ (b * Viscosity)/(Wt - c), st,
               start = coef(storm.fm))
    tmp$m$getAllPars()
@}
rs <- scale(resid(storm.fm), scale = FALSE) # remove the mean
Rprof("boot.out")
storm.boot <- boot(rs, storm.bf, R = 4999) # pretty slow
Rprof(NULL)
@end group
@end smallexample

@noindent
Having run this we can summarize the results by

@smallexample
@group
R CMD Rprof boot.out

Each sample represents 0.02 seconds.
Total run time: 80.74 seconds.

Total seconds: time spent in function and callees.
Self seconds: time spent in function alone.
@end group

@group
   %       total       %       self
 total    seconds     self    seconds    name
100.00     80.74      0.22      0.18     "boot"
 99.65     80.46      1.19      0.96     "statistic"
 96.33     77.78      2.68      2.16     "nls"
 50.21     40.54      1.54      1.24     "<Anonymous>"
 47.11     38.04      1.83      1.48     ".Call"
 23.06     18.62      2.43      1.96     "eval"
 19.87     16.04      0.67      0.54     "as.list"
 18.97     15.32      0.64      0.52     "switch"
 17.88     14.44      0.47      0.38     "model.frame"
 17.41     14.06      1.73      1.40     "model.frame.default"
 17.41     14.06      2.80      2.26     "nlsModel"
 15.43     12.46      1.88      1.52     "qr.qty"
 13.40     10.82      3.07      2.48     "assign"
 12.73     10.28      2.33      1.88     "storage.mode<-"
 12.34      9.96      1.81      1.46     "qr.coef"
 10.13      8.18      5.42      4.38     "paste"
  ...
@end group

@group
   %       self        %       total
 self     seconds    total    seconds    name
  5.42      4.38     10.13      8.18     "paste"
  3.37      2.72      6.71      5.42     "as.integer"
  3.29      2.66      5.00      4.04     "as.double"
  3.20      2.58      4.29      3.46     "seq.default"
  3.07      2.48     13.40     10.82     "assign"
  2.92      2.36      5.95      4.80     "names"
  2.80      2.26     17.41     14.06     "nlsModel"
  2.68      2.16     96.33     77.78     "nls"
  2.53      2.04      2.53      2.04     ".Fortran"
  2.43      1.96     23.06     18.62     "eval"
  2.33      1.88     12.73     10.28     "storage.mode<-"
  ...
@end group
@end smallexample

@noindent
This often produces surprising results and can be used to identify
bottlenecks or pieces of @R{} code that could benefit from being
replaced by compiled code.

@code{R CMD Rprof} uses a Perl script that may be a little faster than
@code{summaryRprof} for large files.  On the other hand
@code{summaryRprof} does not require Perl and provides the results as an
@R{} object.

Two warnings: profiling does impose a small performance penalty, and the
output files can be very large if long runs are profiled.

Profiling short runs can sometimes give misleading results.  @R{} from
time to time performs @emph{garbage collection} to reclaim unused
memory, and this takes an appreciable amount of time which profiling
will charge to whichever function happens to provoke it.  It may be
useful to compare profiling code immediately after a call to @code{gc()}
with a profiling run without a preceding call to @code{gc}.

@node Profiling R code for memory use, Profiling compiled code, Profiling R code for speed, Tidying and profiling R code
@section Profiling R code for memory use
@cindex Profiling
@cindex Memory use

Measuring memory use in @R{} code is useful either when the code takes
more memory than is conveniently available or when memory allocation
and copying of objects is responsible for slow code. There are three
ways to profile memory use over time in @R{} code. All three require
@R{} to have been compiled with @option{--enable-memory-profiling},
which is not the default. All can be misleading, for different
reasons.

In understanding the memory profiles it is useful to know a little
more about @R{}'s memory allocation. Looking at the results of
@code{gc()} shows a division of memory into @code{Vcells} used to
store the contents of vectors and @code{Ncells} used to store
everything else, including all the administrative overhead for vectors
such as type and length information.  In fact the vector contents are
divided into two pools. Memory for small vectors (by default 128 bytes
or less) is obtained in large chunks and then parcelled out by R;
memory for larger vectors is obtained directly from the operating
system.

Some memory allocation is obvious in interpreted code, for example,

@smallexample
y <- x + 1
@end smallexample

@noindent
allocates memory for a new vector @code{y}. Other memory allocation is
less obvious and occurs because @code{R} is forced to make good on its
promise of `call-by-value' argument passing.  When an argument is
passed to a function it is not immediately copied. Copying occurs (if
necessary) only when the argument is modified.  This can lead to
surprising memory use. For example, in the `survey' package we have

@smallexample
print.svycoxph <- function (x, ...)
@{
    print(x$survey.design, varnames = FALSE, design.summaries = FALSE,
        ...)
    x$call <- x$printcall
    NextMethod()
@}
@end smallexample

@noindent
It may not be obvious that the assignment to @code{x$call} will cause
the entire object @code{x} to be copied.  This copying to preserve the
call-by-value illusion is usually done by the internal C function
@code{duplicate}.

The main reason that memory-use profiling is difficult is garbage
collection. Memory is allocated at well-defined times in an @R{}
program, but is freed whenever the garbage collector happens to run.

@menu
* Memory statistics from Rprof::  
* Tracking memory allocations::  
* Tracing copies of an object::  
@end menu

@node Memory statistics from Rprof, Tracking memory allocations, Profiling R code for memory use, Profiling R code for memory use
@subsection Memory statistics from @code{Rprof}
@findex Rprof
@findex summaryRprof

The sampling profiler @code{Rprof} described in the previous section
can be given the option @code{memory.profiling=TRUE}. It then writes
the total @R{} memory allocation in small vectors, large vectors, and
cons cells or nodes at each sampling interval. It also writes out the
number of calls to the internal function @code{duplicate}, which is
called to copy @R{} objects. @code{summaryRprof} provides summaries of
this information.  The main reason that this can be misleading is that
the memory use is attributed to the function running at the end of the
sampling interval. A second reason is that garbage collection can make
the amount of memory in use decrease, so a function appears to use
little memory. Running under @code{gctorture} helps with both
problems: it slows down the code to effectively increase the sampling
frequency and it makes each garbage collection release a smaller
amount of memory.  Changing the memory limits with @code{mem.limits()}
may also be useful, to see how the code would run under different
memory conditions.

@node Tracking memory allocations, Tracing copies of an object, Memory statistics from Rprof, Profiling R code for memory use
@subsection Tracking memory allocations
@findex Rprofmem

The second method of memory profiling uses a memory-allocation
profiler, @code{Rprofmem()}, which writes out a stack trace to an
output file every time a large vector is allocated (with a
user-specified threshold for `large') or a new page of memory is
allocated for the @R{} heap. Summary functions for this output are still
being designed. 

Running the example from the previous section with

@smallexample
> Rprofmem("boot.memprof",threshold=1000)
> storm.boot <- boot(rs, storm.bf, R = 4999)
> Rprofmem(NULL)
@end smallexample

@noindent
shows that apart from some initial and final work in @code{boot} there
are no vector allocations over 1000 bytes.

@node  Tracing copies of an object,  , Tracking memory allocations, Profiling R code for memory use
@subsection Tracing copies of an object
@findex tracemem
@findex untracemem

The third method of memory profiling involves tracing copies made of a
specific (presumably large) @R{} object. Calling @code{tracemem} on an
object marks it so that a message is printed to standard output when
the object is copied via @code{duplicate} or coercion to another type,
or when a new object of the same size is created in arithmetic
operations. The main reason that this can be misleading is that
copying of subsets or components of an object is not tracked. It may
be helpful to use @code{tracemem} on these components.


In the example above we can run @code{tracemem} on the data frame
@code{st}

@smallexample
> tracemem(st)
[1] "<0x9abd5e0>"
> storm.boot <- boot(rs, storm.bf, R = 4)
memtrace[0x9abd5e0->0x92a6d08]: statistic boot
memtrace[0x92a6d08->0x92a6d80]: $<-.data.frame $<- statistic boot
memtrace[0x92a6d80->0x92a6df8]: $<-.data.frame $<- statistic boot
memtrace[0x9abd5e0->0x9271318]: statistic boot
memtrace[0x9271318->0x9271390]: $<-.data.frame $<- statistic boot
memtrace[0x9271390->0x9271408]: $<-.data.frame $<- statistic boot
memtrace[0x9abd5e0->0x914f558]: statistic boot
memtrace[0x914f558->0x914f5f8]: $<-.data.frame $<- statistic boot
memtrace[0x914f5f8->0x914f670]: $<-.data.frame $<- statistic boot
memtrace[0x9abd5e0->0x972cbf0]: statistic boot
memtrace[0x972cbf0->0x972cc68]: $<-.data.frame $<- statistic boot
memtrace[0x972cc68->0x972cd08]: $<-.data.frame $<- statistic boot
memtrace[0x9abd5e0->0x98ead98]: statistic boot
memtrace[0x98ead98->0x98eae10]: $<-.data.frame $<- statistic boot
memtrace[0x98eae10->0x98eae88]: $<-.data.frame $<- statistic boot
@end smallexample

@noindent
The object is duplicated fifteen times, three times for each of the
@code{R+1} calls to @code{storm.bf}.  This is surprising, since none of the duplications happen inside @code{nls}. Stepping through @code{storm.bf} in the debugger shows that all three happen in the line

@smallexample
st$Time <- st$fit + rs[i]
@end smallexample

Data frames are slower than matrices and this is an example of why.
Using @code{tracemem(st$Viscosity)} does not reveal any additional
copying.

@node Profiling compiled code,  , Profiling R code for memory use, Tidying and profiling R code
@section Profiling compiled code
@cindex Profiling

Profiling compiled code is highly system-specific, but this section
contains some hints gleaned from various @R{} users.  Some methods need
to be different for a compiled executable and for dynamic/shared
libraries/objects as used by @R{} packages.  We know of no good way to
profile DLLs on Windows.

@menu
* Linux::                       
* Solaris::                     
* MacOS X::                     
@end menu

@node Linux, Solaris, Profiling compiled code, Profiling compiled code
@subsection Linux

Options include using @command{sprof} for a shared object, and
@command{oprofile} (see @url{http://oprofile.sourceforge.net/}) for any
executable or shared object.

@subsubsection sprof

You can select shared objects to be profiled with @command{sprof} by
setting the environment variable @env{LD_PROFILE}.  For example

@example
% setenv LD_PROFILE /path/to/R_HOME/library/stats/libs/stats.so
R 
... run the boot example
% sprof /path/to/R_HOME/library/stats/libs/stats.so \
  /var/tmp/path/to/R_HOME/library/stats/libs/stats.so.profile

Flat profile:

Each sample counts as 0.01 seconds.
  %   cumulative   self              self     total
 time   seconds   seconds    calls  us/call  us/call  name
 76.19      0.32     0.32        0     0.00           numeric_deriv
 16.67      0.39     0.07        0     0.00           nls_iter
  7.14      0.42     0.03        0     0.00           getListElement

rm /path/to/R_HOME/library/stats/libs/stats.so.profile
... to clean up ...
@end example

It is possible that root access is needed to create the directories used
for the profile data.

@subsubsection oprofile

@code{oprofile} works by running a daemon which collects information.
The daemon must be started as root, e.g.

@example
% su
% opcontrol --no-vmlinux
% opcontrol --start
% exit
@end example

Then as a user

@example
% R
... run the boot example
% opcontrol --dump
% opreport -l /path/to/R_HOME/library/stats/libs/stats.so
...
samples  %        symbol name
1623     75.5939  anonymous symbol from section .plt
349      16.2552  numeric_deriv
113       5.2632  nls_iter
62        2.8878  getListElement
% opreport -l /path/to/R_HOME/bin/exec/R
...
samples  %        symbol name
76052    11.9912  Rf_eval
54670     8.6198  Rf_findVarInFrame3
37814     5.9622  Rf_allocVector
31489     4.9649  Rf_duplicate
28221     4.4496  Rf_protect
26485     4.1759  Rf_cons
23650     3.7289  Rf_matchArgs
21088     3.3250  Rf_findFun
19995     3.1526  findVarLocInFrame
14871     2.3447  Rf_evalList
13794     2.1749  R_Newhashpjw
13522     2.1320  R_gc_internal
...
@end example

Shutting down the profiler and clearing the records needs to be done as
root.  You can use @command{opannotate} to annotate the source code with
the times spent in each section, if the appropriate source code was
compiled with debugging support.

@node Solaris, MacOS X, Linux, Profiling compiled code
@subsection Solaris

On 64-bit (only) Solaris, the standard profiling tool @command{gprof}
collects information from shared libraries compiled with @option{-pg}.

@node MacOS X,  , Solaris, Profiling compiled code
@subsection MacOS X

Developers have recommended @command{sample} (or @command{Sampler.app},
which is a GUI version) and @command{Shark} (see
@url{http://developer.apple.com/tools/sharkoptimize.html} and
@url{http://developer.apple.com/tools/shark_optimize.html}).


@node Debugging, System and foreign language interfaces, Tidying and profiling R code, Top
@chapter Debugging

This chapter covers the debugging of @R{} extensions, starting with the
ways to get useful error information and moving on to how to deal with
errors that crash @R{}.  For those who prefer other styles there are
contributed packages such as @pkg{debug} on CRAN (described in an
article in @url{http://cran.r-project.org/doc/Rnews/Rnews_2003-3.pdf,
R-News 3/3}).  (There are notes from 2002 provided by Roger Peng at
@url{http://www.biostat.jhsph.edu/~rpeng/docs/R-debug-tools.pdf} which
provide complementary examples to those given here.)

@menu
* Browsing::                    
* Debugging R code::            
* Using gctorture and valgrind::  
* Debugging compiled code::     
@end menu


@node Browsing, Debugging R code, Debugging, Debugging
@section Browsing

@findex browser
Most of the R-level debugging facilities are based around the built-in
browser.  This can be used directly by inserting a call to
@code{browser()} into the code of a function (for example, using
@code{fix(my_function)} ).  When code execution reaches that point in
the function, control returns to the @R{} console with a special prompt.
For example

@example
> fix(summary.data.frame) ## insert browser() call after for() loop
> summary(women)
Called from: summary.data.frame(women)
Browse[1]> ls()
 [1] "digits" "i"      "lbs"    "lw"     "maxsum" "nm"     "nr"     "nv"
 [9] "object" "sms"    "z"
Browse[1]> maxsum
[1] 7
Browse[1]>
     height         weight
 Min.   :58.0   Min.   :115.0
 1st Qu.:61.5   1st Qu.:124.5
 Median :65.0   Median :135.0
 Mean   :65.0   Mean   :136.7
 3rd Qu.:68.5   3rd Qu.:148.0
 Max.   :72.0   Max.   :164.0
> rm(summary.data.frame)
@end example

@noindent
At the browser prompt one can enter any @R{} expression, so for example
@code{ls()} lists the objects in the current frame, and entering the
name of an object will@footnote{With the exceptions of the commands
listed below: an object of such a name can be printed @emph{via} an
explicit call to @code{print}.} print it.  The following commands are
also accepted

@itemize @bullet
@item @code{n}

Enter `step-through' mode.  In this mode, hitting return executes the
next line of code (more precisely one line and any continuation lines).
Typing @code{c} will continue to the end of the current context, e.g.@:
to the end of the current loop or function.

@item @code{c}

In normal mode, this quits the browser and continues execution, and just
return works in the same way.  @code{cont} is a synonym.

@item @code{where}

This prints the call stack.  For example

@example
> summary(women)
Called from: summary.data.frame(women)
Browse[1]> where
where 1: summary.data.frame(women)
where 2: summary(women)

Browse[1]>
@end example

@item @code{Q}

Quit both the browser and the current expression, and return to the
top-level prompt.
@end itemize

Errors in code executed at the browser prompt will normally return
control to the browser prompt.  Objects can be altered by assignment,
and will keep their changed values when the browser is exited.  If
really necessary, objects can be assigned to the workspace from the
browser prompt (by using @code{<<-} if the name is not already in
scope).

@node Debugging R code, Using gctorture and valgrind, Browsing, Debugging
@section Debugging R code

@findex traceback
Suppose your @R{} program gives an error message.  The first thing to
find out is what @R{} was doing at the time of the error, and the most
useful tool is @code{traceback()}.  We suggest that this is run whenever
the cause of the error is not immediately obvious.  Daily, errors are
reported to the @R{} mailing lists as being in some package when
@code{traceback()} would show that the error was being reported by some
other package or base @R{}.  Here is an example from the regression
suite.

@smallexample
> success <- c(13,12,11,14,14,11,13,11,12)
> failure <- c(0,0,0,0,0,0,0,2,2)
> resp <- cbind(success, failure)
> predictor <- c(0, 5^(0:7))
> glm(resp ~ 0+predictor, family = binomial(link="log"))
Error: no valid set of coefficients has been found: please supply starting values
> traceback()
3: stop("no valid set of coefficients has been found: please supply 
         starting values", call. = FALSE)
2: glm.fit(x = X, y = Y, weights = weights, start = start, etastart = etastart,
       mustart = mustart, offset = offset, family = family, control = control,
       intercept = attr(mt, "intercept") > 0)
1: glm(resp ~ 0 + predictor, family = binomial(link ="log"))
@end smallexample

@noindent
The calls to the active frames are given in reverse order (starting with
the innermost).  So we see the error message comes from an explicit
check in @code{glm.fit}.  (@code{traceback()} shows you all the lines of
the function calls, which can be limited by setting @code{option}
@option{"deparse.max.lines"}.)

Sometimes the traceback will indicate that the error was detected inside
compiled code, for example (from @code{?nls})

@smallexample
Error in nls(y ~ a + b * x, start = list(a = 0.12345, b = 0.54321), trace = TRUE) :
        step factor 0.000488281 reduced below 'minFactor' of 0.000976563
>  traceback()
2: .Call(R_nls_iter, m, ctrl, trace)
1: nls(y ~ a + b * x, start = list(a = 0.12345, b = 0.54321), trace = TRUE)
@end smallexample

@noindent
This will be the case if the innermost call is to @code{.C},
@code{.Fortran}, @code{.Call}, @code{.External} or @code{.Internal}, but
as it is also possible for such code to evaluate @R{} expressions, this
need not be the innermost call, as in

@smallexample
> traceback()
9: gm(a, b, x)
8: .Call(R_numeric_deriv, expr, theta, rho, dir)
7: numericDeriv(form[[3]], names(ind), env)
6: getRHS()
5: assign("rhs", getRHS(), envir = thisEnv)
4: assign("resid", .swts * (lhs - assign("rhs", getRHS(), envir = thisEnv)),
       envir = thisEnv)
3: function (newPars)
   @{
       setPars(newPars)
       assign("resid", .swts * (lhs - assign("rhs", getRHS(), envir = thisEnv)),
           envir = thisEnv)
       assign("dev", sum(resid^2), envir = thisEnv)
       assign("QR", qr(.swts * attr(rhs, "gradient")), envir = thisEnv)
       return(QR$rank < min(dim(QR$qr)))
   @}(c(-0.00760232418963883, 1.00119632515036))
2: .Call(R_nls_iter, m, ctrl, trace)
1: nls(yeps ~ gm(a, b, x), start = list(a = 0.12345, b = 0.54321))
@end smallexample

Occasionally @code{traceback()} does not help, and this can be the case
if S4 method dispatch is involved.  Consider the following example

@example
> xyd <- new("xyloc", x=runif(20), y=runif(20))
Error in as.environment(pkg) : no item called "package:S4nswv" 
on the search list
Error in initialize(value, ...) : S language method selection got 
an error when called from internal dispatch for function 'initialize'
> traceback()
2: initialize(value, ...)
1: new("xyloc", x = runif(20), y = runif(20))
@end example

@noindent
which does not help much, as there is no call to @code{as.environment}
in @code{initialize} (and the note ``called from internal dispatch''
tells us so).  In this case we searched the @R{} sources for the quoted
call, which occurred in only one place,
@code{methods:::.asEnvironmentPackage}.  So now we knew where the
error was occurring.  (This was an unusually opaque example.)

The error message

@example
evaluation nested too deeply: infinite recursion / options(expressions=)?
@end example

@noindent
can be hard to handle with the default value (5000).  Unless you know
that there actually is deep recursion going on, it can help to set
something like

@example
options(expressions=500)
@end example

@noindent and re-run the example showing the error.

Sometimes there is warning that clearly is the precursor to some later
error, but it is not obvious where it is coming from.  Setting
@command{options(warn = 2)} (which turns warnings into errors) can help here.

Once we have located the error, we have some choices.  One way to proceed
is to find out more about what was happening at the time of the crash by
looking a @emph{post-mortem} dump.  To do so, set
@findex dump.frames
@command{options(error=dump.frames)} and run the code again.  Then invoke
@command{debugger()} and explore the dump.  Continuing our example:

@smallexample
> options(error = dump.frames)
> glm(resp ~ 0 + predictor, family = binomial(link ="log"))
Error: no valid set of coefficients has been found: please supply starting values
@end smallexample

@noindent
which is the same as before, but an object called @code{last.dump} has
appeared in the workspace.  (Such objects can be large, so remove it
when it is no longer needed.)  We can examine this at a later time by
calling the function @code{debugger}.
@findex debugger

@smallexample
> debugger()
Message:  Error: no valid set of coefficients has been found: please supply starting values
Available environments had calls:
1: glm(resp ~ 0 + predictor, family = binomial(link = "log"))
2: glm.fit(x = X, y = Y, weights = weights, start = start, etastart = etastart, mus
3: stop("no valid set of coefficients has been found: please supply starting values
Enter an environment number, or 0 to exit  Selection:
@end smallexample

@noindent
which gives the same sequence of calls as @code{traceback}, but in
outer-first order and with only the first line of the call, truncated to
the current width.  However, we can now examine in more detail what was
happening at the time of the error.  Selecting an environment opens the
browser in that frame.  So we select the function call which spawned the
error message, and explore some of the variables (and execute two
function calls).

@smallexample
Enter an environment number, or 0 to exit  Selection: 2
Browsing in the environment with call:
   glm.fit(x = X, y = Y, weights = weights, start = start, etas
Called from: debugger.look(ind)
Browse[1]> ls()
 [1] "aic"        "boundary"   "coefold"    "control"    "conv"
 [6] "dev"        "dev.resids" "devold"     "EMPTY"      "eta"
[11] "etastart"   "family"     "fit"        "good"       "intercept"
[16] "iter"       "linkinv"    "mu"         "mu.eta"     "mu.eta.val"
[21] "mustart"    "n"          "ngoodobs"   "nobs"       "nvars"
[26] "offset"     "start"      "valideta"   "validmu"    "variance"
[31] "varmu"      "w"          "weights"    "x"          "xnames"
[36] "y"          "ynames"     "z"
Browse[1]> eta
            1             2             3             4             5
 0.000000e+00 -2.235357e-06 -1.117679e-05 -5.588393e-05 -2.794197e-04
            6             7             8             9
-1.397098e-03 -6.985492e-03 -3.492746e-02 -1.746373e-01
Browse[1]> valideta(eta)
[1] TRUE
Browse[1]> mu
        1         2         3         4         5         6         7         8
1.0000000 0.9999978 0.9999888 0.9999441 0.9997206 0.9986039 0.9930389 0.9656755
        9
0.8397616
Browse[1]> validmu(mu)
[1] FALSE
Browse[1]> c
Available environments had calls:
1: glm(resp ~ 0 + predictor, family = binomial(link = "log"))
2: glm.fit(x = X, y = Y, weights = weights, start = start, etastart = etastart
3: stop("no valid set of coefficients has been found: please supply starting v

Enter an environment number, or 0 to exit  Selection: 0
> rm(last.dump)
@end smallexample

Because @code{last.dump} can be looked at later or even in another @R{}
session, post-mortem debugging is possible even for batch usage of @R{}.
We do need to arrange for the dump to be saved: this can be done either
using the command-line flag @option{--save} to save the workspace at the
end of the run, or via a setting such as

@example
> options(error = quote(@{dump.frames(to.file=TRUE); q()@}))
@end example

@noindent
See the help on @code{dump.frames} for further options and a worked
example.

@findex recover
An alternative error action is to use the function @command{recover()}:

@smallexample
> options(error = recover)
> glm(resp ~ 0 + predictor, family = binomial(link = "log"))
Error: no valid set of coefficients has been found: please supply starting values

Enter a frame number, or 0 to exit

1: glm(resp ~ 0 + predictor, family = binomial(link = "log"))
2: glm.fit(x = X, y = Y, weights = weights, start = start, etastart = etastart

Selection:
@end smallexample

@noindent
which is very similar to @code{dump.frames}.  However, we can examine
the state of the program directly, without dumping and re-loading the
dump.  As its help page says, @code{recover} can be routinely used as
the error action in place of @code{dump.calls} and @code{dump.frames},
since it behaves like @code{dump.frames} in non-interactive use.


@findex debug
Post-mortem debugging is good for finding out exactly what went wrong,
but not necessarily why.  An alternative approach is to take a closer
look at what was happening just before the error, and a good way to do
that is to use @command{debug}.  This inserts a call to the browser
at the beginning of the function, starting in step-through mode.  So in
our example we could use

@smallexample
> debug(glm.fit)
> glm(resp ~ 0 + predictor, family = binomial(link ="log"))
debugging in: glm.fit(x = X, y = Y, weights = weights, start = start, etastart = etastart,
    mustart = mustart, offset = offset, family = family, control = control,
    intercept = attr(mt, "intercept") > 0)
debug: @{
## lists the whole function
Browse[1]>
debug: x <- as.matrix(x)
...
Browse[1]> start
[1] -2.235357e-06
debug: eta <- drop(x %*% start)
Browse[1]> eta
            1             2             3             4             5
 0.000000e+00 -2.235357e-06 -1.117679e-05 -5.588393e-05 -2.794197e-04
            6             7             8             9
-1.397098e-03 -6.985492e-03 -3.492746e-02 -1.746373e-01
Browse[1]>
debug: mu <- linkinv(eta <- eta + offset)
Browse[1]> mu
        1         2         3         4         5         6         7         8
1.0000000 0.9999978 0.9999888 0.9999441 0.9997206 0.9986039 0.9930389 0.9656755
        9
0.8397616
@end smallexample

@noindent
(The prompt @code{Browse[1]>} indicates that this is the first level of
browsing: it is possible to step into another function that is itself
being debugged or contains a call to @code{browser()}.)

@code{debug} can be used for hidden functions and S3 methods by
e.g.@: @code{debug(stats:::predict.Arima)}.  (It cannot be used for S4
methods, but an alternative is given on the help page for @code{debug}.)
Sometimes you want to debug a function defined inside another function,
e.g.@: the function @code{arimafn} defined inside @code{arima}.  To do so,
set @code{debug} on the outer function (here @code{arima}) and
step through it until the inner function has been defined.  Then
call @code{debug} on the inner function (and use @code{c} to get out of
step-through mode in the outer function).

@findex undebug
To remove debugging of a function, call @code{undebug} with the argument
previously given to @code{debug}; debugging otherwise lasts for the rest
of the @R{} session (or until the function is edited or otherwise
replaced).

@findex trace
@code{trace} can be used to temporarily insert debugging code into a
function, for example to insert a call to @code{browser()} just before
the point of the error.  To return to our running example

@example
## first get a numbered listing of the expressions of the function
> page(as.list(body(glm.fit)), method="print")
> trace(glm.fit, browser, at=22)
Tracing function "glm.fit" in package "stats"
[1] "glm.fit"
> glm(resp ~ 0 + predictor, family = binomial(link ="log"))
Tracing glm.fit(x = X, y = Y, weights = weights, start = start, 
   etastart = etastart,  .... step 22
Called from: eval(expr, envir, enclos)
Browse[1]> n
## and single-step from here.
> untrace(glm.fit)
@end example
@noindent
For your own functions, it may be as easy to use @code{fix} to insert
temporary code, but @code{trace} can help with functions in a name space
(as can @code{fixInNamespace}).  Alternatively, use
@code{trace(,edit=TRUE)} to insert code visually.


@node Using gctorture and valgrind, Debugging compiled code, Debugging R code, Debugging
@section Using gctorture and valgrind

Errors in memory allocation and reading/writing outside arrays are very
common causes of crashes (e.g.,@: segfaults) on some machines.  Often
the crash appears long after the invalid memory access: in particular
damage to the structures which @R{} itself has allocated may only become
apparent at the next garbage collection (or even at later garbage
collections after objects have been deleted).

@menu
* Using gctorture::             
* Using valgrind::              
@end menu

@node Using gctorture, Using valgrind, Using gctorture and valgrind, Using gctorture and valgrind
@subsection Using gctorture

@findex gctorture
We can help to detect memory problems earlier by running garbage
collection as often as possible.  This is achieved by
@code{gctorture(TRUE)}, which as described on its help page

@quotation
Provokes garbage collection on (nearly) every memory allocation.
Intended to ferret out memory protection bugs.  Also makes @R{} run
@emph{very} slowly, unfortunately.
@end quotation

@noindent
The reference to `memory protection' is to missing C-level calls to
@code{PROTECT}/@code{UNPROTECT} (@pxref{Garbage Collection}) which if
missing allow @R{} objects to be garbage-collected when they are still
in use.  But it can also help with other memory-related errors.

Normally running under @code{gctorture(TRUE)} will just produce a crash
earlier in the @R{} program, hopefully close to the actual cause. See
the next section for how to decipher such crashes.

It is possible to run all the examples, tests and vignettes covered by
@code{R CMD check} under @code{gctorture(TRUE)} by using the option
@option{--use-gct}. 

@node Using valgrind,  , Using gctorture, Using gctorture and valgrind
@subsection Using valgrind

If you have access to Linux on an @code{ix86}, @code{x86_64} or
@code{ppc32} platform you can use @code{valgrind}
(@url{http://www.valgrind.org/}, pronounced to rhyme with `tinned') to
check for possible problems.  To run some examples under @code{valgrind}
use something like

@example
R -d valgrind --vanilla < mypkg-Ex.R
R -d "valgrind --tool=memcheck --leak-check=full" --vanilla < mypkg-Ex.R
@end example

@noindent
where @file{mypkg-Ex.R} is a set of examples, e.g.@: the file created in
@file{mypkg.Rcheck} by @code{R CMD check}.  Occasionally this reports
memory reads of `uninitialised values' that are the result of compiler
optimization, so can be worth checking under an unoptimized compile.  We
know there will be some small memory leaks from @code{readline} and @R{}
itself --- these are memory areas that are in use right up to the end of
the @R{} session.  Expect this to run around 20x slower than without
@code{valgrind}, and in some cases even slower than that.  Current
versions@footnote{Although this is supposed to have been improved,
@code{valgrind} 3.2.0 still aborts using optimized BLASes on an
Opteron.} of @code{valgrind} are not happy with many optimized BLASes
that use cpu-specific instructions (3D now, SSE, SSE2, SSE3 and similar)
so you may need to build a version of @R{} specifically to use with
@code{valgrind}.

On platforms supported by @code{valgrind} you can build a version of
@R{} with extra instrumentation to help @code{valgrind} detect errors in
the use of memory allocated from the @R{} heap.  The configure option is
@option{--with-valgrind-instrumentation=@var{level}}, where @var{level}
is 0, 1, or 2.  Level 0 is the default and does not add any anything.
Level 1 will detect use of uninitialised memory and has little impact on
speed. Level 2 will detect many other memory use bugs but makes @R{}
much slower when running under @code{valgrind}.  Using this in
conjuction with @code{gctorture} can be even more effective (and even
slower).

An example of @code{valgrind} output is
@smallexample
==12539== Invalid read of size 4
==12539==    at 0x1CDF6CBE: csc_compTr (Mutils.c:273)
==12539==    by 0x1CE07E1E: tsc_transpose (dtCMatrix.c:25)
==12539==    by 0x80A67A7: do_dotcall (dotcode.c:858)
==12539==    by 0x80CACE2: Rf_eval (eval.c:400)
==12539==    by 0x80CB5AF: R_execClosure (eval.c:658)
==12539==    by 0x80CB98E: R_execMethod (eval.c:760)
==12539==    by 0x1B93DEFA: R_standardGeneric (methods_list_dispatch.c:624)
==12539==    by 0x810262E: do_standardGeneric (objects.c:1012)
==12539==    by 0x80CAD23: Rf_eval (eval.c:403)
==12539==    by 0x80CB2F0: Rf_applyClosure (eval.c:573)
==12539==    by 0x80CADCC: Rf_eval (eval.c:414)
==12539==    by 0x80CAA03: Rf_eval (eval.c:362)
==12539==  Address 0x1C0D2EA8 is 280 bytes inside a block of size 1996 alloc'd
==12539==    at 0x1B9008D1: malloc (vg_replace_malloc.c:149)
==12539==    by 0x80F1B34: GetNewPage (memory.c:610)
==12539==    by 0x80F7515: Rf_allocVector (memory.c:1915)
...
@end smallexample
@noindent
This example is from an instrumented version of @R{}, while tracking
down a bug in the @pkg{Matrix} package in January, 2006.  The first line
indicates that @R{} has tried to read 4 bytes from a memory address that
it does not have access to. This is followed by a C stack trace showing
where the error occurred. Next is a description of the memory that was
accessed. It is inside a block allocated by @code{malloc}, called from
@code{GetNewPage}, that is, in the internal @R{} heap.  Since this
memory all belongs to @R{}, @code{valgrind} would not (and did not)
detect the problem in an uninstrumented build of @R{}.  In this example
the stack trace was enough to isolate and fix the bug, which was in
@code{tsc_transpose}, and in this example running under
@code{gctorture()} did not provide any additional information.  When the
stack trace is not sufficiently informative the option
@option{--db-attach=yes} to @code{valgrind} may be helpful.  This starts
a post-mortem debugger (by default @code{gdb}) so that variables in the
C code can be inspected (@pxref{Inspecting R objects}).


It is possible to run all the examples, tests and vignettes covered by
@code{R CMD check} under @code{valgrind} by using the option
@option{--use-valgrind}.  If you do this you will need to select the
@code{valgrind} options some other way, for example by having a
@file{~/.valgrindrc} file containing

@example
--tool=memcheck
--memcheck:leak-check=full
@end example

@noindent
or setting the environment variable @env{VALGRIND_OPTS}.

@node Debugging compiled code,  , Using gctorture and valgrind, Debugging
@section Debugging compiled code
@cindex Debugging


Sooner or later programmers will be faced with the need to debug
compiled code loaded into @R{}.   This section is geared to platforms
using @command{gdb} with code compiled by @code{gcc}, but similar things
are possible with front-ends to @command{gdb} such as @command{ddd} and
@command{insight}, and other debuggers such as Sun's @command{dbx}.

Consider first `crashes', that is when @R{} terminated unexpectedly with
an illegal memory access (a `segfault' or `bus error'), illegal
instruction or similar.  Unix-alike versions of @R{} use a signal
handler which aims to give some basic information.  For example

@example
 *** caught segfault ***
address 0x20000028, cause 'memory not mapped'

Traceback:
 1: .identC(class1[[1]], class2)
 2: possibleExtends(class(sloti), classi, ClassDef2 = getClassDef(classi,
where = where))
 3: validObject(t(cu))
 4: stopifnot(validObject(cu <- as(tu, "dtCMatrix")), validObject(t(cu)),
validObject(t(tu)))

Possible actions:
1: abort (with core dump)
2: normal R exit
3: exit R without saving workspace
4: exit R saving workspace
Selection: 3
@end example

@noindent
Since the @R{} process may be damaged, the only really safe option is
the first.

Another cause of a `crash' is to overrun the C stack.  @R{} tries to
track that in its own code, but it may happen in third-party compiled
code.  For modern POSIX-compilant OSes we can safely catch that and
return to the top-level prompt.

@example
> .C("aaa")
Error: segfault from C stack overflow
>
@end example

@noindent
However, C stack overflows are fatal under Windows and normally defeat
attempts at debugging on that platform.

If you have a crash which gives a core dump you can use something like

@example
gdb /path/to/R/bin/exec/R core.12345
@end example

@noindent
to examine the core dump.  If core dumps are disabled or to catch errors
that do not generate a dump one can run @R{} directly under a debugger
by for example

@example
$ R -d gdb --vanilla
...
gdb> run
@end example

@noindent
at which point @R{} will run normally, and hopefully the debugger will
catch the error and return to its prompt.  This can also be used to
catch infinite loops or interrupt very long-running code.  For a simple
example

@example
> for(i in 1:1e7) x <- rnorm(100)
[hit Ctrl-C]
Program received signal SIGINT, Interrupt.
0x00397682 in _int_free () from /lib/tls/libc.so.6
(gdb) where
#0  0x00397682 in _int_free () from /lib/tls/libc.so.6
#1  0x00397eba in free () from /lib/tls/libc.so.6
#2  0xb7cf2551 in R_gc_internal (size_needed=313)
    at /users/ripley/R/svn/R-devel/src/main/memory.c:743
#3  0xb7cf3617 in Rf_allocVector (type=13, length=626)
    at /users/ripley/R/svn/R-devel/src/main/memory.c:1906
#4  0xb7c3f6d3 in PutRNGstate ()
    at /users/ripley/R/svn/R-devel/src/main/RNG.c:351
#5  0xb7d6c0a5 in do_random2 (call=0x94bf7d4, op=0x92580e8, args=0x9698f98,
    rho=0x9698f28) at /users/ripley/R/svn/R-devel/src/main/random.c:183
...
@end example

Some ``tricks'' are worth knowing.

@menu
* Finding entry points::        
* Inspecting R objects::        
@end menu

@node Finding entry points, Inspecting R objects, Debugging compiled code, Debugging compiled code
@subsection Finding entry points in dynamically loaded code

Under most compilation environments, compiled code dynamically loaded
into @R{} cannot have breakpoints set within it until it is loaded.  To
use a symbolic debugger on such dynamically loaded code under
Unix-alikes use

@itemize @bullet
@item
Call the debugger on the @R{} executable, for example by @kbd{R -d gdb}.
@item
Start @R{}.
@item
At the @R{} prompt, use @code{dyn.load} or @code{library} to load your
shared object.
@item
Send an interrupt signal.  This will put you back to the debugger
prompt.
@item
Set the breakpoints in your code.
@item
Continue execution of @R{} by typing @kbd{signal 0@key{RET}}.
@end itemize

Under Windows signals may not be able to be used, and if so the procedure is
more complicated.  See the rw-FAQ and
@uref{http://www.stats.uwo.ca/faculty/murdoch/software/debuggingR/gdb.shtml,
@code{www.stats.uwo.ca/faculty/murdoch/@/software/@/debuggingR/@/gdb.shtml}}.


@node Inspecting R objects,  , Finding entry points, Debugging compiled code
@subsection Inspecting R objects when debugging
@cindex Inspecting R objects when debugging

The key to inspecting @R{} objects from compiled code is the function
@code{PrintValue(SEXP @var{s})} which uses the normal @R{} printing
mechanisms to print the @R{} object pointed to by @var{s}, or the safer
version @code{R_PV(SEXP @var{s})} which will only print `objects'.

One way to make use of @code{PrintValue} is to insert suitable calls
into the code to be debugged.

Another way is to call @code{R_PV} from the symbolic debugger.
(@code{PrintValue} is hidden as @code{Rf_PrintValue}.)  For example,
from @code{gdb} we can use

@example
(gdb) p R_PV(ab)
@end example

@noindent
using the object @code{ab} from the convolution example, if we have
placed a suitable breakpoint in the convolution C code.

To examine an arbitrary @R{} object we need to work a little harder.
For example, let

@example
R> DF <- data.frame(a = 1:3, b = 4:6)
@end example

@noindent
By setting a breakpoint at @code{do_get} and typing @kbd{get("DF")} at
the @R{} prompt, one can find out the address in memory of @code{DF}, for
example

@example
@group
Value returned is $1 = (SEXPREC *) 0x40583e1c
(gdb) p *$1
$2 = @{
  sxpinfo = @{type = 19, obj = 1, named = 1, gp = 0,
    mark = 0, debug = 0, trace = 0, = 0@},
  attrib = 0x40583e80,
  u = @{
    vecsxp = @{
      length = 2,
      type = @{c = 0x40634700 "0>X@@D>X@@0>X@@", i = 0x40634700,
        f = 0x40634700, z = 0x40634700, s = 0x40634700@},
      truelength = 1075851272,
    @},
    primsxp = @{offset = 2@},
    symsxp = @{pname = 0x2, value = 0x40634700, internal = 0x40203008@},
    listsxp = @{carval = 0x2, cdrval = 0x40634700, tagval = 0x40203008@},
    envsxp = @{frame = 0x2, enclos = 0x40634700@},
    closxp = @{formals = 0x2, body = 0x40634700, env = 0x40203008@},
    promsxp = @{value = 0x2, expr = 0x40634700, env = 0x40203008@}
  @}
@}
@end group
@end example

@noindent
(Debugger output reformatted for better legibility).

Using @code{R_PV()} one can ``inspect'' the values of the various
elements of the SEXP, for example,

@example
@group
(gdb) p R_PV($1->attrib)
$names
[1] "a" "b"

$row.names
[1] "1" "2" "3"

$class
[1] "data.frame"

$3 = void
@end group
@end example

To find out where exactly the corresponding information is stored, one
needs to go ``deeper'':

@example
@group
(gdb) set $a = $1->attrib
(gdb) p $a->u.listsxp.tagval->u.symsxp.pname->u.vecsxp.type.c
$4 = 0x405d40e8 "names"
(gdb) p $a->u.listsxp.carval->u.vecsxp.type.s[1]->u.vecsxp.type.c
$5 = 0x40634378 "b"
(gdb) p $1->u.vecsxp.type.s[0]->u.vecsxp.type.i[0]
$6 = 1
(gdb) p $1->u.vecsxp.type.s[1]->u.vecsxp.type.i[1]
$7 = 5
@end group
@end example


@node System and foreign language interfaces, The R API, Debugging, Top
@chapter System and foreign language interfaces

@menu
* Operating system access::     
* Interface functions .C and .Fortran::  
* dyn.load and dyn.unload::     
* Registering native routines::  
* Creating shared objects::     
* Interfacing C++ code::        
* Handling R objects in C::     
* Interface functions .Call and .External::  
* Evaluating R expressions from C::  
* Parsing R code from C::       
* External pointers and weak references::  
* Vector accessor functions::   
* Character encoding issues::   
@end menu

@node  Operating system access, Interface functions .C and .Fortran, System and foreign language interfaces, System and foreign language interfaces
@section  Operating system access
@cindex Operating system access

Access to operating system functions is via the @R{} function
@code{system}.
@findex system
The details will differ by platform (see the on-line help), and about
all that can safely be assumed is that the first argument will be a
string @code{command} that will be passed for execution (not necessarily
by a shell) and the second argument will be @code{internal} which if
true will collect the output of the command into an @R{} character
vector.

The function @code{system.time}
@findex system.time
is available for timing (although the information available may be
limited on non-Unix-like platforms).

@node Interface functions .C and .Fortran, dyn.load and dyn.unload, Operating system access, System and foreign language interfaces
@section Interface functions @code{.C} and @code{.Fortran}
@cindex Interfaces to compiled code

@findex .C
@findex .Fortran

These two functions provide a standard interface to compiled code that
has been linked into @R{}, either at build time or via @code{dyn.load}
(@pxref{dyn.load and dyn.unload}).  They are primarily intended for
compiled C and FORTRAN 77 code respectively, but the @code{.C} function can
be used with other languages which can generate C interfaces, for
example C++ (@pxref{Interfacing C++ code}).

The first argument to each function is a character string given the
symbol name as known to C or FORTRAN, that is the function or subroutine
name.  (That the symbol is loaded can be tested by, for example,
@code{is.loaded("cg")}: it is no longer necessary nor correct to use
@code{symbol.For}, which is defunct as from @R{} 2.5.0.)  (Note that the
underscore is not a valid character in a FORTRAN 77 subprogram name, and
on versions of @R{} prior to 2.4.0 @code{.Fortran} may not correctly
translate names containing underscores.)

There can be up to 65 further arguments giving @R{} objects to be passed
to compiled code.  Normally these are copied before being passed in, and
copied again to an @R{} list object when the compiled code returns.  If
the arguments are given names, these are used as names for the
components in the returned list object (but not passed to the compiled
code).

The following table gives the mapping between the modes of @R{} vectors
and the types of arguments to a C function or FORTRAN subroutine.

@quotation
@multitable {RRR storage.mode} {RRR unsigned char * RR} {DOUBLE PRECISION}
@headitem @R{} storage mode @tab  C type  @tab   FORTRAN type
@item @code{logical}   @tab @code{int *}     @tab @code{INTEGER}
@item @code{integer}   @tab @code{int *}     @tab @code{INTEGER}
@item @code{double}    @tab @code{double *}  @tab @code{DOUBLE PRECISION}
@item @code{complex}   @tab @code{Rcomplex *} @tab @code{DOUBLE COMPLEX}
@item @code{character} @tab @code{char **}   @tab @code{CHARACTER*255}
@item @code{raw}       @tab @code{unsigned char *}    @tab none
@end multitable
@end quotation

Do please note the first two.  On the 64-bit Unix/Linux platforms,
@code{long} is 64-bit whereas @code{int} and @code{INTEGER} are 32-bit.
Code ported from S-PLUS (which uses @code{long *} for @code{logical} and
@code{integer}) will not work on all 64-bit platforms (although it may
appear to work on some).  Note also that if your compiled code is a
mixture of C functions and FORTRAN subprograms the argument types must
match as given in the table above.

C type @code{Rcomplex} is a structure with @code{double} members
@code{r} and @code{i} defined in the header file @file{R_ext/Complex.h}
included by @file{R.h}.  (On most platforms which have it, this is
compatible withe C99 @code{double complex} type.)  Only a single
character string can be passed to or from FORTRAN, and the success of
this is compiler-dependent.  Other @R{} objects can be passed to
@code{.C}, but it is better to use one of the other interfaces.  An
exception is passing an @R{} function for use with @w{@code{call_R}},
when the object can be handled as @code{void *} en route to
@code{call_R}, but even there @code{.Call} is to be preferred.
Similarly, passing an @R{} list as an argument to a C routine should be
done using the @code{.Call} interface.  If one does use the @code{.C}
function to pass a list as an argument, it is visible to the routine as
an array in C of @code{SEXP} types (i.e., @code{SEXP *}).  The elements
of the array correspond directly to the elements of the @R{} list.
However, this array must be treated as read-only and one must not assign
values to its elements within the C routine --- doing so bypasses R's
memory management facilities and will corrupt the object and the R
session.

It is possible to pass numeric vectors of storage mode @code{double} to
C as @code{float *} or to FORTRAN as @code{REAL} by setting the
attribute @code{Csingle}, most conveniently by using the @R{} functions
@code{as.single}, @code{single} or @code{mode}.  This is intended only
to be used to aid interfacing to existing C or FORTRAN code.

Unless formal argument @code{NAOK} is true, all the other arguments are
checked for missing values @code{NA} and for the @acronym{IEEE} special
values @code{NaN}, @code{Inf} and @code{-Inf}, and the presence of any
of these generates an error.  If it is true, these values are passed
unchecked.

Argument @code{DUP} can be used to suppress copying.  It is dangerous:
see the on-line help for arguments against its use.  It is not possible
to pass numeric vectors as @code{float *} or @code{REAL} if
@code{DUP=FALSE}.

Argument @code{PACKAGE} confines the search for the symbol name to a
specific shared object (or use @code{"base"} for code compiled into
@R{}).  Its use is highly desirable, as there is no way to avoid two
package writers using the same symbol name, and such name clashes are
normally sufficient to cause @R{} to crash.  (If it is not present and
the call is from the body of a function defined in a package with a
name space, the shared object loaded by the first (if any)
@code{useDynLib} directive will be used.)

For @code{.C} only you can specify an @code{ENCODING} argument: this
requests that (unless @code{DUP = FALSE}) character vectors be
re-encoded to the requested encoding before being passed in, and
re-encoded from the requested encoding when passed back.  Note that
encoding names are not standardized, and not all @R{} builds support
re-encoding. (The argument is ignored with a warning if re-encoding is
not supported at all: @R{} code can test for this @emph{via}
@code{capabilities("iconv")}.)  But this can be useful to allow code to
work in a UTF-8 locale by specifying @code{ENCODING = "latin1"}.

Note that the compiled code should not return anything except through
its arguments: C functions should be of type @code{void} and FORTRAN
subprograms should be subroutines.

To fix ideas, let us consider a very simple example which convolves two
finite sequences. (This is hard to do fast in interpreted @R{} code, but
easy in C code.)  We could do this using @code{.C} by

@example
@group
void convolve(double *a, int *na, double *b, int *nb, double *ab)
@{
  int i, j, nab = *na + *nb - 1;

  for(i = 0; i < nab; i++)
    ab[i] = 0.0;
  for(i = 0; i < *na; i++)
    for(j = 0; j < *nb; j++)
      ab[i + j] += a[i] * b[j];
@}
@end group
@end example

@noindent
called from @R{} by

@example
@group
conv <- function(a, b)
  .C("convolve",
     as.double(a),
     as.integer(length(a)),
     as.double(b),
     as.integer(length(b)),
     ab = double(length(a) + length(b) - 1))$ab
@end group
@end example

Note that we take care to coerce all the arguments to the correct @R{}
storage mode before calling @code{.C}; mistakes in matching the types
can lead to wrong results or hard-to-catch errors.


@node dyn.load and dyn.unload, Registering native routines, Interface functions .C and .Fortran, System and foreign language interfaces
@section @code{dyn.load} and @code{dyn.unload}
@cindex Dynamic loading

@findex dyn.load
@findex dyn.unload

Compiled code to be used with @R{} is loaded as a shared object (Unix
and MacOS X, @pxref{Creating shared objects} for more information) or
DLL (Windows).

The shared object/DLL is loaded by @code{dyn.load} and unloaded by
@code{dyn.unload}.  Unloading is not normally necessary, but it is
needed to allow the DLL to be re-built on some platforms, including
Windows.

The first argument to both functions is a character string giving the
path to the object.  Programmers should not assume a specific file
extension for the object/DLL (such as @file{.so}) but use a construction
like

@example
file.path(path1, path2, paste("mylib", .Platform$dynlib.ext, sep=""))
@end example

@noindent
for platform independence.  On Unix-alike systems the path supplied to
@code{dyn.load} can be an absolute path, one relative to the current
directory or, if it starts with @samp{~}, relative to the user's home
directory.

Loading is most often done via a call to @code{library.dynam}
@findex library.dynam
in the @code{.First.lib} function of a package.  This has the form

@example
library.dynam("libname", package, lib.loc)
@end example

@noindent
where @code{libname} is the object/DLL name @emph{with the extension
omitted}.  Note that the first argument, @code{chname}, should
@strong{not} be @code{package} since this will not work if the package
is installed under another name (as it will be with a versioned install).

Under some Unix-alike systems there is a choice of how the symbols are
resolved when the object is loaded, governed by the arguments
@code{local} and @code{now}.  Only use these if really necessary: in
particular using @code{now=FALSE} and then calling an unresolved symbol
will terminate @R{} unceremoniously.

@R{} provides a way of executing some code automatically when a object/DLL
is either loaded or unloaded.  This can be used, for example, to
register native routines with @R{}'s dynamic symbol mechanism, initialize
some data in the native code, or initialize a third party library.  On
loading a DLL, @R{} will look for a routine within that DLL named
@code{R_init_@var{lib}} where @var{lib} is the name of the DLL file with
the extension removed.  For example, in the command

@example
library.dynam("mylib", package, lib.loc)
@end example

@noindent
R looks for the symbol named @code{R_init_mylib}.  Similarly, when
unloading the object, @R{} looks for a routine named
@code{R_unload_@var{lib}}, e.g., @code{R_unload_mylib}.  In either case,
if the routine is present, @R{} will invoke it and pass it a single
argument describing the DLL.  This is a value of type @code{DllInfo}
which is defined in the @file{Rdynload.h} file in the @file{R_ext}
directory.

The following example shows templates for the initialization and
unload routines for the @code{mylib} DLL.

@quotation
@cartouche
@example
#include <R.h>
#include <Rinternals.h>
#include <R_ext/Rdynload.h>

void
R_init_mylib(DllInfo *info)
@{
  /* Register routines, allocate resources. */
@}

void
R_unload_mylib(DllInfo *info)
@{
  /* Release resources. */
@}
@end example
@end cartouche
@end quotation

If a shared object/DLL is loaded more than once the most recent version is
used.  More generally, if the same symbol name appears in several
libraries, the most recently loaded occurrence is used.  The
@code{PACKAGE} argument provides a good way to avoid any ambiguity in
which occurrence is meant.


@node Registering native routines, Creating shared objects, dyn.load and dyn.unload, System and foreign language interfaces
@section Registering native routines
@cindex Registering native routines

By `native' routine, we mean an entry point in compiled code.

In calls to @code{.C}, @code{.Call}, @code{.Fortran} and
@code{.External}, @R{} must locate the specified native routine by looking
in the appropriate shared object/DLL.  By default, @R{} uses the operating
system-specific dynamic loader to lookup the symbol.  Alternatively, the
author of the DLL can explicitly register routines with @R{} and use a
single, platform-independent mechanism for finding the routines in the
DLL.  One can use this registration mechanism to provide additional
information about a routine, including the number and type of the
arguments, and also make it available to @R{} programmers under a different
name.  In the future, registration may be used to implement a form of
``secure'' or limited native access.

To register routines with @R{}, one calls the C routine
@code{R_registerRoutines}.  This is typically done when the DLL is first
loaded within the initialization routine @code{R_init_@var{dll name}}
described in @ref{dyn.load and dyn.unload}.  @code{R_registerRoutines}
takes 5 arguments.  The first is the @code{DllInfo} object passed by
@R{} to the initialization routine. This is where @R{} stores the
information about the methods.  The remaining 4 arguments are arrays
describing the routines for each of the 4 different interfaces:
@code{.C}, @code{.Call}, @code{.Fortran} and @code{.External}.  Each
argument is a @code{NULL}-terminated array of the element types given in
the following table:

@quotation
@multitable {@code{.External  }} {@code{R_ExternalMethodDef}}
@item @code{.C} @tab @code{R_CMethodDef}
@item @code{.Call} @tab @code{R_CallMethodDef}
@item @code{.Fortran} @tab @code{R_FortranMethodDef}
@item @code{.External} @tab @code{R_ExternalMethodDef}
@end multitable
@end quotation

Currently, the @code{R_ExternalMethodDef} is the same as
@code{R_CallMethodDef} type and contains fields for the name of the
routine by which it can be accessed in @R{}, a pointer to the actual native
symbol (i.e., the routine itself), and the number of arguments the
routine expects.  For routines with a variable number of arguments
invoked via the @code{.External} interface, one specifies @code{-1} for
the number of arguments which tells @R{} not to check the actual number
passed.  For example, if we had a routine named @code{myCall} defined as

@example
SEXP myCall(SEXP a, SEXP b, SEXP c);
@end example

@noindent
we would describe this as

@example
R_CallMethodDef callMethods[]  = @{
  @{"myCall", &myCall, 3@},
  @{NULL, NULL, 0@}
@};
@end example

@noindent
along with any other routines for the @code{.Call} interface.

Routines for use with the @code{.C} and @code{.Fortran} interfaces are
described with similar data structures, but which have two additional
fields for describing the type and ``style'' of each argument.  Each of
these can be omitted. However, if specified, each should be an array
with the same number of elements as the number of parameters for the
routine.  The types array should contain the @code{SEXP} types
describing the expected type of the argument. (Technically, the elements
of the types array are of type @code{R_NativePrimitiveArgType} which is
just an unsigned integer.)  The @R{} types and corresponding type
identifiers are provided in the following table:

@quotation
@multitable {@code{character  }} {@code{SINGLESXP}}
@item @code{numeric} @tab @code{REALSXP}
@item @code{integer} @tab @code{INTSXP}
@item @code{logical} @tab @code{LGLSXP}
@item @code{single} @tab @code{SINGLESXP}
@item @code{character} @tab @code{STRSXP}
@item @code{list} @tab @code{VECSXP}
@end multitable
@end quotation

Consider a C routine, @code{myC}, declared as

@example
void myC(double *x, int *n, char **names, int *status);
@end example

We would register it as

@example
R_CMethodDef cMethods[] = @{
   @{"myC", &myC, 4, @{REALSXP, INTSXP, STRSXP, LGLSXP@}@},
   @{NULL, NULL, 0@}
@};
@end example

One can also specify whether each argument is used simply as input, or
as output, or as both input and output.  The style field in the
description of a method is used for this.  The purpose is to allow @R{}
to transfer values more efficiently across the R-C/FORTRAN interface by
avoiding copying values when it is not necessary. Typically, one omits
this information in the registration data.

Having created the arrays describing each routine, the last step is to
actually register them with @R{}.  We do this by calling
@code{R_registerRoutines}.  For example, if we have the descriptions
above for the routines accessed by the @code{.C} and @code{.Call}
we would use the following code:

@example
void
R_init_myLib(DllInfo *info)
@{
   R_registerRoutines(info, cMethods, callMethods, NULL, NULL);
@}
@end example

This routine will be invoked when @R{} loads the shared object/DLL named
@code{myLib}.  The last two arguments in the call to
@code{R_registerRoutines} are for the routines accessed by
@code{.Fortran} and @code{.External} interfaces.  In our example, these
are given as @code{NULL} since we have no routines of these types.

When @R{} unloads a shared object/DLL, any registered routines are
automatically removed. There is no (direct) facility for unregistering
a symbol.

Examples of registering routines can be found in the different packages
in the @R{} source tree (e.g., @pkg{stats}).  Also, there is a
brief, high-level introduction in @emph{R News} (volume 1/3, September
2001, pages 20-23).

@c These tools are not currently operational.
@c Additionally, there are (experimental) tools that can be used to
@c automate the generation of the code to register the routines for a
@c collection of C files. See the @code{GccTranslationUnit} module on the
@c Omegahat Web site at @url{http://www.omegahat.org/GccTranslationUnit/}
@c for more information.

In addition to registering C routines to be called by @R{}, it can at times
be useful for one package to make some of its C routines available to be
called by C code in another package.  An experimental interface to
support this has been provided in @R{} 2.4.0.  The interface consists of
two routines declared as

@findex R_RegisterCCallable
@findex R_GetCCallable
@example
void R_RegisterCCallable(const char *package, const char *name, DL_FUNC fptr);
DL_FUNC R_GetCCallable(const char *package, const char *name);
@end example

A package @pkg{packA} that wants to make a C routine @code{myCfun}
available to C code in other packages would include the call

@example
R_RegisterCCallable("packA", "myCfun", myCfun);
@end example

in its initialization function @code{R_init_packA}.  A package
@pkg{packB} that wants to use this routine would retrieve the function
pointer with a call of the form

@example
p_myCfun = R_GetCCallable("packA", "myCfun");
@end example

The author of @pkg{packB} is responsible for insuring that
@code{p_myCfun} has an appropriate declaration. In the future @R{} may
provide some automated tools to simplify exporting larger numbers of
routines.

A package that wishes to make use of header files in other packages needs
to declare them as a comma-separated list in the field @code{LinkingTo}
in the @file{DESCRIPTION} file.  For example

@example
Depends: link2, link3
LinkingTo: link2, link3
@end example

It should also `Depend' on those packages for they have to be installed
prior to this one, and loaded prior to this one (so the path to their
compiled code can be found).

This then arranges that the @file{include} directories in the installed
linked-to packages are added to the include paths for C and C++ code.


@node Creating shared objects, Interfacing C++ code, Registering native routines, System and foreign language interfaces
@section Creating shared objects
@cindex Creating shared objects
@findex R CMD SHLIB

Shared objects for loading into @R{} can be created using @command{R CMD
SHLIB}.  This accepts as arguments a list of files which must be object
files (with extension @file{.o}) or sources for C, C++, FORTRAN 77,
Fortran 9x, Objective C or Objective C++ (with extensions @file{.c},
@file{.cc} or @file{.cpp} or @file{.C}, @file{.f}, @file{.f90} or
@file{.f95}, @file{.m}, and @file{.mm} or @file{.M}, respectively), or
commands to be passed to the linker.  See @kbd{R CMD SHLIB --help} (or
the on-line help for @code{SHLIB}) for usage information.  If compiling
the source files does not work ``out of the box'', you can specify
additional flags by setting some of the variables
@vindex PKG_CPPFLAGS
@code{PKG_CPPFLAGS} (for the C preprocessor, typically @samp{-I} flags),
@vindex PKG_CFLAGS
@vindex PKG_CXXFLAGS
@vindex PKG_FFLAGS
@vindex PKG_FCFLAGS
@vindex PKG_OBJCFLAGS
@code{PKG_CFLAGS}, @code{PKG_CXXFLAGS}, @code{PKG_FFLAGS},
@code{PKG_FCFLAGS}, and @code{PKG_OBJCFLAGS} (for the C, C++, FORTRAN
77, Fortran 9x, and Objective C compilers, respectively) in the file
@file{Makevars} in the compilation directory, or write a @file{Makefile}
in the compilation directory containing the rules required (or, of
course, create the object files directly from the command line).
@vindex PKG_LIBS
Similarly, variable @code{PKG_LIBS} in @file{Makevars} can be used for
additional @samp{-l} and @samp{-L} flags to be passed to the linker when
building the shared object.  (On most systems the @code{PKG_*} flags can
be set in the environment instead of in @file{Makevars}, but they can
also be set as part of the command line of @command{R CMD SHLIB}.)

Flags which are set in file @file{etc/Makeconf} can be overridden by the
environment variable @env{MAKEFLAGS} (at least for systems using
@acronym{GNU} @code{make}), as in (Bourne shell syntax)

@example
MAKEFLAGS="CFLAGS=-O3" R CMD SHLIB *.c
@end example

@noindent
or by using a @file{Makefile}.  

Note that as @code{R CMD SHLIB} uses Make, it will not remake a shared
object just because the flags have changed, and if @code{test.c} and
@code{test.f} both exist in the current directory

@example
R CMD SHLIB test.f
@end example

@noindent
will compile @file{test.c}!


If an add-on package @var{pkg} contains C, C++, or FORTRAN code in its
@file{src} subdirectory, @code{R CMD INSTALL} creates a shared object
(for loading into @R{} in the @code{.First.lib} or @code{.onLoad}
function of the package) either automatically using the above @code{R
CMD SHLIB} mechanism, or using Make if directory @file{src} contains a
@file{Makefile}.  In both cases, if file @file{Makevars} exists it is
read first when invoking @code{make}.  If a @file{Makefile} is really
needed or provided, if FORTRAN is involved it needs to ensure that the
shared object created is linked against all FORTRAN 77 intrinsic and
run-time libraries that @R{} was linked against; Make variable
@code{FLIBS} contains this information.

In Windows the same command works, but files @file{Makevars.win} or
@file{Makefile.win} are used in preference to @file{Makevars} or
@file{Makefile} if they exist.  (This does need the files in the @R{}
binary Windows distribution for installing source packages to be
installed.)  For details of building DLLs with a variety of compilers,
see @samp{README.packages} and
@url{http://@/www.stats.uwo.ca/@/faculty/@/murdoch/@/software/@/compilingDLLs/} .

Under Windows you can supply an exports file called
@file{@var{dllname}-win.def}: otherwise all entry points in objects (but
not libraries) will be exported from the DLL.  An example is
@file{stats-win.def} for the @pkg{stats} package.


@node Interfacing C++ code, Handling R objects in C, Creating shared objects, System and foreign language interfaces
@section Interfacing C++ code
@cindex Interfacing C++ code
@cindex C++ code, interfacing

Suppose we have the following hypothetical C++ library, consisting of
the two files @file{X.hh} and @file{X.cc}, and implementing the two
classes @code{X} and @code{Y} which we want to use in @R{}.

@quotation
@cartouche
@example
// X.hh

class X @{
public: X (); ~X ();
@};

class Y @{
public: Y (); ~Y ();
@};
@end example
@end cartouche
@end quotation

@quotation
@cartouche
@example
// X.cc

#include <iostream>
#include "X.hh"

static Y y;

X::X()  @{ std::cout << "constructor X" << std::endl; @}
X::~X() @{ std::cout << "destructor X"  << std::endl; @}
Y::Y()  @{ std::cout << "constructor Y" << std::endl; @}
Y::~Y() @{ std::cout << "destructor Y"  << std::endl; @}
@end example
@end cartouche
@end quotation

To use with @R{}, the only thing we have to do is writing a wrapper
function and ensuring that the function is enclosed in

@example
@group
extern "C" @{

@}
@end group
@end example

For example,

@quotation
@cartouche
@example
// X_main.cc:

#include "X.hh"

extern "C" @{

void X_main () @{
  X x;
@}

@} // extern "C"
@end example
@end cartouche
@end quotation

Compiling and linking should be done with the C++ compiler-linker
(rather than the C compiler-linker or the linker itself); otherwise, the
C++ initialization code (and hence the constructor of the static
variable @code{Y}) are not called.  On a properly configured system, one
can simply use

@example
R CMD SHLIB X.cc X_main.cc
@end example

@noindent
to create the shared object, typically @file{X.so} (the file name
extension may be different on your platform).  Now starting @R{} yields

@example
@group
R : Copyright 2000, The R Development Core Team
Version 1.1.0 Under development (unstable) (April 14, 2000)
...
Type    "q()" to quit R.
@end group

@group
R> dyn.load(paste("X", .Platform$dynlib.ext, sep = ""))
constructor Y
R> .C("X_main")
constructor X
destructor X
list()
R> q()
Save workspace image? [y/n/c]: y
destructor Y
@end group
@end example

The @R{} for Windows @acronym{FAQ} (@file{rw-FAQ}) contains details of how
to compile this example under various Windows compilers.

Using C++ iostreams, as in this example, is best avoided.  There is no
guarantee that the output will appear in the @R{} console, and indeed it
will not on the @R{} for Windows console.  Use @R{} code or the C entry points
(@pxref{Printing}) for all I/O if at all possible.

Some @R{} header files are C and not C++ header files and should be
included within an @code{extern "C"} block: for clarity this is
advisable for all @R{} header files.


@node Handling R objects in C, Interface functions .Call and .External, Interfacing C++ code, System and foreign language interfaces
@section Handling R objects in C
@cindex Handling R objects in C

Using C code to speed up the execution of an @R{} function is often very
fruitful.  Traditionally this has been done via the @code{.C} function
in @R{}.
@c (for details, see the @R{} documentation on @code{.C}).
One restriction of this interface is that the @R{} objects can not be
handled directly in C.  This becomes more troublesome when one wishes to
call @R{} functions from within the C code.  There is a C function
provided called @code{call_R} (also known as @code{call_S} for
compatibility with S) that can do that, but it is cumbersome to use, and
the mechanisms documented here are usually simpler to use, as well as
more powerful.

If a user really wants to write C code using internal @R{} data
structures, then that can be done using the @code{.Call} and
@code{.External} function.  The syntax for the calling function in @R{}
in each case is similar to that of @code{.C}, but the two functions have
different C interfaces.  Generally the @code{.Call} interface (which is
modelled on the interface of the same name in @Sl{} version 4) is a
little simpler to use, but @code{.External} is a little more general.
@findex .Call
@findex .External

A call to @code{.Call} is very similar to @code{.C}, for example

@example
.Call("convolve2", a, b)
@end example

@noindent
The first argument should be a character string giving a C symbol name
of code that has already been loaded into @R{}.  Up to 65 @R{} objects
can passed as arguments.  The C side of the interface is

@example
@group
#include <R.h>
#include <Rinternals.h>

SEXP convolve2(SEXP a, SEXP b)
 ...
@end group
@end example

A call to @code{.External} is almost identical

@example
.External("convolveE", a, b)
@end example

@noindent
but the C side of the interface is different, having only one argument

@example
@group
#include <R.h>
#include <Rinternals.h>

SEXP convolveE(SEXP args)
 ...
@end group
@end example

@noindent
Here @code{args} is a @code{LISTSXP}, a Lisp-style pairlist from which
the arguments can be extracted.

In each case the @R{} objects are available for manipulation via a set
of functions and macros defined in the header file @file{Rinternals.h}
or some S4-compatibility macros defined in @file{Rdefines.h}.  See
@ref{Interface functions .Call and .External} for details on
@code{.Call} and @code{.External}.

Before you decide to use @code{.Call} or @code{.External}, you should
look at other alternatives.  First, consider working in interpreted @R{}
code; if this is fast enough, this is normally the best option.  You
should also see if using @code{.C} is enough.  If the task to be
performed in C is simple enough requiring no call to @R{}, @code{.C}
suffices.  The new interfaces are relatively recent additions to @Sl{}
and @R{}, and a great deal of useful code has been written using just
@code{.C} before they were available.  The @code{.Call} and
@code{.External} interfaces allow much more control, but they also
impose much greater responsibilities so need to be used with care.
Neither @code{.Call} nor @code{.External} copy their arguments.  You
should treat arguments you receive through these interfaces as
read-only.

There are two approaches that can be taken to handling @R{} objects from
within C code.  The first (historically) is to use the macros and
functions that have been used to implement the core parts of @R{}
through @code{.Internal} calls.  A public@footnote{ @pxref{The R API}:
note that these are not all part of the API.}  subset of these is
defined in the header file @file{Rinternals.h} in the directory
@file{@var{R_INCLUDE_DIR}} (default @file{@var{R_HOME}/include}) that
should be available on any @R{} installation.

Another approach is to use @R{} versions of the macros and functions
defined for the @Sl{} version 4 interface @code{.Call}, which are
defined in the header file @file{Rdefines.h}.  This is a somewhat
simpler approach, and is to be preferred if the code is intended to be
shared with @Sl{}.  However, it is less well documented and even less
tested.  Note too that some idiomatic S4 constructions with these macros
(such as assigning elements of character vectors or lists) are invalid
in @R{}.

A substantial amount of @R{} is implemented using the functions and
macros described here, so the @R{} source code provides a rich source of
examples and ``how to do it'': indeed many of the examples here were
developed by examining closely @R{} system functions for similar tasks.
Do make use of the source code for inspirational examples.

It is necessary to know something about how @R{} objects are handled in
C code.  All the @R{} objects you will deal with will be handled with
the type @dfn{SEXP}@footnote{SEXP is an acronym for @emph{S}imple
@emph{EXP}ression, common in LISP-like language syntaxes.}, which is a
pointer to a structure with typedef @code{SEXPREC}.  Think of this
structure as a @emph{variant type} that can handle all the usual types
of @R{} objects, that is vectors of various modes, functions,
environments, language objects and so on.  The details are given later
in this section and in @ref{R Internal Structures, , R Internal
Structures, R-ints, R Internals}, but for most
purposes the programmer does not need to know them.  Think rather of a
model such as that used by Visual Basic, in which @R{} objects are
handed around in C code (as they are in interpreted @R{} code) as the
variant type, and the appropriate part is extracted for, for example,
numerical calculations, only when it is needed.  As in interpreted @R{}
code, much use is made of coercion to force the variant object to the
right type.

@menu
* Garbage Collection::          
* Allocating storage::          
* Details of R types::          
* Attributes::                  
* Classes::                     
* Handling lists::              
* Handling character data::     
* Finding and setting variables::  
* Some convenience functions::  
* Named objects and copying::   
@end menu

@node Garbage Collection, Allocating storage, Handling R objects in C, Handling R objects in C
@subsection Handling the effects of garbage collection
@cindex Garbage collection

@findex PROTECT
@findex UNPROTECT

We need to know a little about the way @R{} handles memory allocation.
The memory allocated for @R{} objects is not freed by the user; instead,
the memory is from time to time @dfn{garbage collected}.  That is, some
or all of the allocated memory not being used is freed.

The @R{} object types are represented by a C structure defined by a
typedef @code{SEXPREC} in @file{Rinternals.h}.  It contains several
things among which are pointers to data blocks and to other
@code{SEXPREC}s.  A @code{SEXP} is simply a pointer to a @code{SEXPREC}.

If you create an @R{} object in your C code, you must tell @R{} that you
are using the object by using the @code{PROTECT} macro on a pointer to
the object. This tells @R{} that the object is in use so it is not
destroyed during garbage collection.  Notice that it is the object which
is protected, not the pointer variable.  It is a common mistake to
believe that if you invoked @code{PROTECT(@var{p})} at some point then
@var{p} is protected from then on, but that is not true once a new
object is assigned to @var{p}.

Protecting an @R{} object automatically protects all the @R{} objects
pointed to in the corresponding @code{SEXPREC}, for example all elements
of a protected list are automatically protected.

The programmer is solely responsible for housekeeping the calls to
@code{PROTECT}.  There is a corresponding macro @code{UNPROTECT} that
takes as argument an @code{int} giving the number of objects to
unprotect when they are no longer needed.  The protection mechanism is
stack-based, so @code{UNPROTECT(@var{n})} unprotects the last @var{n}
objects which were protected.  The calls to @code{PROTECT} and
@code{UNPROTECT} must balance when the user's code returns.  @R{} will
warn about @code{"stack imbalance in .Call"} (or @code{.External}) if
the housekeeping is wrong.

Here is a small example of creating an @R{} numeric vector in C code.
First we use the macros in @file{Rinternals.h}:

@example
@group
#include <R.h>
#include <Rinternals.h>

  SEXP ab;
    ....
  PROTECT(ab = allocVector(REALSXP, 2));
  REAL(ab)[0] = 123.45;
  REAL(ab)[1] = 67.89;
  UNPROTECT(1);
@end group
@end example

@noindent
and then those in @file{Rdefines.h}:

@example
@group
#include <R.h>
#include <Rdefines.h>

  SEXP ab;
    ....
  PROTECT(ab = NEW_NUMERIC(2));
  NUMERIC_POINTER(ab)[0] = 123.45;
  NUMERIC_POINTER(ab)[1] = 67.89;
  UNPROTECT(1);
@end group
@end example

Now, the reader may ask how the @R{} object could possibly get removed
during those manipulations, as it is just our C code that is running.
As it happens, we can do without the protection in this example, but in
general we do not know (nor want to know) what is hiding behind the @R{}
macros and functions we use, and any of them might cause memory to be
allocated, hence garbage collection and hence our object @code{ab} to be
removed. It is usually wise to err on the side of caution and assume
that any of the @R{} macros and functions might remove the object.

In some cases it is necessary to keep better track of whether protection
is really needed.  Be particularly aware of situations where a large
number of objects are generated.  The pointer protection stack has a
fixed size (default 10,000) and can become full.  It is not a good idea
then to just @code{PROTECT} everything in sight and @code{UNPROTECT}
several thousand objects at the end. It will almost invariably be
possible to either assign the objects as part of another object (which
automatically protects them) or unprotect them immediately after use.

Protection is not needed for objects which @R{} already knows are in
use.  In particular, this applies to function arguments.

There is a less-used macro @code{UNPROTECT_PTR(@var{s})} that unprotects
the object pointed to by the @code{SEXP} @var{s}, even if it is not the
top item on the pointer protection stack. This is rarely needed outside
the parser (the @R{} sources have one example, in
@file{src/main/plot3d.c}).
@findex UNPROTECT_PTR

Sometimes an object is changed (for example duplicated, coerced or
grown) yet the current value needs to be protected.  For these cases
@code{PROTECT_WITH_INDEX} saves an index of the protection location that
can be used to replace the protected value using @code{REPROTECT}.
@findex PROTECT_WITH_INDEX
@findex REPROTECT
For example (from the internal code for @code{optim})

@example
    PROTECT_INDEX ipx;

    ....
    PROTECT_WITH_INDEX(s = eval(OS->R_fcall, OS->R_env), &ipx);
    REPROTECT(s = coerceVector(s, REALSXP), ipx);
@end example


@node Allocating storage, Details of R types, Garbage Collection, Handling R objects in C
@subsection Allocating storage
@cindex Allocating storage

For many purposes it is sufficient to allocate @R{} objects and
manipulate those.  There are quite a few @code{alloc@var{Xxx}} functions
defined in @file{Rinternals.h}---you may want to explore them.  These
allocate @R{} objects of various types, and for the standard vector
types there are equivalent @code{NEW_@var{XXX}} macros defined in
@file{Rdefines.h}.

If storage is required for C objects during the calculations this is
best allocating by calling @code{R_alloc}; @pxref{Memory allocation}.
All of these memory allocation routines do their own error-checking, so
the programmer may assume that they will raise an error and not return
if the memory cannot be allocated.

@node Details of R types, Attributes, Allocating storage, Handling R objects in C
@subsection Details of R types
@cindex Details of R types

Users of the @file{Rinternals.h} macros will need to know how the @R{}
types are known internally: if the @file{Rdefines.h} macros are used
then S4-compatible names are used.

The different @R{} data types are represented in C by @dfn{SEXPTYPE}.
Some of these are familiar from @R{} and some are internal data types.
The usual @R{} object modes are given in the table.

@quotation
@multitable {SEXPTYPE} {numeric with storage mode integer integer}
@headitem SEXPTYPE @tab @R{} equivalent
@item @code{REALSXP}  @tab numeric with storage mode @code{double}
@item @code{INTSXP}   @tab integer
@item @code{CPLXSXP}  @tab complex
@item @code{LGLSXP}   @tab logical
@item @code{STRSXP}   @tab character
@item @code{VECSXP}   @tab list (generic vector)
@item @code{LISTSXP}  @tab ``dotted-pair'' list
@item @code{DOTSXP}   @tab a @samp{@dots{}} object
@item @code{NILSXP}   @tab NULL
@item @code{SYMSXP}   @tab name/symbol
@item @code{CLOSXP}   @tab function or function closure
@item @code{ENVSXP}   @tab environment
@end multitable
@end quotation

@noindent
Among the important internal @code{SEXPTYPE}s are @code{LANGSXP},
@code{CHARSXP}, @code{PROMSXP}, etc.  (@strong{Note}: although it is
possible to return objects of internal types, it is unsafe to do so as
assumptions are made about how they are handled which may be violated at
user-level evaluation.)  More details are given in @ref{R Internal
Structures, , R Internal Structures, R-ints, R Internals}.

Unless you are very sure about the type of the arguments, the code
should check the data types.  Sometimes it may also be necessary to
check data types of objects created by evaluating an @R{} expression in
the C code.  You can use functions like @code{isReal}, @code{isInteger}
and @code{isString} to do type checking.  See the header file
@file{Rinternals.h} for definitions of other such functions.  All of
these take a @code{SEXP} as argument and return 1 or 0 to indicate
@var{TRUE} or @var{FALSE}.  Once again there are two ways to do this,
and @file{Rdefines.h} has macros such as @code{IS_NUMERIC}.

What happens if the @code{SEXP} is not of the correct type?  Sometimes
you have no other option except to generate an error.  You can use the
function @code{error} for this.  It is usually better to coerce the
object to the correct type.  For example, if you find that an
@code{SEXP} is of the type @code{INTEGER}, but you need a @code{REAL}
object, you can change the type by using, equivalently,

@example
PROTECT(@var{newSexp} = coerceVector(@var{oldSexp}, REALSXP));
@end example

@noindent
or

@example
PROTECT(@var{newSexp} = AS_NUMERIC(@var{oldSexp}));
@end example

@noindent
Protection is needed as a new @emph{object} is created; the object
formerly pointed to by the @code{SEXP} is still protected but now
unused.

All the coercion functions do their own error-checking, and generate
@code{NA}s with a warning or stop with an error as appropriate.

Note that these coercion functions are @emph{not} the same as calling
@code{as.numeric} (and so on) in @R{} code, as they do not dispatch on
the class of the object.  Thus it is normally preferable to do the
coercion in the calling @R{} code.

So far we have only seen how to create and coerce @R{} objects from C
code, and how to extract the numeric data from numeric @R{} vectors.
These can suffice to take us a long way in interfacing @R{} objects to
numerical algorithms, but we may need to know a little more to create
useful return objects.

@node Attributes, Classes, Details of R types, Handling R objects in C
@subsection Attributes
@cindex Attributes

Many @R{} objects have attributes: some of the most useful are classes
and the @code{dim} and @code{dimnames} that mark objects as matrices or
arrays.  It can also be helpful to work with the @code{names} attribute
of vectors.

To illustrate this, let us write code to take the outer product of two
vectors (which @code{outer} and @code{%o%} already do).  As usual the
@R{} code is simple

@example
out <- function(x, y)
@{
   storage.mode(x) <- storage.mode(y) <- "double"
   .Call("out", x, y)
@}
@end example

@noindent
where we expect @code{x} and @code{y} to be numeric vectors (possibly
integer), possibly with names.  This time we do the coercion in the
calling @R{} code.

C code to do the computations is

@example
@group
#include <R.h>
#include <Rinternals.h>

SEXP out(SEXP x, SEXP y)
@{
  int i, j, nx, ny;
  double tmp, *rx = REAL(x), *ry = REAL(y), *rans;
  SEXP ans;

  nx = length(x); ny = length(y);
  PROTECT(ans = allocMatrix(REALSXP, nx, ny));
  rans = REAL(ans);
  for(i = 0; i < nx; i++) @{
    tmp = rx[i];
    for(j = 0; j < ny; j++)
      rans[i + nx*j] = tmp * ry[j];
  @}
  UNPROTECT(1);
  return(ans);
@}
@end group
@end example

@noindent
Note the way @code{REAL} is used: as it is a function call it can be
considerably faster to store the result and index that.

However, we would like to set the @code{dimnames} of the result.
Although @code{allocMatrix} provides a short cut, we will show how to
set the @code{dim} attribute directly.

@example
#include <R.h>
#include <Rinternals.h>

@group
SEXP out(SEXP x, SEXP y)
@{
  R_len_t i, j, nx, ny;
  double tmp, *rx = REAL(x), *ry = REAL(y), *rans;
  SEXP ans, dim, dimnames;
@end group

@group
  nx = length(x); ny = length(y);
  PROTECT(ans = allocVector(REALSXP, nx*ny));
  rans = REAL(ans);
  for(i = 0; i < nx; i++) @{
    tmp = rx[i];
    for(j = 0; j < ny; j++)
      rans[i + nx*j] = tmp * ry[j];
  @}
@end group

@group
  PROTECT(dim = allocVector(INTSXP, 2));
  INTEGER(dim)[0] = nx; INTEGER(dim)[1] = ny;
  setAttrib(ans, R_DimSymbol, dim);
@end group

@group
  PROTECT(dimnames = allocVector(VECSXP, 2));
  SET_VECTOR_ELT(dimnames, 0, getAttrib(x, R_NamesSymbol));
  SET_VECTOR_ELT(dimnames, 1, getAttrib(y, R_NamesSymbol));
  setAttrib(ans, R_DimNamesSymbol, dimnames);
@end group

@group
  UNPROTECT(3);
  return(ans);
@}
@end group
@end example

This example introduces several new features.  The @code{getAttrib} and
@code{setAttrib}
@findex getAttrib
@findex setAttrib
functions get and set individual attributes.  Their second argument is a
@code{SEXP} defining the name in the symbol table of the attribute we
want; these and many such symbols are defined in the header file
@file{Rinternals.h}.

There are shortcuts here too: the functions @code{namesgets},
@code{dimgets} and @code{dimnamesgets} are the internal versions of the
default methods of @code{names<-}, @code{dim<-} and @code{dimnames<-}
(for vectors and arrays), and there are functions such as
@code{GetMatrixDimnames} and @code{GetArrayDimnames}.

What happens if we want to add an attribute that is not pre-defined? We
need to add a symbol for it @emph{via} a call to
@findex install
@code{install}.  Suppose for illustration we wanted to add an attribute
@code{"version"} with value @code{3.0}.  We could use

@example
@group
  SEXP version;
  PROTECT(version = allocVector(REALSXP, 1));
  REAL(version)[0] = 3.0;
  setAttrib(ans, install("version"), version);
  UNPROTECT(1);
@end group
@end example

Using @code{install} when it is not needed is harmless and provides a
simple way to retrieve the symbol from the symbol table if it is already
installed.

@node Classes, Handling lists, Attributes, Handling R objects in C
@subsection Classes
@cindex Classes

In @R{} the (S3) class is just the attribute named @code{"class"} so it
can be handled as such, but there is a shortcut @code{classgets}.
Suppose we want to give the return value in our example the class
@code{"mat"}.  We can use

@example
@group
#include <R.h>
#include <Rdefines.h>
    .... 
  SEXP ans, dim, dimnames, class;
    ....
  PROTECT(class = allocVector(STRSXP, 1));
  SET_STRING_ELT(class, 0, mkChar("mat"));
  classgets(ans, class);
  UNPROTECT(4);
  return(ans);
@}
@end group
@end example

@noindent
As the value is a character vector, we have to know how to create that
from a C character array, which we do using the function
@code{mkChar}.

@node Handling lists, Handling character data, Classes, Handling R objects in C
@subsection Handling lists
@cindex Handling lists

Some care is needed with lists, as @R{} moved early on from using
LISP-like lists (now called ``pairlists'') to S-like generic vectors.
As a result, the appropriate test for an object of mode @code{list} is
@code{isNewList}, and we need @code{allocVector(VECSXP, @var{n}}) and
@emph{not} @code{allocList(@var{n})}.

List elements can be retrieved or set by direct access to the elements
of the generic vector.  Suppose we have a list object

@example
a <- list(f=1, g=2, h=3)
@end example

@noindent
Then we can access @code{a$g} as @code{a[[2]]} by

@example
@group
  double g;
    ....
  g = REAL(VECTOR_ELT(a, 1))[0];
@end group
@end example

This can rapidly become tedious, and the following function (based on
one in package @pkg{stats}) is very useful:

@example
@group
/* get the list element named str, or return NULL */

SEXP getListElement(SEXP list, const char *str)
@{
  SEXP elmt = R_NilValue, names = getAttrib(list, R_NamesSymbol);
  int i;
@end group

@group
  for (i = 0; i < length(list); i++)
    if(strcmp(CHAR(STRING_ELT(names, i)), str) == 0) @{
      elmt = VECTOR_ELT(list, i);
      break;
    @}
  return elmt;
@}
@end group
@end example

@noindent
and enables us to say

@example
@group
  double g;
  g = REAL(getListElement(a, "g"))[0];
@end group
@end example

@node Handling character data, Finding and setting variables, Handling lists, Handling R objects in C
@subsection Handling character data
@cindex handling character data

R character vectors are stored as @code{STRSXP}s, a vector type like
@code{VECSXP} where every element is of type @code{CHARSXP}.  The
@code{CHARSXP} elements of @code{STRSXP}s are accessed using
@code{STRING_ELT} and @code{SET_STRING_ELT}.

As of @R{} 2.6.0, @code{CHARSXP}s are read-only objects and must never
be modified.  In particular, the C-style string contained in a
@code{CHARSXP} should be treated as read-only and for this reason the
@code{CHAR} function used to access the character data of a
@code{CHARSXP} returns @code{(const char *)} (this also allows compilers
to issue warnings about improper use).  Since @code{CHARSXP}s are
immutable, the same @code{CHARSXP} can be shared by any @code{STRSXP}
needing an element representing the same string.  As of @R{} 2.6.0, @R{}
maintains a global cache of @code{CHARSXP}s so that there is only ever
one @code{CHARSXP} representing a given string in memory.

You can obtain a @code{CHARSXP} by calling @code{mkChar} and providing a
nul-terminated C-style string.  This function will return a pre-existing
@code{CHARSXP} if one with a matching string already exists, otherwise
it will create a new one and add it to the cache before returning it to
you.

Currently, it is still possible to create @code{CHARSXP}s using
@code{allocVector} or @code{allocString}; @code{CHARSXP}s created in
this way will not be captured by the global @code{CHARSXP} cache and
this should be avoided.  In the future, all @code{CHARSXP}s will be
captured by the cache and this will allow further optimizations, for
example, replacing calls to @code{strcmp} with pointer comparisons.  A
helper macro, @code{CallocCharBuf}, can be used to obtain a temporary
character buffer for in-place string manipulation: this memory must be
released using @code{Free}.

@node Finding and setting variables, Some convenience functions, Handling character data, Handling R objects in C
@subsection Finding and setting variables
@cindex Finding variables
@cindex Setting variables

It will be usual that all the @R{} objects needed in our C computations
are passed as arguments to @code{.Call} or @code{.External}, but it is
possible to find the values of @R{} objects from within the C given
their names.  The following code is the equivalent of @code{get(name,
envir = rho)}.

@example
@group
SEXP getvar(SEXP name, SEXP rho)
@{
  SEXP ans;

  if(!isString(name) || length(name) != 1)
    error("name is not a single string");
  if(!isEnvironment(rho))
    error("rho should be an environment");
  ans = findVar(install(CHAR(STRING_ELT(name, 0))), rho);
  printf("first value is %f\n", REAL(ans)[0]);
  return(R_NilValue);
@}
@end group
@end example

The main work is done by
@findex findVar
@code{findVar}, but to use it we need to install @code{name} as a name
in the symbol table.  As we wanted the value for internal use, we return
@code{NULL}.

Similar functions with syntax

@example
@group
void defineVar(SEXP symbol, SEXP value, SEXP rho)
void setVar(SEXP symbol, SEXP value, SEXP rho)
@end group
@end example
@findex defineVar
@findex setVar

@noindent
can be used to assign values to @R{} variables.  @code{defineVar}
creates a new binding or changes the value of an existing binding in the
specified environment frame; it is the analogue of @code{assign(symbol,
value, envir = rho, inherits = FALSE)}, but unlike @code{assign},
@code{defineVar} does not make a copy of the object
@code{value}.@footnote{You can assign a @emph{copy} of the object in the
environment frame @code{rho} using @code{defineVar(symbol,
duplicate(value), rho)}).}  @code{setVar} searches for an existing
binding for @code{symbol} in @code{rho} or its enclosing environments.
If a binding is found, its value is changed to @code{value}.  Otherwise,
a new binding with the specified value is created in the global
environment.  This corresponds to @code{assign(symbol, value, envir =
rho, inherits = TRUE)}.

@node Some convenience functions, Named objects and copying, Finding and setting variables, Handling R objects in C
@subsection Some convenience functions

Some operations are done so frequently that there are convenience
functions to handle them.  Suppose we wanted to pass a single logical
argument @code{ignore_quotes}: we could use

@example
    int ign;

    ign = asLogical(ignore_quotes);
    if(ign == NA_LOGICAL) error("'ignore_quotes' must be TRUE or FALSE");
@end example

@noindent
which will do any coercion needed, and return @code{NA_LOGICAL} if the
value passed was @code{NA} or coercion failed.  There are also
@code{asInteger}, @code{asReal} and @code{asComplex}.  The function
@code{asChar} returns a @code{CHARSXP}.  All of these functions ignore
any elements of an input vector after the first.

To return a length-one real vector we can use

@example
    double x;

    ...
    return ScalarReal(x);
@end example

@noindent
and there are versions of this for all the atomic vector types (those for
a length-one character vector being @code{ScalarString} with argument a
@code{CHARSXP} and @code{mkString} with argument @code{const char *}).

Some of the @code{isXXXX} functions differ from their apparent
@R{}-level counterparts: for example @code{isVector} is true for any
atomic vector type (@code{isVectorAtomic}) and for lists and expressions
(@code{isVectorList}) (with no check on attributes).  @code{isMatrix} is
a test of a length-2 @code{"dim"} attribute.

There are a series of small macros/functions to help construct pairlists
and language objects (whose internal structures just differ by
@code{SEXPTYPE}.  Function @code{CONS(u, v)} is the basic building
block: is constructs a pairlist from @code{u} followed by @code{v}
(which is a pairlist or @code{R_NilValue}).  @code{LCONS} is a variant
that constructs a language object.  Functions @code{list1} to
@code{list4} construct a pairlist from one to four items, and
@code{lang1} to @code{lang4} do the same for a language object (a
function to call plus zero to three arguments).  Function @code{elt} and
@code{lastElt} find the @var{i}th element and the last element of a
pairlist, and @code{nthcdr} returns a pointer to the @var{n}th position
in the pairlist (whose @code{CAR} is the @var{n}th item).

Functions @code{str2type} and @code{type2str} map @R{}
length-one character strings to and from @code{SEXPTYPE} numbers, and
@code{type2char} maps numbers to C character strings.


@node Named objects and copying,  , Some convenience functions, Handling R objects in C
@subsection Named objects and copying
@findex duplicate
@cindex Copying objects

When assignments are done in @R{} such as

@example
x <- 1:10
y <- x
@end example

@noindent
the named object is not necessarily copied, so after those two
assignments @code{y} and @code{x} are bound to the same @code{SEXPREC}
(the structure a @code{SEXP} points to).  This means that any code which
alters one of them has to make a copy before modifying the copy if the
usual @R{} semantics are to apply.  Note that whereas @code{.C} and
@code{.Fortran} do copy their arguments (unless the dangerous @code{dup
= FALSE} is used), @code{.Call} and @code{.External} do not.  So
@code{duplicate} is commonly called on arguments to @code{.Call} before
modifying them.

However, at least some of this copying is unneeded.  In the first
assignment shown, @code{x <- 1:10}, @R{} first creates an object with
value @code{1:10} and then assigns it to @code{x} but if @code{x} is
modified no copy is necessary as the temporary object with value
@code{1:10} cannot be referred to again.  @R{} distinguishes between
named and unnamed objects @emph{via} a field in a @code{SEXPREC} that
can be accessed via the macros @code{NAMED} and @code{SET_NAMED}.  This
can take values

@table @code
@item 0
The object is not bound to any symbol
@item 1
The object has been bound to exactly one symbol
@item 2
The object has potentially been bound to two or more symbols, and one
should act as if another variable is currently bound to this value.
@end table

@noindent
Note the past tenses: @R{} does not do full reference counting and there
may currently be fewer bindings.

It is safe to modify the value of any @code{SEXP} for which
@code{NAMED(foo)} is zero, and if @code{NAMED(foo)} is two, the value
should be duplicated (via a call to @code{duplicate}) before any
modification.  Note that it is the responsibility of the author of the
code making the modification to do the duplication, even if it is
@code{x} whose value is being modified after @code{y <- x}.

The case @code{NAMED(foo) == 1} allows some optimization, but it can be
ignored (and duplication done whenever @code{NAMED(foo) > 0}).  (This
optimization is not currently usable in user code.)  It is intended
for use within assignment functions.  Suppose we used

@example
x <- 1:10
foo(x) <- 3
@end example

@noindent
which is computed as

@example
x <- 1:10
x <- "foo<-"(x, 3)
@end example

@noindent
Then inside @code{"foo<-"} the object pointing to the current value of
@code{x} will have @code{NAMED(foo)} as one, and it would be safe to
modify it as the only symbol bound to it is @code{x} and that will be
rebound immediately.  (Provided the remaining code in @code{"foo<-"}
make no reference to @code{x}, and no one is going to attempt a direct
call such as @code{y <- "foo<-"(x)}.)

Currently all arguments to a @code{.Call} call will have @code{NAMED}
set to 2, and so users must assume that they need to be duplicated
before alteration.

@node Interface functions .Call and .External, Evaluating R expressions from C, Handling R objects in C, System and foreign language interfaces
@section Interface functions @code{.Call} and @code{.External}
@cindex Interfaces to compiled code

In this section we consider the details of the @R{}/C interfaces.

These two interfaces have almost the same functionality. @code{.Call} is
based on the interface of the same name in @Sl{} version 4, and
@code{.External} is based on @code{.Internal}.  @code{.External} is more
complex but allows a variable number of arguments.

@menu
* Calling .Call::               
* Calling .External::           
* Missing and special values::  
@end menu

@node Calling .Call, Calling .External, Interface functions .Call and .External, Interface functions .Call and .External
@subsection Calling @code{.Call}

@findex .Call

Let us convert our finite convolution example to use @code{.Call}, first
using the @file{Rdefines.h} macros.  The calling function in @R{} is

@example
conv <- function(a, b) .Call("convolve2", a, b)
@end example

@noindent
which could hardly be simpler, but as we shall see all the type checking
must be transferred to the C code, which is

@example
@group
#include <R.h>
#include <Rdefines.h>

SEXP convolve2(SEXP a, SEXP b)
@{
  int i, j, na, nb, nab;
  double *xa, *xb, *xab;
  SEXP ab;

  PROTECT(a = AS_NUMERIC(a));
  PROTECT(b = AS_NUMERIC(b));
  na = LENGTH(a); nb = LENGTH(b); nab = na + nb - 1;
  PROTECT(ab = NEW_NUMERIC(nab));
  xa = NUMERIC_POINTER(a); xb = NUMERIC_POINTER(b);
  xab = NUMERIC_POINTER(ab);
  for(i = 0; i < nab; i++) xab[i] = 0.0;
  for(i = 0; i < na; i++)
    for(j = 0; j < nb; j++) xab[i + j] += xa[i] * xb[j];
  UNPROTECT(3);
  return(ab);
@}
@end group
@end example

Note that unlike the macros in @Sl{} version 4, the @R{} versions of
these macros do check that coercion can be done and raise an error if it
fails.  They will raise warnings if missing values are introduced by
coercion.  Although we illustrate doing the coercion in the C code here,
it often is simpler to do the necessary coercions in the @R{} code.

Now for the version in @R{}-internal style.  Only the C code changes.

@example
@group
#include <R.h>
#include <Rinternals.h>

SEXP convolve2(SEXP a, SEXP b)
@{
  R_len_t i, j, na, nb, nab;
  double *xa, *xb, *xab;
  SEXP ab;

  PROTECT(a = coerceVector(a, REALSXP));
  PROTECT(b = coerceVector(b, REALSXP));
  na = length(a); nb = length(b); nab = na + nb - 1;
  PROTECT(ab = allocVector(REALSXP, nab));
  xa = REAL(a); xb = REAL(b);
  xab = REAL(ab);
  for(i = 0; i < nab; i++) xab[i] = 0.0;
  for(i = 0; i < na; i++)
    for(j = 0; j < nb; j++) xab[i + j] += xa[i] * xb[j];
  UNPROTECT(3);
  return(ab);
@}
@end group
@end example

@noindent
This is called in exactly the same way.

@node Calling .External, Missing and special values, Calling .Call, Interface functions .Call and .External
@subsection Calling @code{.External}

@findex .External

We can use the same example to illustrate @code{.External}.  The @R{}
code changes only by replacing @code{.Call} by @code{.External}

@example
conv <- function(a, b) .External("convolveE", a, b)
@end example

@noindent
but the main change is how the arguments are passed to the C code, this
time as a single SEXP.  The only change to the C code is how we handle
the arguments.

@example
@group
#include <R.h>
#include <Rinternals.h>

SEXP convolveE(SEXP args)
@{
  int i, j, na, nb, nab;
  double *xa, *xb, *xab;
  SEXP a, b, ab;

  PROTECT(a = coerceVector(CADR(args), REALSXP));
  PROTECT(b = coerceVector(CADDR(args), REALSXP));
    ...
@}
@end group
@end example

@noindent
Once again we do not need to protect the arguments, as in the @R{} side
of the interface they are objects that are already in use.  The macros

@example
@group
  first = CADR(args);
  second = CADDR(args);
  third = CADDDR(args);
  fourth = CAD4R(args);
@end group
@end example

@noindent
provide convenient ways to access the first four arguments.  More
generally we can use the
@findex CAR
@findex CDR
@code{CDR} and @code{CAR} macros as in

@example
@group
  args = CDR(args); a = CAR(args);
  args = CDR(args); b = CAR(args);
@end group
@end example

@noindent
which clearly allows us to extract an unlimited number of arguments
(whereas @code{.Call} has a limit, albeit at 65 not a small one).

More usefully, the @code{.External} interface provides an easy way to
handle calls with a variable number of arguments, as @code{length(args)}
will give the number of arguments supplied (of which the first is
ignored).  We may need to know the names (`tags') given to the actual
arguments, which we can by using the @code{TAG} macro and using
something like the following example, that prints the names and the first
value of its arguments if they are vector types.

@example
@group
#include <R_ext/PrtUtil.h>

SEXP showArgs(SEXP args)
@{
  int i, nargs;
  Rcomplex cpl;
  const char *name;
  SEXP el;
@end group

@group
  args = CDR(args); /* skip 'name' */
  for(i = 0; args != R_NilValue; i++, args = CDR(args)) @{
    args = CDR(args);
    name = CHAR(PRINTNAME(TAG(args)));
    switch(TYPEOF(CAR(args))) @{
    case REALSXP:
      Rprintf("[%d] '%s' %f\n", i+1, name, REAL(CAR(args))[0]);
      break;
@end group
@group
    case LGLSXP:
    case INTSXP:
      Rprintf("[%d] '%s' %d\n", i+1, name, INTEGER(CAR(args))[0]);
      break;
@end group
@group
    case CPLXSXP:
      cpl = COMPLEX(CAR(args))[0];
      Rprintf("[%d] '%s' %f + %fi\n", i+1, name, cpl.r, cpl.i);
      break;
@end group
@group
    case STRSXP:
      Rprintf("[%d] '%s' %s\n", i+1, name,
             CHAR(STRING_ELT(CAR(args), 0)));
      break;
@end group
@group
    default:
      Rprintf("[%d] '%s' R type\n", i+1, name);
    @}
  @}
  return(R_NilValue);
@}
@end group
@end example

This can be called by the wrapper function

@example
showArgs <- function(...) .External("showArgs", ...)
@end example

@noindent
Note that this style of programming is convenient but not necessary, as
an alternative style is

@example
showArgs1 <- function(...) .Call("showArgs1", list(...))
@end example

@noindent
The (very similar) C code is in the scripts.

@node Missing and special values,  , Calling .External, Interface functions .Call and .External
@subsection Missing and special values
@cindex Missing values
@cindex IEEE special values

One piece of error-checking the @code{.C} call does (unless @code{NAOK}
is true) is to check for missing (@code{NA}) and @acronym{IEEE} special
values (@code{Inf}, @code{-Inf} and @code{NaN}) and give an error if any
are found.  With the @code{.Call} interface these will be passed to our
code.  In this example the special values are no problem, as
@acronym{IEEE} arithmetic will handle them correctly.  In the current
implementation this is also true of @code{NA} as it is a type of
@code{NaN}, but it is unwise to rely on such details.  Thus we will
re-write the code to handle @code{NA}s using macros defined in
@file{R_exts/Arith.h} included by @file{R.h}.

The code changes are the same in any of the versions of @code{convolve2}
or @code{convolveE}:

@example
@group
    ...
  for(i = 0; i < na; i++)
    for(j = 0; j < nb; j++)
        if(ISNA(xa[i]) || ISNA(xb[j]) || ISNA(xab[i + j]))
          xab[i + j] = NA_REAL;
        else
          xab[i + j] += xa[i] * xb[j];
    ...
@end group
@end example

@findex ISNA
@findex ISNAN

Note that the @code{ISNA} macro, and the similar macros @code{ISNAN}
(which checks for @code{NaN} or @code{NA}) and @code{R_FINITE} (which is
false for @code{NA} and all the special values), only apply to numeric
values of type @code{double}.  Missingness of integers, logicals and
character strings can be tested by equality to the constants
@code{NA_INTEGER}, @code{NA_LOGICAL} and @code{NA_STRING}.  These and
@code{NA_REAL} can be used to set elements of @R{} vectors to @code{NA}.

The constants @code{R_NaN}, @code{R_PosInf}, @code{R_NegInf} and
@code{R_NaReal} can be used to set @code{double}s to the special values.

@node Evaluating R expressions from C, Parsing R code from C, Interface functions .Call and .External, System and foreign language interfaces
@section Evaluating R expressions from C
@cindex Evaluating R expressions from C

We noted that the @code{call_R} interface could be used to evaluate @R{}
expressions from C code, but the current interfaces are much more
convenient to use.  The main function we will use is

@example
SEXP eval(SEXP expr, SEXP rho);
@end example

@noindent
the equivalent of the interpreted @R{} code @code{eval(expr, envir =
rho)}, although we can also make use of @code{findVar}, @code{defineVar}
and @code{findFun} (which restricts the search to functions).

To see how this might be applied, here is a simplified internal version
of @code{lapply} for expressions, used as

@example
@group
a <- list(a = 1:5, b = rnorm(10), test = runif(100))
.Call("lapply", a, quote(sum(x)), new.env())
@end group
@end example

@noindent
with C code

@example
@group
SEXP lapply(SEXP list, SEXP expr, SEXP rho)
@{
  R_len_t i, n = length(list);
  SEXP ans;

  if(!isNewList(list)) error("`list' must be a list");
  if(!isEnvironment(rho)) error("`rho' should be an environment");
  PROTECT(ans = allocVector(VECSXP, n));
  for(i = 0; i < n; i++) @{
    defineVar(install("x"), VECTOR_ELT(list, i), rho);
    SET_VECTOR_ELT(ans, i, eval(expr, rho));
  @}
  setAttrib(ans, R_NamesSymbol, getAttrib(list, R_NamesSymbol));
  UNPROTECT(1);
  return(ans);
@}
@end group
@end example

It would be closer to @code{lapply} if we could pass in a function
rather than an expression.  One way to do this is @emph{via} interpreted
@R{} code as in the next example, but it is possible (if somewhat
obscure) to do this in C code.  The following is based on the code in
@file{src/main/optimize.c}.

@example
@group
SEXP lapply2(SEXP list, SEXP fn, SEXP rho)
@{
  R_len_t i, n = length(list);
  SEXP R_fcall, ans;

  if(!isNewList(list)) error("`list' must be a list");
  if(!isFunction(fn)) error("`fn' must be a function");
  if(!isEnvironment(rho)) error("`rho' should be an environment");
  PROTECT(R_fcall = lang2(fn, R_NilValue));
  PROTECT(ans = allocVector(VECSXP, n));
  for(i = 0; i < n; i++) @{
    SETCADR(R_fcall, VECTOR_ELT(list, i));
    SET_VECTOR_ELT(ans, i, eval(R_fcall, rho));
  @}
  setAttrib(ans, R_NamesSymbol, getAttrib(list, R_NamesSymbol));
  UNPROTECT(2);
  return(ans);
@}
@end group
@end example

@noindent
used by

@example
.Call("lapply2", a, sum, new.env())
@end example

@noindent
Function @code{lang2} creates an executable pairlist of two elements, but
this will only be clear to those with a knowledge of a LISP-like
language.

As a more comprehensive example of constructing an @R{} call in C code
and evaluating, consider the following fragment of
@code{printAttributes} in @file{src/main/print.c}.

@example
    /* Need to construct a call to
       print(CAR(a), digits=digits)
       based on the R_print structure, then eval(call, env).
       See do_docall for the template for this sort of thing.
    */
    SEXP s, t;
    PROTECT(t = s = allocList(3));
    SET_TYPEOF(s, LANGSXP);
    CAR(t) = install("print"); t = CDR(t);
    CAR(t) = CAR(a); t = CDR(t);
    CAR(t) = allocVector(INTSXP, 1);
    INTEGER(CAR(t))[0] = digits;
    SET_TAG(t, install("digits"));
    eval(s, env);
    UNPROTECT(1);
@end example

@noindent
At this point @code{CAR(a)} is the @R{} object to be printed, the
current attribute.  There are three steps: the call is constructed as
a pairlist of length 3, the list is filled in, and the expression
represented by the pairlist is evaluated.

A pairlist is quite distinct from a generic vector list, the only
user-visible form of list in @R{}.  A pairlist is a linked list (with
@code{CDR(t)} computing the next entry), with items (accessed by
@code{CAR(t)}) and names or tags (set by @code{SET_TAG}).  In this call
there are to be three items, a symbol (pointing to the function to be
called) and two argument values, the first unnamed and the second named.
Setting the type to @code{LANGSXP} makes this a call which can be evaluated.

@menu
* Zero-finding::                
* Calculating numerical derivatives::  
@end menu

@node Zero-finding, Calculating numerical derivatives, Evaluating R expressions from C, Evaluating R expressions from C
@subsection Zero-finding
@cindex Zero-finding

In this section we re-work the example of @code{call_S} in Becker,
Chambers & Wilks (1988) on finding a zero of a univariate function,
The @R{} code and an example are

@example
zero <- function(f, guesses, tol = 1e-7) @{
  f.check <- function(x) @{
    x <- f(x)
    if(!is.numeric(x)) stop("Need a numeric result")
    as.double(x)
  @}
  .Call("zero", body(f.check), as.double(guesses), as.double(tol),
        new.env())
@}

cube1 <- function(x) (x^2 + 1) * (x - 1.5)
zero(cube1, c(0, 5))
@end example

@noindent
where this time we do the coercion and error-checking in the @R{} code.
The C code is

@example
@group
SEXP mkans(double x)
@{
    SEXP ans;
    PROTECT(ans = allocVector(REALSXP, 1));
    REAL(ans)[0] = x;
    UNPROTECT(1);
    return ans;
@}
@end group

@group
double feval(double x, SEXP f, SEXP rho)
@{
    defineVar(install("x"), mkans(x), rho);
    return(REAL(eval(f, rho))[0]);
@}
@end group

@group
SEXP zero(SEXP f, SEXP guesses, SEXP stol, SEXP rho)
@{
    double x0 = REAL(guesses)[0], x1 = REAL(guesses)[1],
           tol = REAL(stol)[0];
    double f0, f1, fc, xc;
@end group

@group
    if(tol <= 0.0) error("non-positive tol value");
    f0 = feval(x0, f, rho); f1 = feval(x1, f, rho);
    if(f0 == 0.0) return mkans(x0);
    if(f1 == 0.0) return mkans(x1);
    if(f0*f1 > 0.0) error("x[0] and x[1] have the same sign");
@end group

@group
    for(;;) @{
        xc = 0.5*(x0+x1);
        if(fabs(x0-x1) < tol) return  mkans(xc);
        fc = feval(xc, f, rho);
        if(fc == 0) return  mkans(xc);
        if(f0*fc > 0.0) @{
            x0 = xc; f0 = fc;
        @} else @{
            x1 = xc; f1 = fc;
        @}
    @}
@}
@end group
@end example

@noindent
The C code is essentially unchanged from the @code{call_R} version, just
using a couple of functions to convert from @code{double} to @code{SEXP}
and to evaluate @code{f.check}.

@node Calculating numerical derivatives,  , Zero-finding, Evaluating R expressions from C
@subsection Calculating numerical derivatives
@cindex Numerical derivatives

We will use a longer example (by Saikat DebRoy) to illustrate the use of
evaluation and @code{.External}.  This calculates numerical derivatives,
something that could be done as effectively in interpreted @R{} code but
may be needed as part of a larger C calculation.

An interpreted @R{} version and an example are

@example
@group
numeric.deriv <- function(expr, theta, rho=sys.frame(sys.parent()))
@{
  eps <- sqrt(.Machine$double.eps)
  ans <- eval(substitute(expr), rho)
  grad <- matrix(,length(ans), length(theta),
                 dimnames=list(NULL, theta))
  for (i in seq(along=theta)) @{
    old <- get(theta[i], envir=rho)
    delta <- eps * min(1, abs(old))
    assign(theta[i], old+delta, envir=rho)
    ans1 <- eval(substitute(expr), rho)
    assign(theta[i], old, envir=rho)
    grad[, i] <- (ans1 - ans)/delta
  @}
  attr(ans, "gradient") <- grad
  ans
@}
omega <- 1:5; x <- 1; y <- 2
numeric.deriv(sin(omega*x*y), c("x", "y"))
@end group
@end example

@noindent
where @code{expr} is an expression, @code{theta} a character vector of
variable names and @code{rho} the environment to be used.

For the compiled version the call from @R{} will be

@example
.External("numeric_deriv", @var{expr}, @var{theta}, @var{rho})
@end example

@noindent
with example usage

@example
.External("numeric_deriv", quote(sin(omega*x*y)),
          c("x", "y"), .GlobalEnv)
@end example

@noindent
Note the need to quote the expression to stop it being evaluated.

Here is the complete C code which we will explain section by section.

@example
@group
#include <R.h> /* for DOUBLE_EPS */
#include <Rinternals.h>

SEXP numeric_deriv(SEXP args)
@{
  SEXP theta, expr, rho, ans, ans1, gradient, par, dimnames;
  double tt, xx, delta, eps = sqrt(DOUBLE_EPS), *rgr, *rans;
  int start, i, j;
@end group

@group
  expr = CADR(args);
  if(!isString(theta = CADDR(args)))
    error("theta should be of type character");
  if(!isEnvironment(rho = CADDDR(args)))
    error("rho should be an environment");
@end group

@group
  PROTECT(ans = coerceVector(eval(expr, rho), REALSXP));
  PROTECT(gradient = allocMatrix(REALSXP, LENGTH(ans), LENGTH(theta)));
  rgr = REAL(gradient); rans = REAL(ans);
@end group

@group
  for(i = 0, start = 0; i < LENGTH(theta); i++, start += LENGTH(ans)) @{
    PROTECT(par = findVar(install(CHAR(STRING_ELT(theta, i))), rho));
    tt = REAL(par)[0];
    xx = fabs(tt);
    delta = (xx < 1) ? eps : xx*eps;
    REAL(par)[0] += delta;
    PROTECT(ans1 = coerceVector(eval(expr, rho), REALSXP));
    for(j = 0; j < LENGTH(ans); j++)
      rgr[j + start] = (REAL(ans1)[j] - rans[j])/delta;
    REAL(par)[0] = tt;
    UNPROTECT(2); /* par, ans1 */
  @}
@end group

@group
  PROTECT(dimnames = allocVector(VECSXP, 2));
  SET_VECTOR_ELT(dimnames, 1,  theta);
  dimnamesgets(gradient, dimnames);
  setAttrib(ans, install("gradient"), gradient);
  UNPROTECT(3); /* ans  gradient  dimnames */
  return ans;
@}
@end group
@end example

The code to handle the arguments is

@example
@group
  expr = CADR(args);
  if(!isString(theta = CADDR(args)))
    error("theta should be of type character");
  if(!isEnvironment(rho = CADDDR(args)))
    error("rho should be an environment");
@end group
@end example

@noindent
Note that we check for correct types of @code{theta} and @code{rho} but
do not check the type of @code{expr}.  That is because @code{eval} can
handle many types of @R{} objects other than @code{EXPRSXP}.  There is
no useful coercion we can do, so we stop with an error message if the
arguments are not of the correct mode.

The first step in the code is to evaluate the expression in the
environment @code{rho}, by

@example
  PROTECT(ans = coerceVector(eval(expr, rho), REALSXP));
@end example

@noindent
We then allocate space for the calculated derivative by

@example
  PROTECT(gradient = allocMatrix(REALSXP, LENGTH(ans), LENGTH(theta)));
@end example

@noindent
The first argument to @code{allocMatrix} gives the @code{SEXPTYPE} of
the matrix: here we want it to be @code{REALSXP}.  The other two
arguments are the numbers of rows and columns.

@example
@group
  for(i = 0, start = 0; i < LENGTH(theta); i++, start += LENGTH(ans)) @{
    PROTECT(par = findVar(install(CHAR(STRING_ELT(theta, i))), rho));
@end group
@end example

@noindent
Here, we are entering a for loop.  We loop through each of the
variables.  In the @code{for} loop, we first create a symbol
corresponding to the @code{i}'th element of the @code{STRSXP}
@code{theta}.  Here, @code{STRING_ELT(theta, i)} accesses the
@code{i}'th element of the @code{STRSXP} @code{theta}.  Macro
@code{CHAR()} extracts the actual character
representation@footnote{@pxref{Character encoding issues} for why this
might not be what is required.} of it: it returns a pointer.  We then
install the name and use @code{findVar} to find its value.

@example
@group
    tt = REAL(par)[0];
    xx = fabs(tt);
    delta = (xx < 1) ? eps : xx*eps;
    REAL(par)[0] += delta;
    PROTECT(ans1 = coerceVector(eval(expr, rho), REALSXP));
@end group
@end example

@noindent
We first extract the real value of the parameter, then calculate
@code{delta}, the increment to be used for approximating the numerical
derivative.  Then we change the value stored in @code{par} (in
environment @code{rho}) by @code{delta} and evaluate @code{expr} in
environment @code{rho} again.  Because we are directly dealing with
original @R{} memory locations here, @R{} does the evaluation for the
changed parameter value.

@example
@group
    for(j = 0; j < LENGTH(ans); j++)
      rgr[j + start] = (REAL(ans1)[j] - rans[j])/delta;
    REAL(par)[0] = tt;
    UNPROTECT(2);
  @}
@end group
@end example

@noindent
Now, we compute the @code{i}'th column of the gradient matrix.  Note how
it is accessed: @R{} stores matrices by column (like FORTRAN).

@example
@group
  PROTECT(dimnames = allocVector(VECSXP, 2));
  SET_VECTOR_ELT(dimnames, 1, theta);
  dimnamesgets(gradient, dimnames);
  setAttrib(ans, install("gradient"), gradient);
  UNPROTECT(3);
  return ans;
@}
@end group
@end example

@noindent
First we add column names to the gradient matrix.  This is done by
allocating a list (a @code{VECSXP}) whose first element, the row names,
is @code{NULL} (the default) and the second element, the column names,
is set as @code{theta}.  This list is then assigned as the attribute
having the symbol @code{R_DimNamesSymbol}.  Finally we set the gradient
matrix as the gradient attribute of @code{ans}, unprotect the remaining
protected locations and return the answer @code{ans}.

@node Parsing R code from C, External pointers and weak references, Evaluating R expressions from C, System and foreign language interfaces
@section Parsing R code from C
@cindex Parsing R code from C

Suppose an @R{} extension want to accept an @R{} expression from the
user and evaluate it.  The previous section covered evaluation, but the
expression will be entered as text and needs to be parsed first.  A
small part of @R{}'s parse interface is declared in header file
@file{R_ext/Parse.h}@footnote{This is only guaranteed to show the
current interface: it is liable to change.}.

An example of the usage can be found in the (example) Windows package
@pkg{windlgs} included in the @R{} source tree.  The essential part is

@example
@group
#include <R.h>
#include <Rinternals.h>
#include <R_ext/Parse.h>

SEXP menu_ttest3()
@{
    char cmd[256];
    SEXP cmdSexp, cmdexpr, ans = R_NilValue;
    int i;
    ParseStatus status;
   ...
    if(done == 1) @{
        PROTECT(cmdSexp = allocVector(STRSXP, 1));
        SET_STRING_ELT(cmdSexp, 0, mkChar(cmd));
        cmdexpr = PROTECT(R_ParseVector(cmdSexp, -1, &status, R_NilValue));
        if (status != PARSE_OK) @{
            UNPROTECT(2);
            error("invalid call %s", cmd);
        @}
        /* Loop is needed here as EXPSEXP will be of length > 1 */
        for(i = 0; i < length(cmdexpr); i++)
            ans = eval(VECTOR_ELT(cmdexpr, i), R_GlobalEnv);
        UNPROTECT(2);
    @}
    return ans;
@}
@end group
@end example
@noindent
Note that a single line of text may give rise to more than one @R{}
expression.

@findex R_ParseVector
@code{R_ParseVector} is essentially the code used to implement
@code{parse(text=)} at @R{} level.  The first argument is a character
vector (corresponding to @code{text}) and the second the maximal number
of expressions to parse (corresponding to @code{n}).  The third argument
is a pointer to a variable of an enumeration type, and it is normal (as
@code{parse} does) to regard all values other than @code{PARSE_OK} as an
error.  Other values which might be returned are @code{PARSE_INCOMPLETE}
(an incomplete expression was found) and @code{PARSE_ERROR} (a syntax
error), in both cases the value returned being @code{R_NilValue}.
The fourth argument is a @code{srcfile} object or the @R{} @code{NULL}
object (as in the example above). In the former case a @code{srcref}
attribute would be attached to the result, containing a list of
@code{srcref} objects of the same length as the expression, to allow it to be
echoed with its original formatting.

@node External pointers and weak references, Vector accessor functions, Parsing R code from C, System and foreign language interfaces
@section External pointers and weak references

The @code{SEXPTYPE}s @code{EXTPTRSXP} and @code{WEAKREFSXP} can be
encountered at @R{} level, but are created in C code.

@cindex external pointer
External pointer @code{SEXP}s are intended to handle references to C
structures such as `handles', and are used for this purpose in package
@pkg{RODBC} for example.  They are unusual in their copying semantics in
that when an @R{} object is copied, the external pointer object is not
duplicated.  (For this reason external pointers should only be used as
part of an object with normal semantics, for example an attribute or an
element of a list.)

An external pointer is created by

@example
SEXP R_MakeExternalPtr(void *p, SEXP tag, SEXP prot);
@end example

@noindent
where @code{p} is the pointer (and hence this cannot portably be a
function pointer), @code{tag} is a symbol identifying the (class of)
object, and @code{prot} is a reference to a `protecting' object: the
external pointer object will remain in existence (be protected from
garbage collection) for the lifetime of the `protecting' object.  Both
@code{tag} and @code{prot} can be @code{R_NilValue}, and often are.

The elements of an external pointer can be accessed and set @emph{via}

@example
void *R_ExternalPtrAddr(SEXP s);
SEXP R_ExternalPtrTag(SEXP s);
SEXP R_ExternalPtrProtected(SEXP s);
void R_ClearExternalPtr(SEXP s);
void R_SetExternalPtrAddr(SEXP s, void *p);
void R_SetExternalPtrTag(SEXP s, SEXP tag);
void R_SetExternalPtrProtected(SEXP s, SEXP p);
@end example

@noindent
Clearing a pointer sets its value to the C @code{NULL} pointer.

@cindex finalizer
An external pointer object can have a @emph{finalizer}, a piece of code
to be run when the object is garbage collected.  This can be @R{} code
or C code, and the various interfaces are

@example
void R_RegisterFinalizer(SEXP s, SEXP fun);
void R_RegisterFinalizerEx(SEXP s, SEXP fun, Rboolean onexit);

typedef void (*R_CFinalizer_t)(SEXP);
void R_RegisterCFinalizer(SEXP s, R_CFinalizer_t fun);
void R_RegisterCFinalizerEx(SEXP s, R_CFinalizer_t fun, Rboolean onexit);
@end example

@noindent
The @R{} function indicated by @code{fun} should be a function of a
single argument, the object to be finalized.  @R{} does not perform a
garbage collection when shutting down, and the @code{onexit} argument of
the extended forms can be used to ask that the finalizer be run during a
normal shutdown of the @R{} session.  It is suggested that it is good
practice to clear the pointer on finalization.

The only @R{} level function for interacting with external pointers is
@code{reg.finalizer} which can be used to set a finalizer.

It is probably not a good idea to allow an external pointer to be
@code{save}d and then reloaded, but it this happens the pointer will be
set to the C @code{NULL} pointer.


@cindex weak reference
Weak references are used to allow the programmer to maintain information
on entities without preventing the garbage collection of the entities
once they become unreachable.

A weak reference contains a key and a value.  The value is reachable is
if it either reachable directly or via weak references with reachable
keys.  Once a value is determined to be unreachable during garbage
collection, the key and value are set to @code{R_NilValue} and the
finalizer will be run later in the garbage collection.

Weak reference objects are created by one of

@example
SEXP R_MakeWeakRef(SEXP key, SEXP val, SEXP fin, Rboolean onexit);
SEXP R_MakeWeakRefC(SEXP key, SEXP val, R_CFinalizer_t fin,
                    Rboolean onexit);
@end example

@noindent
where the @R{} or C finalizer are specified in exactly the same way as
for an external pointer object (whose finalization interface is
implemented via weak references).

The parts can be accessed @emph{via}

@example
SEXP R_WeakRefKey(SEXP w);
SEXP R_WeakRefValue(SEXP w);
void R_RunWeakRefFinalizer(SEXP w);
@end example

A toy example of the use of weak references can be found at
@url{http://www.stat.uiowa.edu/~luke/R/references/weakfinex.html,
@code{www.@/stat.@/uiowa.@/edu/@/~luke/@/R/references/@/weakfinex.html}},
but that is used to add finalizers to external pointers which can now be
done more directly.


@node Vector accessor functions, Character encoding issues, External pointers and weak references, System and foreign language interfaces
@section Vector accessor functions 

The vector accessors like @code{REAL} and @code{INTEGER} and
@code{VECTOR_ELT} are @emph{functions} when used in @R{} extensions.
(For efficiency they are macros when used in the @R{} source code, apart
from @code{SET_STRING_ELT} and @code{SET_VECTOR_ELT} which are always
functions.)

As from @R{} 2.4.0 the accessor functions check that they are being used
on an appropriate type of @code{SEXP}.  By default an certain amount of
misuse is allowed where the internal representation is the same: for
example @code{LOGICAL} can be used on a @code{INTSXP} and
@code{SET_VECTOR_ELT} on a @code{STRSXP}.  Strict checking can be
enabled by compiling @R{} (specifically @file{src/main/memory.c}) with
@samp{USE_TYPE_CHECKING_STRICT} defined (e.g. in as the configure
variable @samp{DEFS} on a Unix-alike).

If efficiency is essential, the macro versions of the accessors can be 
obtained by defining @samp{USE_RINTERNALS} before including
@file{Rinternals.h}.  If you find it necessary to do so, please do test
that your code compiled without @samp{USE_RINTERNALS} defined as this
provides a stricter test that the accessors have been used correctly.

@node Character encoding issues,  , Vector accessor functions, System and foreign language interfaces
@section Character encoding issues

@findex translateChar
As from @R{} 2.5.0 @code{CHARSXP}s can be marked as coming from a known
encoding (Latin-1 or UTF-8).  This is mainly intended for human-readable
output, and most packages can just treat such @code{CHARSXP}s as a
whole.  However, if they need to be interpreted as characters or output
at C level then it would normally be correct to ensure that they are
converted to the encoding of the currrent locale: this can be done by
accessing the data in the @code{CHARSXP} by @code{translateChar} rather
than by @code{CHAR}.  If re-encoding is needed this allocates memory
with @code{R_alloc} which thus persists to the end of the
@code{.Call}/@code{.External} call unless @code{vmaxset} is used.

@node The R API, Generic functions and methods, System and foreign language interfaces, Top
@chapter The R @acronym{API}: entry points for C code

@menu
* Memory allocation::           
* Error handling::              
* Random numbers::              
* Missing and IEEE values::     
* Printing::                    
* Calling C from FORTRAN and vice versa::  
* Numerical analysis subroutines::  
* Optimization::                
* Integration::                 
* Utility functions::           
* Re-encoding::                 
* Allowing interrupts::         
* Platform and version information::  
* Inlining C functions::        
* Standalone Mathlib::          
* Organization of header files::  
@end menu

There are a large number of entry points in the @R{} executable/DLL that
can be called from C code (and some that can be called from FORTRAN
code).  Only those documented here are stable enough that they will only
be changed with considerable notice.

The recommended procedure to use these is to include the header file
@file{R.h} in your C code by

@example
#include <R.h>
@end example

@noindent
This will include several other header files from the directory
@file{@var{R_INCLUDE_DIR}/R_ext}, and there are other header files
there that can be included too, but many of the features they contain
should be regarded as undocumented and unstable.

An alternative is to include the header file @file{S.h}, which may be
useful when porting code from @Sl{}.  This includes rather less than
@file{R.h}, and has extra some compatibility definitions (for example
the @code{S_complex} type from @Sl{}).

The defines used for compatibility with @Sl{} sometimes causes
conflicts (notably with Windows headers), and the known
problematic defines can be removed by defining @code{STRICT_R_HEADERS}.

Most of these header files, including all those included by @file{R.h},
can be used from C++ code.  Some others need to be included within an
@code{extern "C"} declaration, and for clarity this is advisable for all
@R{} header files.

@quotation Note
Because @R{} re-maps many of its external names to avoid clashes with
user code, it is @emph{essential} to include the appropriate header
files when using these entry points.
@end quotation

This remapping can cause problems@footnote{Known problems are redefining
@code{error}, @code{length}, @code{vector} and @code{warning}}, and can
be eliminated by defining @code{R_NO_REMAP} and prepending @code{Rf_} to
@emph{all} the function names used from @file{Rinternals.h} and
@file{R_ext/Error.h}.

We can classify the entry points as

@itemize
@item @emph{API}
Entry points which are documented in this manual and declared in an
installed header file.  These can be used in distributed packages and
will only be changed after deprecation.

@item @emph{public}
Entry points declared in an installed header file that are exported
on all @R{} platforms but are not documented and subject to change
without notice.

@item @emph{private}
Entry points that are used when building @R{} and exported on all @R{}
platforms but are not declared in the installed header files.
Do not use these in distributed code.

@item @emph{hidden}
Entry points that are where possible (Windows and some modern Unix
compilers/loaders when using @R{} as a shared library) not exported.
@end itemize

@node Memory allocation, Error handling, The R API, The R API
@section Memory allocation
@cindex Memory allocation from C

@menu
* Transient::                   
* User-controlled::             
@end menu

There are two types of memory allocation available to the C programmer,
one in which @R{} manages the clean-up and the other in which user
has full control (and responsibility).

@node Transient, User-controlled, Memory allocation, Memory allocation
@subsection Transient storage allocation
@findex R_alloc
@findex S_alloc
@findex S_realloc
@findex vmaxget
@findex vmaxset

Here @R{} will reclaim the memory at the end of the call to @code{.C}.
Use

@example
char *R_alloc(size_t @var{n}, int @var{size})
@end example

@noindent
which allocates @var{n} units of @var{size} bytes each.  A typical usage
(from package @pkg{stats}) is

@example
x = (int *) R_alloc(nrows(merge)+2, sizeof(int));
@end example

@noindent
(@code{size_t} is defined in @file{stddef.h} which the header defining
@code{R_alloc} includes.)

There is a similar call, @code{S_alloc} (for compatibility with older
versions of @Sl{}) which zeroes the memory allocated,

@example
char *S_alloc(long @var{n}, int @var{size})
@end example

@noindent
and

@example
char *S_realloc(char *@var{p}, long @var{new}, long @var{old}, int @var{size})
@end example

@noindent
which changes the allocation size from @var{old} to @var{new} units, and
zeroes the additional units.

For compatibility with current versions of @Sl{}, header @file{S.h}
(only) defines wrapper macros equivalent to

@example
type* Salloc(long @var{n}, int @var{type})
type* Srealloc(char *@var{p}, long @var{new}, long @var{old}, int @var{type})
@end example

This memory is taken from the heap, and released at the end of the
@code{.C}, @code{.Call} or @code{.External} call.  Users can also manage
it, by noting the current position with a call to @code{vmaxget} and
clearing memory allocated subsequently by a call to @code{vmaxset}.
This is only recommended for experts.

Note that this memory will be freed on error or user interrupt
(if allowed: @pxref{Allowing interrupts}).

Note that although @var{n} is @code{long}, there are limits imposed by
@R{}'s internal allocation mechanism.  These will only come into play on
64-bit systems, where the current limit for @var{n} is just under 16Gb.

@node User-controlled,  , Transient, Memory allocation
@subsection User-controlled memory
@findex Calloc
@findex Realloc
@findex Free

The other form of memory allocation is an interface to @code{malloc},
the interface providing @R{} error handling.  This memory lasts until
freed by the user and is additional to the memory allocated for the @R{}
workspace.

The interface functions are

@example
@group
@var{type}* Calloc(size_t @var{n}, @var{type})
@var{type}* Realloc(@var{any} *@var{p}, size_t @var{n}, @var{type})
void Free(@var{any} *@var{p})
@end group
@end example

@noindent
providing analogues of @code{calloc}, @code{realloc} and @code{free}.
If there is an error during allocation it is handled by @R{}, so if
these routines return the memory has been successfully allocated or
freed.  @code{Free} will set the pointer @var{p} to @code{NULL}.  (Some
but not all versions of @Sl{} do so.)

Users should arrange to @code{Free} this memory when no longer needed,
including on error or user interrupt.  This can often be done most
conveniently from an @code{on.exit} action in the calling @R{} function
-- see @code{pwilcox} for an example.

Do not assume that memory allocated by @code{Calloc}/@code{Realloc}
comes from the same pool as used by @code{malloc}: in particular do not
use @code{free} or @code{strdup} with it.

These entry points need to be prefixed by @code{R_} if
@code{STRICT_R_HEADERS} has been defined.


@node Error handling, Random numbers, Memory allocation, The R API
@section Error handling
@cindex Error handling from C

The basic error handling routines are the equivalents of @code{stop} and
@code{warning} in @R{} code, and use the same interface.

@example
@group
void error(const char * @var{format}, ...);
void warning(const char * @var{format}, ...);
@end group
@end example

@noindent
These have the same call sequences as calls to @code{printf}, but in the
simplest case can be called with a single character string argument
giving the error message. (Don't do this if the string contains @samp{%}
or might otherwise be interpreted as a format.)

If @code{STRICT_R_HEADERS} is not defined there is also an
@Sl{}-compatibility interface which uses calls of the form

@example
@group
PROBLEM ...... ERROR
MESSAGE ...... WARN
PROBLEM ...... RECOVER(NULL_ENTRY)
MESSAGE ...... WARNING(NULL_ENTRY)
@end group
@end example

@noindent
the last two being the forms available in all @Sl{} versions.  Here
@samp{......} is a set of arguments to @code{printf}, so can be a string
or a format string followed by arguments separated by commas.

@menu
* Error handling from FORTRAN::  
@end menu

@node Error handling from FORTRAN,  , Error handling, Error handling
@subsection Error handling from FORTRAN
@cindex Error handling from FORTRAN

There are two interface function provided to call @code{error} and
@code{warning} from FORTRAN code, in each case with a simple character
string argument.  They are defined as

@example
@group
subroutine rexit(@var{message})
subroutine rwarn(@var{message})
@end group
@end example

Messages of more than 255 characters are truncated, with a warning.


@node Random numbers, Missing and IEEE values, Error handling, The R API
@section Random number generation
@cindex Random numbers in C
@findex unif_rand
@findex norm_rand
@findex exp_rand
@findex GetRNGstate
@findex PutRNGstate
@findex .Random.seed
@findex seed_in
@findex seed_out

The interface to @R{}'s internal random number generation routines is

@example
@group
double unif_rand();
double norm_rand();
double exp_rand();
@end group
@end example

@noindent
giving one uniform, normal or exponential pseudo-random variate.
However, before these are used, the user must call

@example
GetRNGstate();
@end example

@noindent
and after all the required variates have been generated, call

@example
PutRNGstate();
@end example

@noindent
These essentially read in (or create) @code{.Random.seed} and write it
out after use.

File @file{S.h} defines @code{seed_in} and @code{seed_out} for
@Sl{}-compatibility rather than @code{GetRNGstate} and
@code{PutRNGstate}.  These take a @code{long *} argument which is
ignored.

The random number generator is private to @R{}; there is no way to
select the kind of RNG or set the seed except by evaluating calls to the
@R{} functions.

The C code behind @R{}'s @code{r@var{xxx}} functions can be accessed by
including the header file @file{Rmath.h}; @xref{Distribution
functions}.  Those calls generate a single variate and should also be
enclosed in calls to @code{GetRNGstate} and @code{PutRNGstate}.

@comment MM: FIXME   void rmultinom() is different, returning a vector!

In addition, there is an interface (defined in header
@file{R_ext/Applic.h}) to the generation of random 2-dimensional tables
with given row and column totals using Patefield's algorithm.

@deftypefun void rcont2 (int* @var{nrow}, int* @var{ncol}, int* @var{nrowt}, int* @var{ncolt}, int* @var{ntotal}, double* @var{fact}, int* @var{jwork}, int* @var{matrix})
Here, @var{nrow} and @var{ncol} give the numbers @math{nr} and @math{nc}
of rows and columns and @var{nrowt} and @var{ncolt} the corresponding
row and column totals, respectively, @var{ntotal} gives the sum of the
row (or columns) totals, @var{jwork} is a workspace of length @math{nc},
and on output @var{matrix} a contains the @math{nr * nc} generated
random counts in the usual column-major order.
@end deftypefun

@node Missing and IEEE values, Printing, Random numbers, The R API
@section Missing and @acronym{IEEE} special values
@cindex Missing values
@cindex IEEE special values
@findex ISNA
@findex ISNAN
@findex R_FINITE
@findex R_IsNaN
@findex R_PosInf
@findex R_NegInf
@findex NA_REAL

A set of functions is provided to test for @code{NA}, @code{Inf},
@code{-Inf} and @code{NaN}.  These functions are accessed via macros:

@example
@group
ISNA(@var{x})        @r{True for R's @code{NA} only}
ISNAN(@var{x})       @r{True for R's @code{NA} and @acronym{IEEE} @code{NaN}}
R_FINITE(@var{x})    @r{False for @code{Inf}, @code{-Inf}, @code{NA}, @code{NaN}}
@end group
@end example

@noindent
and via function @code{R_IsNaN} which is true for @code{NaN} but not
@code{NA}.

Do use @code{R_FINITE} rather than @code{isfinite} or @code{finite}; the
latter is often mendacious and @code{isfinite} is only available on a
few platforms, on which @code{R_FINITE} is a macro expanding to
@code{isfinite}.

Currently in C code @code{ISNAN} is a macro calling @code{isnan}.
(Since this gives problems on some C++ systems, if the @R{} headers is
called from C++ code a function call is used.)

You can check for @code{Inf} or @code{-Inf} by testing equality to
@code{R_PosInf} or @code{R_NegInf}, and set (but not test) an @code{NA}
as @code{NA_REAL}.

All of the above apply to @emph{double} variables only.  For integer
variables there is a variable accessed by the macro @code{NA_INTEGER}
which can used to set or test for missingness.


@node Printing, Calling C from FORTRAN and vice versa, Missing and IEEE values, The R API
@section Printing
@cindex Printing from C
@findex Rprintf
@findex REprintf
@findex Rvprintf
@findex REvprintf

The most useful function for printing from a C routine compiled into
@R{} is @code{Rprintf}.  This is used in exactly the same way as
@code{printf}, but is guaranteed to write to @R{}'s output (which might
be a @acronym{GUI} console rather than a file).  It is wise to write
complete lines (including the @code{"\n"}) before returning to @R{}.

The function @code{REprintf} is similar but writes on the error stream
(@code{stderr}) which may or may not be different from the standard
output stream.  Functions @code{Rvprintf} and @code{REvprintf} are
analogues using the @code{vprintf} interface.

@menu
* Printing from FORTRAN::       
@end menu

@node Printing from FORTRAN,  , Printing, Printing
@subsection Printing from FORTRAN
@cindex Printing from FORTRAN

On many systems FORTRAN @code{write} and @code{print} statements can be
used, but the output may not interleave well with that of C, and will be
invisible on @acronym{GUI} interfaces.  They are not portable and best
avoided.

Three subroutines are provided to ease the output of information from
FORTRAN code.

@example
@group
subroutine dblepr(@var{label}, @var{nchar}, @var{data}, @var{ndata})
subroutine realpr(@var{label}, @var{nchar}, @var{data}, @var{ndata})
subroutine intpr (@var{label}, @var{nchar}, @var{data}, @var{ndata})
@end group
@end example

@noindent
Here @var{label} is a character label of up to 255 characters,
@var{nchar} is its length (which can be @code{-1} if the whole label is
to be used), and @var{data} is an array of length at least @var{ndata}
of the appropriate type (@code{double precision}, @code{real} and
@code{integer} respectively).  These routines print the label on one
line and then print @var{data} as if it were an @R{} vector on
subsequent line(s).  They work with zero @var{ndata}, and so can be used
to print a label alone.

@node Calling C from FORTRAN and vice versa, Numerical analysis subroutines, Printing, The R API
@section Calling C from FORTRAN and vice versa
@cindex Calling C from FORTRAN and vice versa

Naming conventions for symbols generated by FORTRAN differ by platform:
it is not safe to assume that FORTRAN names appear to C with a trailing
underscore.  To help cover up the platform-specific differences there is
a set of macros that should be used.

@table @code
@item F77_SUB(@var{name})
to define a function in C to be called from FORTRAN
@item F77_NAME(@var{name})
to declare a FORTRAN routine in C before use
@item F77_CALL(@var{name})
to call a FORTRAN routine from C
@item F77_COMDECL(@var{name})
to declare a FORTRAN common block in C
@item F77_COM(@var{name})
to access a FORTRAN common block from C
@end table

On most current platforms these are all the same, but it is unwise to
rely on this.  Note that names with underscores are not legal in FORTRAN
77, and are not portably handled by the above macros.  (Also, all
FORTRAN names for use by @R{} are lower case, but this is not enforced
by the macros.)

For example, suppose we want to call R's normal random numbers from
FORTRAN.  We need a C wrapper along the lines of

@cindex Random numbers in FORTRAN
@example
@group
#include <R.h>

void F77_SUB(rndstart)(void) @{ GetRNGstate(); @}
void F77_SUB(rndend)(void) @{ PutRNGstate(); @}
double F77_SUB(normrnd)(void) @{ return norm_rand(); @}
@end group
@end example

@noindent
to be called from FORTRAN as in

@example
@group
      subroutine testit()
      double precision normrnd, x
      call rndstart()
      x = normrnd()
      call dblepr("X was", 5, x, 1)
      call rndend()
      end
@end group
@end example

@noindent
Note that this is not guaranteed to be portable, for the return
conventions might not be compatible between the C and FORTRAN compilers
used.  (Passing values via arguments is safer.)

The standard packages, for example @pkg{stats}, are a rich source of
further examples.



@node Numerical analysis subroutines, Optimization, Calling C from FORTRAN and vice versa, The R API
@section Numerical analysis subroutines
@cindex Numerical analysis subroutines from C

@R{} contains a large number of mathematical functions for its own use,
for example numerical linear algebra computations and special functions.

The header files @file{R_ext/BLAS.h}, @file{R_ext/Lapack.h} and
@file{R_ext/Linpack.h} contains declarations of the BLAS, LAPACK and
LINPACK/EISPACK linear algebra functions included in @R{}.  These
are expressed as calls to FORTRAN subroutines, and they will also be
usable from users' FORTRAN code.  Although not part of the official
@acronym{API}, this set of subroutines is unlikely to change (but might
be supplemented).

The header file @file{Rmath.h} lists many other functions that are
available and documented in the following subsections. Many of these are
C interfaces to the code behind @R{} functions, so the @R{} function
documentation may give further details.

@menu
* Distribution functions::      
* Mathematical functions::      
* Numerical Utilities::         
* Mathematical constants::      
@end menu

@node Distribution functions, Mathematical functions, Numerical analysis subroutines, Numerical analysis subroutines
@subsection Distribution functions
@cindex  Distribution functions from C

The routines used to calculate densities, cumulative distribution
functions and quantile functions for the standard statistical
distributions are available as entry points.

The arguments for the entry points follow the pattern of those for the
normal distribution:

@example
@group
double dnorm(double @var{x}, double @var{mu}, double @var{sigma}, int @var{give_log});
double pnorm(double @var{x}, double @var{mu}, double @var{sigma}, int @var{lower_tail},
             int @var{give_log});
double qnorm(double @var{p}, double @var{mu}, double @var{sigma}, int @var{lower_tail},
             int @var{log_p});
double rnorm(double @var{mu}, double @var{sigma});
@end group
@end example

@noindent
That is, the first argument gives the position for the density and CDF
and probability for the quantile function, followed by the
distribution's parameters.  Argument @var{lower_tail} should be
@code{TRUE} (or @code{1}) for normal use, but can be @code{FALSE} (or
@code{0}) if the probability of the upper tail is desired or specified.

Finally, @var{give_log} should be non-zero if the result is required on
log scale, and @var{log_p} should be non-zero if @var{p} has been
specified on log scale.

Note that you directly get the cumulative (or ``integrated'')
@emph{hazard} function, @eqn{H(t) = - \log(1 - F(t)), H(t) = - log(1 -
F(t))}, by using

@example
- p@var{dist}(t, ..., /*lower_tail = */ FALSE, /* give_log = */ TRUE)
@end example

@noindent
or shorter (and more cryptic) @code{- p@var{dist}(t, ..., 0, 1)}.
@cindex cumulative hazard

The random-variate generation routine @code{rnorm} returns one normal
variate. @xref{Random numbers}, for the protocol in using the
random-variate routines.
@cindex Random numbers in C

Note that these argument sequences are (apart from the names and that
@code{rnorm} has no @var{n}) exactly the same as the corresponding @R{}
functions of the same name, so the documentation of the @R{} functions
can be used.

For reference, the following table gives the basic name (to be prefixed
by @samp{d}, @samp{p}, @samp{q} or @samp{r} apart from the exceptions
noted) and distribution-specific arguments for the complete set of
distributions.

@quotation
@multitable @columnfractions .28 .22 .30
@item beta @tab @code{beta} @tab @code{a}, @code{b}
@item non-central beta @tab @code{nbeta} @tab @code{a}, @code{b}, @code{lambda}
@item binomial @tab @code{binom} @tab @code{n}, @code{p}
@item Cauchy @tab @code{cauchy} @tab @code{location}, @code{scale}
@item chi-squared @tab @code{chisq} @tab @code{df}
@item non-central chi-squared @tab @code{nchisq} @tab @code{df}, @code{lambda}
@item exponential @tab @code{exp} @tab @code{scale}
@item F @tab @code{f} @tab @code{n1}, @code{n2}
@item non-central F @tab @code{nf} @tab @code{n1}, @code{n2}, @code{ncp}
@item gamma @tab @code{gamma} @tab @code{shape}, @code{scale}
@item geometric @tab @code{geom} @tab @code{p}
@item hypergeometric @tab @code{hyper} @tab @code{NR}, @code{NB}, @code{n}
@item logistic @tab @code{logis} @tab @code{location}, @code{scale}
@item lognormal @tab @code{lnorm} @tab @code{logmean}, @code{logsd}
@item negative binomial @tab @code{nbinom} @tab @code{n}, @code{p}
@item normal @tab @code{norm} @tab @code{mu}, @code{sigma}
@item Poisson @tab @code{pois} @tab @code{lambda}
@item Student's t @tab @code{t} @tab @code{n}
@item non-central t @tab @code{nt} @tab @code{df}, @code{delta}
@item Studentized range @tab @code{tukey} (*) @tab @code{rr}, @code{cc}, @code{df}
@item uniform @tab @code{unif} @tab @code{a}, @code{b}
@item Weibull @tab @code{weibull} @tab @code{shape}, @code{scale}
@item Wilcoxon rank sum @tab @code{wilcox} @tab @code{m}, @code{n}
@item Wilcoxon signed rank @tab @code{signrank} @tab @code{n}
@end multitable
@end quotation

@noindent
Entries marked with an asterisk only have @samp{p} and @samp{q}
functions available, and none of the non-central distributions have
@samp{r} functions.  After a call to @code{dwilcox}, @code{pwilcox} or
@code{qwilcox} the function @code{wilcox_free()} should be called, and
similarly for the signed rank functions.

The argument names are not all quite the same as the @R{} ones.
@c ^^^ FIXME ?? (argument names in the C code wouldn't change the API ..) ^^
@c {don't want to change the R function argument names} -- <<

@node Mathematical functions, Numerical Utilities, Distribution functions, Numerical analysis subroutines
@subsection Mathematical functions

@findex gammafn
@findex lgammafn
@findex digamma
@findex trigamma
@findex tetragamma
@findex pentagamma
@findex psigamma
@cindex Gamma function
@deftypefun double gammafn (double @var{x})
@deftypefunx double lgammafn (double @var{x})
@deftypefunx double digamma (double @var{x})
@deftypefunx double trigamma (double @var{x})
@deftypefunx double tetragamma (double @var{x})
@deftypefunx double pentagamma (double @var{x})
@deftypefunx double psigamma (double @var{x}, double @var{deriv})
The Gamma function, its natural logarithm and first four derivatives and
the n-th derivative of Psi, the digamma function.
@end deftypefun

@findex beta
@findex lbeta
@cindex Beta function
@deftypefun double beta (double @var{a}, double @var{b})
@deftypefunx double lbeta (double @var{a}, double @var{b})
The (complete) Beta function and its natural logarithm.
@end deftypefun

@findex choose
@findex lchoose
@deftypefun double choose (double @var{n}, double @var{k})
@deftypefunx double lchoose (double @var{n}, double @var{k})
The number of combinations of @var{k} items chosen from from @var{n} and
its natural logarithm.  @var{n} and @var{k} are rounded to the nearest
integer.
@end deftypefun

@findex bessel_i
@findex bessel_j
@findex bessel_k
@findex bessel_y
@cindex Bessel functions
@deftypefun double bessel_i (double @var{x}, double @var{nu}, double @var{expo})
@deftypefunx double bessel_j (double @var{x}, double @var{nu})
@deftypefunx double bessel_k (double @var{x}, double @var{nu}, double @var{expo})
@deftypefunx double bessel_y (double @var{x}, double @var{nu})
Bessel functions of types I, J, K and Y with index @var{nu}.  For
@code{bessel_i} and @code{bessel_k} there is the option to return
@w{exp(-@var{x}) I(@var{x}; @var{nu})} or @w{exp(@var{x}) K(@var{x};
@var{nu})} if @var{expo} is 2. (Use @code{@var{expo} == 1} for unscaled
values.)
@end deftypefun


@node Numerical Utilities, Mathematical constants, Mathematical functions, Numerical analysis subroutines
@subsection Numerical Utilities
There are a few other numerical utility functions available as entry points.


@deftypefun double R_pow (double @var{x}, double @var{y})
@deftypefunx double R_pow_di (double @var{x}, int @var{i})
@code{R_pow(@var{x}, @var{y})} and @code{R_pow_di(@var{x}, @var{i})}
compute @code{@var{x}^@var{y}} and @code{@var{x}^@var{i}}, respectively
using @code{R_FINITE} checks and returning the proper result (the same
as @R{}) for the cases where @var{x}, @var{y} or @var{i} are 0 or
missing or infinite or @code{NaN}.
@end deftypefun

@deftypefun double pythag (double @var{a}, double @var{b})
@code{pythag(@var{a}, @var{b})} computes @code{sqrt(@var{a}^2 +
@var{b}^2)} without overflow or destructive underflow: for example it
still works when both @var{a} and @var{b} are between @code{1e200} and
@code{1e300} (in @acronym{IEEE} double precision).
@end deftypefun

@deftypefun double log1p (double @var{x})
Computes @code{log(1 + @var{x})} (@emph{log 1 @b{p}lus x}), accurately
even for small @var{x}, i.e., @eqn{|x| \ll 1, |x| << 1}.

This may be provided by your platform, in which case it is not included
in @file{Rmath.h}, but is (probably) in @file{math.h} which
@file{Rmath.h} includes.  For backwards compatibility with @R{} versions
prior to 1.5.0, the entry point @code{Rf_log1p} is still provided.
@end deftypefun

@deftypefun double log1pmx (double @var{x})
Computes @code{log(1 + @var{x}) - @var{x}} (@emph{log 1 @b{p}lus x @b{m}inus @b{x}}),
accurately even for small @var{x}, i.e., @eqn{|x| \ll 1, |x| << 1}.
@end deftypefun

@deftypefun double expm1 (double @var{x})
Computes @code{exp(@var{x}) - 1} (@emph{exp x @b{m}inus 1}), accurately
even for small @var{x}, i.e., @eqn{|x| \ll 1, |x| << 1}.

This may be provided by your platform, in which case it is not included
in @file{Rmath.h}, but is (probably) in @file{math.h} which
@file{Rmath.h} includes.
@end deftypefun

@deftypefun double lgamma1p (double @var{x})
Computes @code{log(gamma(@var{x} + 1))} (@emph{log(gamma(1 @b{p}lus x))}),
accurately even for small @var{x}, i.e., @eqn{0 < x < 0.5, 0 < x < 0.5}.
@end deftypefun

@deftypefun double logspace_add (double @var{logx}, double @var{logy})
@deftypefunx double logspace_sub (double @var{logx}, double @var{logy})
Compute the log of a sum or difference from logs of terms, i.e.,
``x + y'' as @code{log (exp(@var{logx}) + exp(@var{logy}))} and
``x - y'' as @code{log (exp(@var{logx}) - exp(@var{logy}))},
without causing overflows or throwing away too much accuracy.
@end deftypefun

@deftypefun int imax2 (int @var{x}, int @var{y})
@deftypefunx int imin2 (int @var{x}, int @var{y})
@deftypefunx double fmax2 (double @var{x}, double @var{y})
@deftypefunx double fmin2 (double @var{x}, double @var{y})
Return the larger (@code{max}) or smaller (@code{min}) of two integer or
double numbers, respectively.
@end deftypefun

@deftypefun double sign (double @var{x})
Compute the @emph{signum} function, where sign(@var{x}) is 1, 0, or
@math{-1}, when @var{x} is positive, 0, or negative, respectively.
@end deftypefun

@deftypefun double fsign (double @var{x}, double @var{y})
Performs ``transfer of sign'' and is defined as @eqn{|x| *
\hbox{sign}(y), |x| * sign(y)}.
@end deftypefun

@deftypefun double fprec (double @var{x}, double @var{digits})
Returns the value of @var{x} rounded to @var{digits} decimal digits
(after the decimal point).

This is the function used by @R{}'s @code{round()}.
@end deftypefun

@deftypefun double fround (double @var{x}, double @var{digits})
Returns the value of @var{x} rounded to @var{digits} @emph{significant}
decimal digits.

This is the function used by @R{}'s @code{signif()}.
@end deftypefun

@deftypefun double ftrunc (double @var{x})
Returns the value of @var{x} truncated (to an integer value) towards zero.
@end deftypefun

@node Mathematical constants,  , Numerical Utilities, Numerical analysis subroutines
@subsection Mathematical constants
@findex M_E
@findex M_PI
@c maybe not all into the index ...

@R{} has a set of commonly used mathematical constants encompassing
constants usually found @file{math.h} and contains further ones that are
used in statistical computations.  All these are defined to (at least)
30 digits accuracy in @file{Rmath.h}.  The following definitions
use @code{ln(x)} for the natural logarithm (@code{log(x)} in @R{}).

@quotation
@multitable {Name can be long}  {Definition (needs space)}  {0.123456789012345678 ...}
@headitem Name @tab Definition (@code{ln = log}) @tab round(@emph{value}, 7)
@c SVID & X/Open Constants -- names from Solaris math.h :
@item @code{M_E} @tab @math{e} @tab 2.7182818
@item @code{M_LOG2E} @tab log2(@math{e}) @tab 1.4426950
@item @code{M_LOG10E} @tab log10(@math{e}) @tab 0.4342945
@item @code{M_LN2} @tab ln(2) @tab 0.6931472
@item @code{M_LN10} @tab ln(10) @tab 2.3025851
@item @code{M_PI} @tab @eqn{\pi, pi}   @tab 3.1415927
@item @code{M_PI_2} @tab @eqn{\pi/2, pi/2} @tab 1.5707963
@item @code{M_PI_4} @tab @eqn{\pi/4, pi/4} @tab 0.7853982
@item @code{M_1_PI} @tab @eqn{1/\pi, 1/pi} @tab 0.3183099
@item @code{M_2_PI} @tab @eqn{2/\pi, 2/pi} @tab 0.6366198
@item @code{M_2_SQRTPI} @tab 2/sqrt(@eqn{\pi, pi}) @tab 1.1283792
@item @code{M_SQRT2} @tab sqrt(2) @tab 1.4142136
@item @code{M_SQRT1_2} @tab 1/sqrt(2) @tab 0.7071068
@c R-specific ones
@item @code{M_SQRT_3} @tab sqrt(3) @tab 1.7320508
@item @code{M_SQRT_32} @tab sqrt(32) @tab 5.6568542
@item @code{M_LOG10_2} @tab log10(2) @tab 0.3010300
@item @code{M_2PI} @tab @eqn{2\pi, 2*pi} @tab 6.2831853
@item @code{M_SQRT_PI} @tab sqrt(@eqn{\pi, pi}) @tab 1.7724539
@item @code{M_1_SQRT_2PI} @tab 1/sqrt(@eqn{2\pi, 2*pi}) @tab 0.3989423
@item @code{M_SQRT_2dPI} @tab sqrt(2/@eqn{\pi, pi}) @tab 0.7978846
@item @code{M_LN_SQRT_PI} @tab ln(sqrt(@eqn{\pi, pi})) @tab 0.5723649
@item @code{M_LN_SQRT_2PI} @tab ln(sqrt(@eqn{2\pi, 2*pi})) @tab 0.9189385
@item @code{M_LN_SQRT_PId2} @tab ln(sqrt(@eqn{\pi, pi}/2)) @tab 0.2257914
@end multitable
@end quotation

There are a set of constants (@code{PI}, @code{DOUBLE_EPS}) (and so on)
defined (unless @code{STRICT_R_HEADERS} is defined) in the included
header @file{R_ext/Constants.h}, mainly for compatibility with @Sl{}.

@findex TRUE
@findex FALSE
Further, the included header @file{R_ext/Boolean.h} has constants
@code{TRUE} and @code{FALSE = 0} of type @code{Rboolean} in order to
provide a way of using ``logical'' variables in C consistently.


@node Optimization, Integration, Numerical analysis subroutines, The R API
@section Optimization
@cindex optimization

The C code underlying @code{optim} can be accessed directly.  The user
needs to supply a function to compute the function to be minimized, of
the type

@example
typedef double optimfn(int n, double *par, void *ex);
@end example

@noindent
where the first argument is the number of parameters in the second
argument.  The third argument is a pointer passed down from the calling
routine, normally used to carry auxiliary information.

Some of the methods also require a gradient function

@example
typedef void optimgr(int n, double *par, double *gr, void *ex);
@end example

@noindent
which passes back the gradient in the @code{gr} argument.  No function
is provided for finite-differencing, nor for approximating the Hessian
at the result.

The interfaces (defined in header @file{R_ext/Applic.h}) are

@itemize @bullet
@item Nelder Mead:
@findex nmmin
@example
void nmmin(int n, double *xin, double *x, double *Fmin, optimfn fn,
           int *fail, double abstol, double intol, void *ex,
           double alpha, double beta, double gamma, int trace,
           int *fncount, int maxit);
@end example

@item BFGS:
@findex vmmin
@example
void vmmin(int n, double *x, double *Fmin,
           optimfn fn, optimgr gr, int maxit, int trace,
           int *mask, double abstol, double reltol, int nREPORT,
           void *ex, int *fncount, int *grcount, int *fail);
@end example

@item Conjugate gradients:
@findex cgmin
@example
void cgmin(int n, double *xin, double *x, double *Fmin,
           optimfn fn, optimgr gr, int *fail, double abstol,
           double intol, void *ex, int type, int trace,
           int *fncount, int *grcount, int maxit);
@end example

@item Limited-memory BFGS with bounds:
@findex lbfgsb
@example
void lbfgsb(int n, int lmm, double *x, double *lower,
            double *upper, int *nbd, double *Fmin, optimfn fn,
            optimgr gr, int *fail, void *ex, double factr,
            double pgtol, int *fncount, int *grcount,
            int maxit, char *msg, int trace, int nREPORT);
@end example

@item Simulated annealing:
@findex samin
@example
void samin(int n, double *x, double *Fmin, optimfn fn, int maxit,
           int tmax, double temp, int trace, void *ex);
@end example

@end itemize

@noindent
Many of the arguments are common to the various methods.  @code{n} is
the number of parameters, @code{x} or @code{xin} is the starting
parameters on entry and @code{x} the final parameters on exit, with
final value returned in @code{Fmin}.  Most of the other parameters can
be found from the help page for @code{optim}: see the source code
@file{src/appl/lbfgsb.c} for the values of @code{nbd}, which
specifies which bounds are to be used.


@node Integration, Utility functions, Optimization, The R API
@section Integration
@cindex integration

The C code underlying @code{integrate} can be accessed directly.  The
user needs to supply a @emph{vectorizing} C function to compute the
function to be integrated, of the type

@example
typedef void integr_fn(double *x, int n, void *ex);
@end example

@noindent
where @code{x[]} is both input and output and has length @code{n}, i.e.,
a C function, say @code{fn}, of type @code{integr_fn} must basically do
@code{for(i in 1:n) x[i] := f(x[i], ex)}.  The vectorization requirement
can be used to speed up the integrand instead of calling it @code{n}
times.  Note that in the current implementation built on QUADPACK,
@code{n} will be either 15 or 21.  The @code{ex} argument is a pointer
passed down from the calling routine, normally used to carry auxiliary
information.

There are interfaces (defined in header @file{R_ext/Applic.h}) for
definite and for indefinite integrals.  `Indefinite' means that at least
one of the integration boundaries is not finite.

@itemize @bullet
@item Finite:
@findex Rdqags
@example
void Rdqags(integr_fn f, void *ex, double *a, double *b,
            double *epsabs, double *epsrel,
            double *result, double *abserr, int *neval, int *ier,
            int *limit, int *lenw, int *last,
            int *iwork, double *work);
@end example

@item Indefinite:
@findex Rdqagi
@example
void Rdqagi(integr_fn f, void *ex, double *bound, int *inf,
            double *epsabs, double *epsrel,
            double *result, double *abserr, int *neval, int *ier,
            int *limit, int *lenw, int *last,
            int *iwork, double *work);
@end example

@end itemize

@noindent
Only the 3rd and 4th argument differ for the two integrators; for the
definite integral, using @code{Rdqags}, @code{a} and @code{b} are the
integration interval bounds, whereas for an indefinite integral, using
@code{Rdqagi}, @code{bound} is the finite bound of the integration (if
the integral is not doubly-infinite) and @code{inf} is a code indicating
the kind of integration range,

@table @code
@item inf = 1
      corresponds to (bound, +Inf),
@item inf = -1
      corresponds to (-Inf, bound),
@item inf = 2
      corresponds to (-Inf, +Inf),
@end table

@code{f} and @code{ex} define the integrand function, see above;
@code{epsabs} and @code{epsrel} specify the absolute and relative
accuracy requested, @code{result}, @code{abserr} and @code{last} are the
output components @code{value}, @code{abs.err} and @code{subdivisions}
of the @R{} function integrate, where @code{neval} gives the number of
integrand function evaluations, and the error code @code{ier} is
translated to @R{}'s @code{integrate() $ message}, look at that function
definition.  @code{limit} corresponds to @code{integrate(...,
subdivisions = *)}.  It seems you should always define the two work
arrays and the length of the second one as

@example
    lenw = 4 * limit;
    iwork =   (int *) R_alloc(limit, sizeof(int));
    work = (double *) R_alloc(lenw,  sizeof(double));
@end example

The comments in the source code in @file{src/appl/integrate.c} give
more details, particularly about reasons for failure (@code{ier >= 1}).


@node Utility functions, Re-encoding, Integration, The R API
@section Utility functions
@cindex Sort functions from C

@R{} has a fairly comprehensive set of sort routines which are made
available to users' C code.  These are declared in header file
@file{R_ext/Utils.h} (included by @file{R.h}) and include the following.

@deftypefun void R_isort (int* @var{x}, int @var{n})
@deftypefunx void R_rsort (double* @var{x}, int @var{n})
@deftypefunx void R_csort (Rcomplex* @var{x}, int @var{n})
@deftypefunx void rsort_with_index (double* @var{x}, int* @var{index}, int @var{n})
The first three sort integer, real (double) and complex data
respectively.  (Complex numbers are sorted by the real part first then
the imaginary part.)  @code{NA}s are sorted last.

@code{rsort_with_index} sorts on @var{x}, and applies the same
permutation to @var{index}.  @code{NA}s are sorted last.
@end deftypefun

@deftypefun void revsort (double* @var{x}, int* @var{index}, int @var{n})
Is similar to @code{rsort_with_index} but sorts into decreasing order,
and @code{NA}s are not handled.
@end deftypefun

@deftypefun void iPsort (int* @var{x}, int @var{n}, int @var{k})
@deftypefunx void rPsort (double* @var{x}, int @var{n}, int @var{k})
@deftypefunx void cPsort (Rcomplex* @var{x}, int @var{n}, int @var{k})
These all provide (very) partial sorting: they permute @var{x} so that
@code{@var{x}[@var{k}]} is in the correct place with smaller values to
the left, larger ones to the right.
@end deftypefun

@deftypefun  void R_qsort   (double *@var{v}, int @var{i}, int @var{j})
@deftypefunx void R_qsort_I (double *@var{v}, int *@var{I}, int @var{i}, int @var{j})
@deftypefunx void R_qsort_int   (int *@var{iv}, int @var{i}, int @var{j})
@deftypefunx void R_qsort_int_I (int *@var{iv}, int *@var{I}, int @var{i}, int @var{j})


These routines sort @code{@var{v}[@var{i}:@var{j}]} or
@code{@var{iv}[@var{i}:@var{j}]} (using 1-indexing, i.e.,
@code{@var{v}[1]} is the first element) calling the quicksort algorithm
as used by @R{}'s @code{sort(v, method = "quick")} and documented on the
help page for the @R{} function @code{sort}.  The @code{..._I()}
versions also return the @code{sort.index()} vector in @code{I}.  Note
that the ordering is @emph{not} stable, so tied values may be permuted.

Note that @code{NA}s are not handled (explicitly) and you should
use different sorting functions if @code{NA}s can be present.
@end deftypefun

@deftypefun subroutine qsort4 (double precision @var{v}, integer @var{indx}, integer @var{ii}, integer @var{jj})
@deftypefunx subroutine qsort3 (double precision @var{v}, integer @var{ii}, integer @var{jj})

The FORTRAN interface routines for sorting double precision vectors are
@code{qsort3} and @code{qsort4}, equivalent to @code{R_qsort} and
@code{R_qsort_I}, respectively.
@end deftypefun

@deftypefun void R_max_col (double* @var{matrix}, int* @var{nr}, int* @var{nc}, int* @var{maxes}, int* @var{ties_meth})
Given the @var{nr} by @var{nc} matrix @code{matrix} in column-major
(``FORTRAN'')
order, @code{R_max_col()} returns in @code{@var{maxes}[@var{i}-1]} the
column number of the maximal element in the @var{i}-th row (the same as
@R{}'s @code{max.col()} function).  In the case of ties (multiple maxima),
@code{*ties_meth} is an integer code in @code{1:3} determining the method:
1 = ``random'', 2 = ``first'' and 3 = ``last''.
See @R{}'s help page @code{?max.col}.
@end deftypefun

@deftypefun int findInterval (double* @var{xt}, int @var{n}, double @var{x}, Rboolean @var{rightmost_closed}, Rboolean @var{all_inside}, int @var{ilo}, int* @var{mflag})
Given the ordered vector @var{xt} of length @var{n}, return the interval
or index of @var{x} in @code{@var{xt}[]}, typically max(@math{i}; @eqn{1
\le i \le @var{n}, 1 <= i <= @var{n}} & @math{@var{xt}[i]} @eqn{\le, <=}
@var{x}) where we use 1-indexing as in @R{} and FORTRAN (but not C).  If
@var{rightmost_closed} is true, also returns @math{@var{n}-1} if @var{x}
equals @math{@var{xt}[@var{n}]}.  If @var{all_inside} is not 0, the
result is coerced to lie in @code{1:(@var{n}-1)} even when @var{x} is
outside the @var{xt}[] range.  On return, @code{*@var{mflag}} equals
@math{-1} if @var{x} < @var{xt}[1], @math{+1} if @var{x} >=
@var{xt}[@var{n}], and 0 otherwise.

The algorithm is particularly fast when @var{ilo} is set to the last
result of @code{findInterval()} and @var{x} is a value of a sequence which
is increasing or decreasing for subsequent calls.

There is also an @code{F77_CALL(interv)()} version of
@code{findInterval()} with the same arguments, but all pointers.
@end deftypefun

The following two functions do @emph{numerical} colorspace conversion from
HSV to RGB and back.  Note that all colours must be in [0,1].

@deftypefun void hsv2rgb (double @var{h}, double @var{s}, double @var{v}, double *@var{r}, double *@var{g}, double *@var{b})
@end deftypefun

@deftypefun void rgb2hsv (double @var{r}, double @var{g}, double @var{b}, double *@var{h}, double *@var{s}, double *@var{v})
@end deftypefun

A system-independent interface to produce the name of a temporary
file is provided as

@deftypefun {char *} R_tmpnam (const char *@var{prefix})
Return a pathname for a temporary file with name beginning with
@var{prefix}.  A @code{NULL} prefix is replaced by @code{""}.
@end deftypefun

@c ----

There is also the internal function used to expand file names in several
@R{} functions, and called directly by @code{path.expand}.

@deftypefun {const char *} R_ExpandFileName (const char *@var{fn})
Expand a path name @var{fn} by replacing a leading tilde by the user's
home directory (if defined).  The precise meaning is platform-specific;
it will usually be taken from the environment variable @env{HOME} if
this is defined.
@end deftypefun

@node Re-encoding, Allowing interrupts, Utility functions, The R API
@section Re-encoding

@R{} has its own C-level interface to the encoding conversion
capabilities provided by @code{iconv}, for the following reasons

@itemize @bullet
@item
These wrapper routines do error-handling when no usable implementation
of @code{iconv} was available at configure time.

@item
Under Windows they arrange to load the @file{iconv.dll} at first use.

@item
There are incompatibilities between the declarations in different
implementations of @code{iconv}.

@end itemize

These are declared in header file @file{R_ext/Riconv.h}.

@deftypefun void *Riconv_open (const char *@var{to}, const char *@var{from})
@end deftypefun
Set up a pointer to an encoding object to be used to convert between two
encodings: @code{""} indicates the current locale.

@deftypefun size_t Riconv (void *@var{cd}, const char **@var{inbuf}, size_t *@var{inbytesleft}, char  **@var{outbuf}, size_t *@var{outbytesleft})
@end deftypefun
Convert as much as possible of @code{inbuf} to @code{outbuf}.  Initially
the @code{int} variables indicate the number of bytes available in the
buffers, and they are updated (and the @code{char} pointers are updated
to point to the next free byte in the buffer).  The return value is the
number of characters converted, or @code{(size_t)-1} (beware:
@code{size_t} is usually an unsigned type).  It should be safe to assume
that an error condition sets @code{errno} to one of @code{E2BIG} (the
output buffer is full), @code{EILSEQ} (the input cannot be converted,
and might be invalid in the encoding specified) or @code{EINVAL} (the
input does not end with a complete multi-byte character).

@deftypefun int Riconv_close (void * @var{cd})
@end deftypefun
Free the resources of an encoding object.


@node Allowing interrupts, Platform and version information, Re-encoding, The R API
@section Allowing interrupts
@cindex Interrupts

No port of @R{} can be interrupted whilst running long computations in
compiled code, so programmers should make provision for the code to be
interrupted at suitable points by calling from C

@example
#include <R_ext/Utils.h>

void R_CheckUserInterrupt(void);
@end example

@noindent
and from FORTRAN

@example
subroutine rchkusr()
@end example

These check if the user has requested an interrupt, and if so branch to
@R{}'s error handling functions.

Note that it is possible that the code behind one of the entry points
defined here if called from your C or FORTRAN code could be interruptible
or generate an error and so not return to your code.


@node Platform and version information, Inlining C functions, Allowing interrupts, The R API
@section Platform and version information
@cindex Version information from C
@findex R_Version

The header files define @code{USING_R}, which should be used to test if
the code is indeed being used with @R{}.

Header file @file{Rconfig.h} (included by @file{R.h}) is used to define
platform-specific macros that are mainly for use in other header files.
The macro @code{WORDS_BIGENDIAN} is defined on big-endian systems
(e.g.@: @code{sparc-sun-solaris2.6}) and not on little-endian systems
(such as @code{i686} under Linux or Windows). It can be useful when
manipulating binary files.

Header file @file{Rversion.h} (@strong{not} included by @file{R.h})
defines a macro @code{R_VERSION} giving the version number encoded as an
integer, plus a macro @code{R_Version} to do the encoding.  This can be
used to test if the version of @R{} is late enough, or to include
back-compatibility features.  For protection against earlier versions of
@R{} which did not have this macro, use a construction such as

@example
@group
#if defined(R_VERSION) && R_VERSION >= R_Version(1, 9, 0)
  ...
#endif
@end group
@end example

More detailed information is available in the macros @code{R_MAJOR},
@code{R_MINOR}, @code{R_YEAR}, @code{R_MONTH} and @code{R_DAY}: see the
header file @file{Rversion.h} for their format.  Note that the minor
version includes the patchlevel (as in @samp{9.0}).

@node Inlining C functions, Standalone Mathlib, Platform and version information, The R API
@section Inlining C functions
@findex R_INLINE

The C99 keyword @code{inline} is recognized by some compilers used to
build @R{} whereas others need @code{__inline__} or do not support
inlining.  Portable code can be written using the macro @code{R_INLINE}
(defined in file @file{Rconfig.h} included by @file{R.h}), as for
example from package @pkg{cluster}

@example
#include <R.h>

static R_INLINE int ind_2(int l, int j)
@{
...
@}
@end example

Be aware that using inlining with functions in more than one compilation
unit is almost impossible to do portably: see
@url{http://www.greenend.org.uk/rjk/2003/03/inline.html}.  All the @R{}
configure code has checked is that  @code{R_INLINE} can be used in a
single C file with the compiler used to build @R{}.  We recommend that
packages making extensive use of inlining include their own configure code.

@node Standalone Mathlib, Organization of header files, Inlining C functions, The R API
@section Using these functions in your own C code

It is possible to build @code{Mathlib}, the @R{} set of mathematical
functions documented in @file{Rmath.h}, as a standalone library
@file{libRmath} under both Unix and Windows.  (This includes the
functions documented in @ref{Numerical analysis subroutines} as from
that header file.)

The library is not built automatically when @R{} is installed, but can
be built in the directory @file{src/nmath/standalone} in the @R{}
sources: see the file @file{README} there.  To use the code in your own
C program include

@example
@group
#define MATHLIB_STANDALONE
#include <Rmath.h>
@end group
@end example

@noindent
and link against @samp{-lRmath} (and perhaps @samp{-lm}.  There is an
example file @file{test.c}.

A little care is needed to use the random-number routines. You will
need to supply the uniform random number generator

@example
double unif_rand(void)
@end example

@noindent
or use the one supplied (and with a dynamic library or DLL you will have
to use the one supplied, which is the Marsaglia-multicarry with an entry
points

@example
set_seed(unsigned int, unsigned int)
@end example

@noindent
to set its seeds and

@example
get_seed(unsigned int *, unsigned int *)
@end example

@noindent
to read the seeds).

@node Organization of header files,  , Standalone Mathlib, The R API
@section Organization of header files

The header files which @R{} installs are in directory
@file{@var{R_INCLUDE_DIR}} (default @file{@var{R_HOME}/include}).  This
currently contains

@quotation
@multitable @columnfractions 0.30 0.55
@item @file{R.h} @tab includes many other files
@item @file{S.h} @tab different version for code ported from @Sl{}
@item @file{Rinternals.h} @tab definitions for using @R{}'s internal
structures
@item @file{Rdefines.h} @tab macros for an @Sl{}-like interface to the
above
@item @file{Rmath.h} @tab standalone math library
@item @file{Rversion.h} @tab @R{} version information
@item @file{Rinterface.h} @tab for add-on front-ends (Unix-alikes only)
@item @file{R_ext/RStartup.h} @tab ditto
@item @file{R_ext/eventloop.h} @tab for add-on front-ends and for packages that need to
share in the @R{} event loops (on all platforms)
@item @file{R_ext/Applic.h} @tab optimization and integration
@item @file{R_ext/BLAS.h} @tab C definitions for BLAS routines
@item @file{R_ext/Lapack.h} @tab C definitions for some LAPACK routines
@item @file{R_ext/Linpack.h} @tab C definitions for some LINPACK
routines, not all of which are included in @R{}
@item @file{R_ext/GetX11Image.h} @tab X11Image interface used by package
@pkg{trkplot}
@item @file{R_ext/Parse.h} @tab a small part of @R{}'s parse interface
@item @file{R_ext/Callbacks.h} @tab C (and R function) top-level task
handlers
@item @file{R_ext/RConvertors.h}
@item @file{R_ext/Rdynload.h} @tab needed to register compiled code in
packages
@item @file{R_ext/R-ftp-http.h} @tab interface to internal method of
@code{download.file}
@item @file{R_ext/Riconv.h} @tab interface to @code{iconv}
@end multitable
@end quotation

The following headers are included by @file{R.h}:

@quotation
@multitable @columnfractions 0.30 0.55
@item @file{Rconfig.h} @tab configuration info that is made available
@item @file{R_ext/Arith.h} @tab handling for @code{NA}s, @code{NaN}s,
@code{Inf}/@code{-Inf}
@item @file{R_ext/Boolean.h} @tab @code{TRUE}/@code{FALSE} type
@item @file{R_ext/Complex.h} @tab C typedefs for @R{}'s @code{complex}
@item @file{R_ext/Constants.h} @tab constants
@item @file{R_ext/Error.h} @tab error handling
@item @file{R_ext/Memory.h} @tab memory allocation
@item @file{R_ext/Print.h} @tab @code{Rprintf} and variations.
@item @file{R_ext/Random.h} @tab random number generation
@item @file{R_ext/RS.h} @tab definitions common to @file{R.h} and
@file{S.h}, including @code{F77_CALL} etc.
@item @file{R_ext/Utils.h} @tab sorting and other utilities
@item @file{R_ext/libextern.h} @tab definitions for exports from
@file{R.dll} on Windows.
@end multitable
@end quotation

The graphics systems are exposed in headers @file{Rdevices.h} (for
writing graphics devices), @file{Rgraphics.h} and
@file{R_ext/Graphics@{Base,Device,Engine@}.h}.


@node Generic functions and methods, Linking GUIs and other front-ends to R, The R API, Top
@chapter Generic functions and methods
@cindex Generic functions
@cindex Method functions

@R{} programmers will often want to add methods for existing generic
functions, and may want to add new generic functions or make existing
functions generic.  In this chapter we give guidelines for doing so,
with examples of the problems caused by not adhering to them.

This chapter only covers the `informal' class system copied from S3,
and not with the S4 (formal) methods of package @pkg{methods}.

The key function for methods is @code{NextMethod}, which dispatches the
next method.  It is quite typical for a method function to make a few
changes to its arguments, dispatch to the next method, receive the
results and modify them a little.  An example is

@example
@group
t.data.frame <- function(x)
@{
    x <- as.matrix(x)
    NextMethod("t")
@}
@end group
@end example

@noindent
Also consider @code{predict.glm}: it happens that in @R{} for historical
reasons it calls @code{predict.lm} directly, but in principle (and in S
originally and currently) it could use @code{NextMethod}.
(@code{NextMethod} seems under-used in the @R{} sources.  Do be aware
that there as S/R differences in this area, and the example above works
because there is a @emph{next} method, the default method, not that a
new method is selected when the class is changed.)

@emph{Any} method a programmer writes may be invoked from another method
by @code{NextMethod}, @emph{with the arguments appropriate to the
previous method}.  Further, the programmer cannot predict which method
@code{NextMethod} will pick (it might be one not yet dreamt of), and the
end user calling the generic needs to be able to pass arguments to the
next method.  For this to work

@quotation
@emph{A method must have all the arguments of the generic, including
@code{@dots{}} if the generic does.}
@end quotation

It is a grave misunderstanding to think that a method needs only to
accept the arguments it needs.  The original S version of
@code{predict.lm} did not have a @code{@dots{}} argument, although
@code{predict} did.  It soon became clear that @code{predict.glm} needed
an argument @code{dispersion} to handle over-dispersion.  As
@code{predict.lm} had neither a @code{dispersion} nor a @code{@dots{}}
argument, @code{NextMethod} could no longer be used.  (The legacy, two
direct calls to @code{predict.lm}, lives on in @code{predict.glm} in
@R{}, which is based on the workaround for S3 written by Venables &
Ripley.)

Further, the user is entitled to use positional matching when calling
the generic, and the arguments to a method called by @code{UseMethod}
are those of the call to the generic.  Thus

@quotation
@emph{A method must have arguments in exactly the same order as the
generic.}
@end quotation

@noindent
To see the scale of this problem, consider the generic function
@code{scale}, defined as

@example
@group
scale <- function (x, center = TRUE, scale = TRUE)
    UseMethod("scale")
@end group
@end example

@noindent
Suppose an unthinking package writer created methods such as

@example
scale.foo <- function(x, scale = FALSE, ...) @{ @}
@end example

@noindent
Then for @code{x} of class @code{"foo"} the calls

@example
@group
scale(x, , TRUE)
scale(x, scale = TRUE)
@end group
@end example

@noindent
would do most likely do different things, to the justifiable
consternation of the end user.

To add a further twist, which default is used when a user calls
@code{scale(x)} in our example?  What if

@example
scale.bar <- function(x, center, scale = TRUE) NextMethod("scale")
@end example

@noindent
and @code{x} has class @code{c("bar", "foo")}?  We are not going to give
you the answers because it is unreasonable that a user should be
expected to anticipate such behaviour.  This leads to the
recommendation:

@quotation
@emph{A method should use the same defaults as the generic.}
@end quotation

@noindent
Here there might be justifiable exceptions, which will need careful
documentation.

@menu
* Adding new generics::         
@end menu

@node Adding new generics,  , Generic functions and methods, Generic functions and methods
@section Adding new generics

When creating a new generic function, bear in mind that its argument
list will be the maximal set of arguments for methods, including those
written elsewhere years later.  So choosing a good set of arguments may
well be an important design issue, and there need to be good arguments
@emph{not} to include a @code{@dots{}} argument.

If a @code{@dots{}} argument is supplied, some thought should be given
to its position in the argument sequence.  Arguments which follow
@code{@dots{}} must be named in calls to the function, and they must be
named in full (partial matching is suppressed after @code{@dots{}}).
Formal arguments before @code{@dots{}} can be partially matched, and so
may `swallow' actual arguments intended for @code{@dots{}}.  Although it
is commonplace to make the @code{@dots{}} argument the last one, that is
not always the right choice.

Sometimes package writers want to make generic a function in the base
package, and request a change in @R{}.  This may be justifiable, but
making a function generic with the old definition as the default method
does have a small performance cost.  It is never necessary, as a package
can take over a function in the base package and make it generic by

@example
@group
foo <- function(object, ...) UseMethod("foo")
foo.default <- base::foo
@end group
@end example

@noindent
(If the thus defined default method needs a @samp{...} added to its
argument list, one can e.g.@: use @code{formals(foo.default) <-
c(formals(foo.default), alist(... = ))}.)

The same idea can be applied for functions in other packages with name spaces.

@node Linking GUIs and other front-ends to R, Function and variable index, Generic functions and methods, Top
@chapter Linking GUIs and other front-ends to R

There are a number of ways to build front-ends to @R{}: we take this to
mean a GUI or other application that has the ability to submit commands
to @R{} and perhaps to receive results back (not necessarily in a text
format).  There are other routes besides those described here, for
example @samp{Rserve} (see @url{http://www.rosuda.org/Rserve}) and
connections to Java in @samp{SJava} (see
@url{http://www.omegahat.org/RSJava/} and @samp{JRI}, part of the
@pkg{rJava} package on CRAN).

@menu
* Embedding R under Unix-alikes::  
* Embedding R under Windows::   
@end menu

@node Embedding R under Unix-alikes, Embedding R under Windows, Linking GUIs and other front-ends to R, Linking GUIs and other front-ends to R
@section Embedding R under Unix-alikes

@R{} can be built as a shared library@footnote{In the parlance of MacOS
X this is a @emph{dynamic} library, and is the normal way to build @R{} on
that platform.} if configured with @option{--enable-R-shlib}.  This
shared library can be used to run @R{} from alternative front-end
programs.  We will assume this has been done for the rest of this
section.

The command-line @R{} front-end, @file{@var{R_HOME}/bin/exec/R} is one
such example, and the unbundled @acronym{GNOME} and MacOS X consoles are
others.  The source for @file{@var{R_HOME}/bin/exec/R} is in file
@file{src/main/Rmain.c} and is very simple

@example
int Rf_initialize_R(int ac, char **av); /* in ../unix/system.c */
void Rf_mainloop();                     /* in main.c */

extern int R_running_as_main_program;   /* in ../unix/system.c */

int main(int ac, char **av)
@{
    R_running_as_main_program = 1;
    Rf_initialize_R(ac, av);
    Rf_mainloop(); /* does not return */
    return 0;
@}
@end example

@noindent
indeed, misleadingly simple.  Remember that
@file{@var{R_HOME}/bin/exec/R} is run from a shell script
@file{@var{R_HOME}/bin/R} which sets up the environment for the
executable, and this is used for

@itemize @bullet
@item
Setting @env{R_HOME} and checking it is valid, as well as the path
@env{R_SHARE_DIR} and @env{R_DOC_DIR} to the installed @file{share} and
@file{doc} directory trees.  Also setting @env{R_ARCH} if needed.

@item
Setting @env{LD_LIBRARY_PATH} to include the directories used in linking
@R{}.  This is recorded as the default setting of
@env{R_LD_LIBRARY_PATH} in the shell script.

@item
Processing some of the arguments, for example to run @R{} under a
debugger and to launch alternative front-ends to provide GUIs.
@end itemize

@noindent
The first two of these can be achieved for your front-end by running it
@emph{via} @command{R CMD}. So, for example

@example
R CMD /usr/local/lib/R/bin/exec/R
R CMD exec/R
@end example

@noindent
will both work in a standard @R{} installation. (@command{R CMD} looks
first for executables in @file{@var{R_HOME}/bin}.)  If you do not want
to run your front-end in this way, you need to ensure that @env{R_HOME}
is set and @env{LD_LIBRARY_PATH} is suitable.  (The latter might well
be, but modern Unix/Linux systems do not normally include
@file{/usr/local/lib}, and @R{} does look there for system components.)

The other senses in which this example is too simple are that all the
internal defaults are used and that control is handed over to the
@R{} main loop.  There are a number of small examples@footnote{but these
are not part of the automated test procedures and so little tested.} in the
@file{tests/Embedding} directory.  These make use of
@code{Rf_initEmbeddedR} in @file{src/main/Rembedded.c}, and essentially
use
@example
#include <Rembedded.h>

int main(int ac, char **av)
@{
    /* do some setup */
    Rf_initEmbeddedR(argc, argv);
    /* do some more setup */

    /* submit some code to R, which is done interactively via
        run_Rmainloop();

        A possible substitute for a pseudo-console is

        R_ReplDLLinit();
        while(R_ReplDLLdo1() > 0) @{
        /* add user actions here if desired */
       @}
        
     */
    Rf_endEmbeddedR(0);
    /* final tidying up after R is shutdown */
    return 0;
@}
@end example

@noindent
If you don't want to pass @R{} arguments, you can fake an @code{argv}
array, for example by

@example
    char *argv[]= @{"REmbeddedPostgres", "--silent"@};
    Rf_initEmbeddedR(sizeof(argv)/sizeof(argv[0]), argv);
@end example

However, to make a GUI we usually do want to run @code{run_Rmainloop}
after setting up various parts of @R{} to talk to our GUI, and arranging
for our GUI callbacks to be called during the @R{} mainloop.

One issue to watch is that on some platforms @code{Rf_initEmbeddedR} and
@code{Rf_endEmbeddedR} change the settings of the FPU (e.g.@: to allow
errors to be trapped and to set extended precision registers).

The standard code sets up a session temporary directory in the usual
way, @emph{unless} @code{R_TempDir} is set to a non-NULL value before
@code{Rf_initEmbeddedR} is called.  In that case the value is assumed to
contain an existing writable directory (no check is done), and it is not
cleaned up when @R{} is shut down.

@code{Rf_initEmbeddedR} sets @R{} to be in interactive mode: you can set
@code{R_Interactive} (defined in @file{Rinterface.h}) subsequently to
change this.

@menu
* Compiling against the R shared library::  
* Setting R callbacks::         
* Registering symbols::         
* Meshing event loops::         
* Threading issues::            
@end menu

@node Compiling against the R shared library, Setting R callbacks, Embedding R under Unix-alikes, Embedding R under Unix-alikes
@subsection Compiling against the R shared library

Suitable flags to compile and link against the @R{} shared library
can be found by

@example
R CMD config --cppflags
R CMD config --ldflags
@end example

If @R{} is installed, @code{pkg-config} is available and
sub-architectures have not be used, alternatives are

@example
pkg-config --cflags libR
pkg-config --libs libR
@end example



@node Setting R callbacks, Registering symbols, Compiling against the R shared library, Embedding R under Unix-alikes
@subsection Setting R callbacks

For Unix-alkes there is a public header file @file{Rinterface.h} that
makes it possible to change the standard callbacks used by @R{} in a
documented way.  This defines pointers (if @code{R_INTERFACE_PTRS} is
defined)

@example
extern void (*ptr_R_Suicide)(char *);
extern void (*ptr_R_ShowMessage)(char *);
extern int  (*ptr_R_ReadConsole)(char *, unsigned char *, int, int);
extern void (*ptr_R_WriteConsole)(char *, int);
extern void (*ptr_R_WriteConsoleEx)(char *, int, int);
extern void (*ptr_R_ResetConsole)();
extern void (*ptr_R_FlushConsole)();
extern void (*ptr_R_ClearerrConsole)();
extern void (*ptr_R_Busy)(int);
extern void (*ptr_R_CleanUp)(SA_TYPE, int, int);
extern int  (*ptr_R_ShowFiles)(int, char **, char **, char *,
                               Rboolean, char *);
extern int  (*ptr_R_ChooseFile)(int, char *, int);
extern int  (*ptr_R_EditFile)(char *);
extern void (*ptr_R_loadhistory)(SEXP, SEXP, SEXP, SEXP);
extern void (*ptr_R_savehistory)(SEXP, SEXP, SEXP, SEXP);
extern void (*ptr_R_addhistory)(SEXP, SEXP, SEXP, SEXP);
@end example

@noindent
which allow standard @R{} callbacks to be redirected to your GUI.  What
these do is generally documented in the file @file{src/unix/system.txt}.

@deftypefun void R_ShowMessage (char *@var{message})
This should display the message, which may have multiple lines:  it
should be brought to the user's attention immediately.
@end deftypefun

@deftypefun void R_Busy (int @var{which})
This function invokes actions (such as change of cursor) when @R{}
embarks on an extended computation (@code{@var{which}=1}) and when such
a state terminates (@code{@var{which}=0}).
@end deftypefun

@deftypefun int R_ReadConsole (char *@var{prompt}, unsigned char *@var{buf}, @
  int @var{buflen}, int @var{hist})
@deftypefunx void R_WriteConsole (char *@var{buf}, int @var{buflen})
@deftypefunx void R_WriteConsoleEx (char *@var{buf}, int @var{buflen}, int @var{otype})
@deftypefunx void R_ResetConsole ()
@deftypefunx void R_FlushConsole ()
@deftypefunx void R_ClearErrConsole ()

These functions interact with a console.

@code{R_ReadConsole} prints the given prompt at the console and then
does a @code{gets(3)}--like operation, transferring up to @var{buflen}
characters into the buffer @var{buf}. The last two bytes should be
set to @samp{"\n\0"} to preserve sanity.  If @var{hist} is non-zero,
then the line should be added to any command history which is being
maintained.  The return value is 0 is no input is available and >0
otherwise.

@code{R_WriteConsoleEx} writes the given buffer to the console,
@var{otype} specifies the output type (regular output or
warning/error). Call to @code{R_WriteConsole(buf, buflen)} is equivalent
to @code{R_WriteConsoleEx(buf, buflen, 0)}. To ensure backward
compatibility of the callbacks, @code{ptr_R_WriteConsoleEx} is used only
if @code{ptr_R_WriteConsole} is set to @code{NULL}.  To ensure that
@code{stdout()} and @code{stderr()} connections point to the console,
set the corresponding files to @code{NULL} @emph{via}
@example
      R_Outputfile = NULL;
      R_Consolefile = NULL;
@end example

@code{R_ResetConsole} is called when the system is reset after an error.
@code{R_FlushConsole} is called to flush any pending output to the
system console.  @code{R_ClearerrConsole} clears any errors associated
with reading from the console.
@end deftypefun

@deftypefun int R_ShowFiles (int @var{nfile}, char **@var{file}, @
  char **@var{headers}, char *@var{wtitle}, Rboolean @var{del}, @
  char *@var{pager})

This function is used to display the contents of files.
@end deftypefun

@deftypefun int R_ChooseFile (int @var{new}, char *@var{buf}, @
  int @var{len})

Choose a file and return its name in @var{buf} of length @var{len}.
Return value is 0 for success, > 0 otherwise.
@end deftypefun

@deftypefun int R_EditFile (char *@var{buf})
Send a file to an editor window.
@end deftypefun

@deftypefun SEXP R_loadhistory (SEXP, SEXP, SEXP, SEXP);
@deftypefunx SEXP R_savehistory (SEXP, SEXP, SEXP, SEXP);
@deftypefunx SEXP R_addhistory (SEXP, SEXP, SEXP, SEXP);

@code{.Internal} functions for @code{loadhistory}, @code{savehistory}
and @code{timestamp}: these are called after checking the number of
arguments.

If the console has no history mechanism these can be as
simple as

@example
SEXP R_loadhistory (SEXP call, SEXP op, SEXP args, SEXP env)
@{
    errorcall(call, "loadhistory is not implemented");
    return R_NilValue;
@}
SEXP R_savehistory (SEXP call, SEXP op , SEXP args, SEXP env)
@{
    errorcall(call, "savehistory is not implemented");
    return R_NilValue;
@}
SEXP R_addhistory (SEXP call, SEXP op , SEXP args, SEXP env)
@{
    return R_NilValue;
@}
@end example

The @code{R_addhistory} function should return silently if no history
mechanism is present, as a user may be calling @code{timestamp} purely
to write the time stamp to the console.
@end deftypefun

@deftypefun void R_Suicide (char *@var{message})
This should abort @R{} as rapidly as possible, displaying the message.
A possible implementation is

@example
void R_Suicide (char *message)
@{
    char  pp[1024];
    snprintf(pp, 1024, "Fatal error: %s\n", s);
    R_ShowMessage(pp);
    R_CleanUp(SA_SUICIDE, 2, 0);
@}
@end example
@end deftypefun

@deftypefun void R_CleanUp (SA_TYPE @var{saveact}, int @var{status}, @
  int @var{RunLast})

This function invokes any actions which occur at system termination.
It needs to be quite complex:

@example
#include <Rinterface.h>
#include <Rdevices.h>    /* for KillAllDevices */

void R_CleanUp (SA_TYPE saveact, int status, int RunLast)
@{
    if(saveact == SA_DEFAULT) saveact = SaveAction;
    if(saveact == SA_SAVEASK) @{
       /* ask what to do and set saveact */
    @}
    switch (saveact) @{
    case SA_SAVE:
        if(runLast) R_dot_Last();
        if(R_DirtyImage) R_SaveGlobalEnv();
        /* save the console history in R_HistoryFile */
        break;
    case SA_NOSAVE:
        if(runLast) R_dot_Last();
        break;
    case SA_SUICIDE:
    default:
        break;
    @}

    R_RunExitFinalizers();
    /* clean up after the editor e.g. CleanEd() */

    R_CleanTempDir();

    /* close all the graphics devices */
    if(saveact != SA_SUICIDE) KillAllDevices();
    fpu_setup(FALSE);

    exit(status);
@}
@end example
@end deftypefun

@node Registering symbols, Meshing event loops, Setting R callbacks, Embedding R under Unix-alikes
@subsection Registering symbols

An application embedding @R{} needs a different way of registering
symbols because it is not a dynamic library loaded by @R{} as would be
the case with a package.  Therefore @R{} reserves a special
@code{DllInfo} entry for the embedding application such that it can
register symbols to be used with @code{.C}, @code{.Call} etc.  This
entry can be obtained by calling @code{getEmbeddingDllInfo}, so a
typical use is

@example
DllInfo *info = R_getEmbeddingDllInfo();
R_registerRoutines(info, cMethods, callMethods, NULL, NULL);
@end example

The native routines defined by @code{cMethod} and @code{callMethods}
should be present in the embedding application.  See @ref{Registering
native routines} for details on registering symbols in general.


@node Meshing event loops, Threading issues, Registering symbols, Embedding R under Unix-alikes
@subsection Meshing event loops

One of the most difficult issues in interfacing @R{} to a front-end is
the handling of event loops, at least if a single thread is used.  @R{}
uses events and timers for

@itemize
@item
Running X11 windows such as the graphics device and data editor, and
interacting with them (e.g., using @code{locator()}).

@item
Supporting Tcl/Tk events for the @pkg{tcltk} package.

@item
Preparing input.

@item
Timing operations, for example for profiling @R{} code and
@code{Sys.sleep()}.

@item
Interrupts, where permitted.
@end itemize

@noindent
Specifically, the Unix command-line version of @R{} runs separate event
loops for

@itemize
@item
Preparing input at the console command-line, in file
@file{src/unix/sys-unix.c}.

@item
Waiting for a response from a socket in the internal functions
underlying FTP and HTTP transfers in @code{download.file()} and for
direct socket access, in files
@file{src/@/modules/@/internet/@/nanoftp.c},
@file{src/@/modules/@/internet/@/nanohttp.c} and
@file{src/@/modules/@/internet/@/Rsock.c}

@item
Mouse and window events when displaying the X11-based dataentry window,
in file @file{src/modules/X11/dataentry.c}.  This is regarded as
@emph{modal}, and no other events are serviced whilst it is active.
@end itemize

There is a protocol for adding event handlers to the first two types of
event loops, using types and functions declared in the header
@file{R_ext/eventloop.h} and described in comments in file
@file{src/unix/sys-std.c}.  It is possible to add (or remove) an input
handler for events on a particular file descriptor, or to set a polling
interval (@emph{via} @code{R_wait_usec}) and a function to be called
periodically via @code{R_PolledEvents}: the polling mechanism is used by
the @pkg{tcltk} package.

An alternative front-end needs both to make provision for other @R{}
events whilst waiting for input, and to ensure that it is not frozen out
during events of the second type.  This is not handled very well in the
existing examples.  The GNOME front-end can run a own handler for polled
events by setting

@example
extern int (*R_timeout_handler)();
extern long R_timeout_val;

      if (R_timeout_handler && R_timeout_val)
          gtk_timeout_add(R_timeout_val, R_timeout_handler, NULL);
      gtk_main ();
@end example

@noindent
whilst it is waiting for console input.  This obviously handles events
for Gtk windows (such as the graphics device in the @pkg{gtkDevice}
package), but not X11 events (such as the @code{X11()} device) or for
other event handlers that might have been registered with @R{}.  It does
not attempt to keep itself alive whilst @R{} is waiting on sockets.  The
ability to add a polled handler as @code{R_timeout_handler} is used by
the @pkg{tcltk} package.


@node Threading issues,  , Meshing event loops, Embedding R under Unix-alikes
@subsection Threading issues

Embedded @R{} is designed to be run in the main thread, and all the
testing is done in that context.  There is a potential issue with the
stack-checking mechanism where threads are involved.  This uses two
variables declared in @file{Rinterface.h} (if @code{CSTACK_DEFNS} is
defined) as

@example
extern uintptr_t R_CStackLimit; /* C stack limit */
extern uintptr_t R_CStackStart; /* Initial stack address */
@end example

@noindent
Note that @code{uintptr_t} is a C99 type for which a substitute is
defined in @R{}, so your code needs to define @code{HAVE_UINTPTR_T}
appropriately.

These will be set@footnote{at least on platforms where the values are
available, that is having @code{getrlimit} and on Linux or having
@code{sysctl} supporting @code{KERN_USRSTACK}, including FreeBSD and
MacOS X.} when @code{R_initialize_R} is called, to values appropriate to
the main thread.  Stack-checking can be disabled by seting
@code{R_CStackLimit = (uintptr_t)-1}, but it is better to if possible
set appropriate values.  (What these are and how to determine them are
OS-specific, and the stack size limit may differ for secondary threads.
If you have a choice of stack size, at least 8Mb is recommended.)

You may also want to consider how signals are handled: @R{} sets signal
handlers for several signals, including @code{SIGINT}, @code{SIGSEGV},
@code{SIGPIPE}, @code{SIGUSR1} and @code{SIGUSR2}, but these can all be
suppressed by setting the variable @code{R_SignalHandlers} (declared in
@file{Rinterface.h}) to @code{0}.


@node Embedding R under Windows,  , Embedding R under Unix-alikes, Linking GUIs and other front-ends to R
@section Embedding R under Windows

All Windows interfaces to @R{} call entry points in the DLL
@file{R.dll}, directly or indirectly.  Simpler applications may find it
easier to use the indirect route via @acronym{(D)COM}.

@menu
* Using (D)COM::                
* Calling R.dll directly::      
@end menu

@node Using (D)COM, Calling R.dll directly, Embedding R under Windows, Embedding R under Windows
@subsection Using (D)COM

@acronym{(D)COM} is a standard Windows mechanism used for communication
between Windows applications.  One application (here @R{}) is run as COM
server which offers services to clients, here the front-end calling
application.  The services are described in a `Type Library' and are
(more or less) language-independent, so the calling application can be
written in C or C++ or Visual Basic or Perl or Python and so on.
The `D' in (D)COM refers to `distributed', as the client and server can
be running on different machines.

The basic @R{} distribution is not a (D)COM server, but two addons are
currently available that interface directly with @R{} and provide a
(D)COM server:
@itemize
@item
There is a (D)COM server called @code{StatConnector} written by Thomas
Baier available on CRAN
(@url{http://@/cran.r-project.org/@/other-software.html}) which works
with @file{Rproxy.dll} (in the @R{} distribution) and @file{R.dll} to
support transfer of data to and from @R{} and remote execution of R
commands, as well as embedding of an @R{} graphics window.  The @pkg{rcom}
package on CRAN provides a (D)COM server in a running @R{} session.

@item
Another (D)COM server, @code{RDCOMServer}, is available from
@url{http://www.omegahat.org/}. Its philosophy is discussed in
@url{http://www.omegahat.org/RDCOMServer/Docs/Paradigm.html} and is
very different from the purpose of this section.
@end itemize
@node Calling R.dll directly,  , Using (D)COM, Embedding R under Windows
@subsection Calling R.dll directly

The @code{R} DLL is mainly written in C and has @code{_cdecl} entry
points.  Calling it directly will be tricky except from C code (or C++
with a little care).

There is a version of the Unix interface callng 

@example
int Rf_initEmbeddedR(int ac, char **av);
void Rf_endEmbeddedR(int fatal);
@end example

@noindent
which is an entry point in @file{R.dll}.  Examples of its use (and a
suitable @file{Makefile.win}) can be found in the @file{tests/Embedding}
directory of the sources.  You may need to ensure that
@file{@var{R_HOME}/bin} is in your @env{PATH} so the @R{} DLLs are found.

Examples of calling @file{R.dll} directly are provided in the directory
@file{src/@/gnuwin32/@/front-ends}, including @file{Rproxy.dll} used by
@code{StatConnector} and a simple command-line front end @file{rtest.c}
whose code is

@smallexample
#define Win32
#include <windows.h>
#include <stdio.h>
#include <Rversion.h>
#define LibExtern __declspec(dllimport) extern
#include <Rembedded.h>
#include <R_ext/RStartup.h>
/* for askok and askyesnocancel */
#include <graphapp/graphapp.h>

/* for signal-handling code */
#include <psignal.h>

/* simple input, simple output */

/* This version blocks all events: a real one needs to call ProcessEvents
   frequently. See rterm.c and ../system.c for one approach using
   a separate thread for input.
*/
int myReadConsole(char *prompt, char *buf, int len, int addtohistory)
@{
    fputs(prompt, stdout);
    fflush(stdout);
    if(fgets(buf, len, stdin)) return 1; else return 0;
@}

void myWriteConsole(char *buf, int len)
@{
    printf("%s", buf);
@}

void myCallBack()
@{
    /* called during i/o, eval, graphics in ProcessEvents */
@}

void myBusy(int which)
@{
    /* set a busy cursor ... if which = 1, unset if which = 0 */
@}

static void my_onintr(int sig) @{ UserBreak = 1; @}

int main (int argc, char **argv)
@{
    structRstart rp;
    Rstart Rp = &rp;
    char Rversion[25], *RHome;

    sprintf(Rversion, "%s.%s", R_MAJOR, R_MINOR);
    if(strcmp(getDLLVersion(), Rversion) != 0) @{
        fprintf(stderr, "Error: R.DLL version does not match\n");
        exit(1);
    @}

    R_setStartTime();
    R_DefParams(Rp);
    if((RHome = get_R_HOME()) == NULL) @{
         fprintf(stderr, "R_HOME must be set in the environment or Registry\n");
         exit(1);
    @}
    Rp->rhome = RHome;
    Rp->home = getRUser();
    Rp->CharacterMode = LinkDLL;
    Rp->ReadConsole = myReadConsole;
    Rp->WriteConsole = myWriteConsole;
    Rp->CallBack = myCallBack;
    Rp->ShowMessage = askok;
    Rp->YesNoCancel = askyesnocancel;
    Rp->Busy = myBusy;

    Rp->R_Quiet = TRUE;        /* Default is FALSE */
    Rp->R_Interactive = FALSE; /* Default is TRUE */
    Rp->RestoreAction = SA_RESTORE;
    Rp->SaveAction = SA_NOSAVE;
    R_SetParams(Rp);
    R_set_command_line_arguments(argc, argv);

    FlushConsoleInputBuffer(GetStdHandle(STD_INPUT_HANDLE));

    signal(SIGBREAK, my_onintr);
    GA_initapp(0, 0);
    readconsolecfg();
    setup_Rmainloop();
#ifdef SIMPLE_CASE
    run_Rmainloop();
#else
    R_ReplDLLinit();
    while(R_ReplDLLdo1() > 0) @{
/* add user actions here if desired */
    @}
/* only get here on EOF (not q()) */
#endif
    Rf_endEmbeddedR(0);
    return 0;
@}
@end smallexample

The ideas are

@itemize
@item
Check that the front-end and the linked @file{R.dll} match -- other
front-ends may allow a looser match.

@item
Find and set the @R{} home directory and the user's home directory.  The
former may be available from the Windows Registry: it will normally be
in @code{HKEY_LOCAL_MACHINE\Software\R-core\R\InstallPath} and can be
set there by running the program @file{@var{R_HOME}\bin\RSetReg.exe}.

@item
Define startup conditions and callbacks via the @code{Rstart} structure.
@code{R_DefParams} sets the defaults, and @code{R_SetParams} sets
updated values.

@item
Record the command-line arguments used by
@code{R_set_command_line_arguments} for use by the @R{} function
@code{commandArgs()}.

@item
Set up the signal handler and the basic user interface.

@item
Run the main @R{} loop, possibly with our actions intermeshed.

@item
Arrange to clean up.
@end itemize

An underlying theme is the need to keep the GUI `alive', and this has
not been done in this example.  The @R{} callback @code{R_ProcessEvents}
needs to be called frequently to ensure that Windows events in @R{}
windows are handled expeditiously.  Conversely, @R{} needs to allow the
GUI code (which is running in the same process) to update itself as
needed -- two ways are provided to allow this:

@itemize
@item
@code{R_ProcessEvents} calls the callback registered by
@code{Rp->callback}.  A version of this is used to run package Tcl/Tk
for @pkg{tcltk} under Windows, for the code is

@example
void R_ProcessEvents(void)
@{
    while (peekevent()) doevent(); /* Windows events for GraphApp */
    if (UserBreak) @{ UserBreak = FALSE; onintr(); @}
    R_CallBackHook();
    if(R_tcldo) R_tcldo();
@}
@end example

@item
The mainloop can be split up to allow the calling application to take
some action after each line of input has been dealt with: see the
alternative code below @code{#ifdef SIMPLE_CASE}.
@end itemize

It may be that no @R{} GraphApp windows need to be considered, although
these include pagers, the @code{windows()} graphics device, the @R{}
data and script editors and various popups such as @code{choose.file()}
and @code{select.list()}.  It would be possible to replace all of these,
but it seems easier to allow GraphApp to handle most of them.

It is possible to run @R{} in a GUI in a single thread (as
@file{RGui.exe} shows) but it will normally be easier@footnote{An
attempt to use only threads in the late 1990s failed to work correctly
under Windows 95, the predominant version of Windows at that time.} to
use multiple threads.

Note that @R{}'s own front ends use a stack size of 10Mb, whereas MinGW
executables default to 2Mb, and Visual C++ ones to 1Mb.  The latter
stack sizes are too small for a number of @R{} applications, so
general-purpose front-ends should use a larger stack size.




@node Function and variable index, Concept index, Linking GUIs and other front-ends to R, Top
@unnumbered Function and variable index

@printindex vr

@node Concept index,  , Function and variable index, Top
@unnumbered Concept index

@printindex cp

@bye

@c Local Variables: ***
@c mode: TeXinfo ***
@c End: ***
